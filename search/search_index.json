{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ebcc: Coupled cluster calculations on electron-boson systems The ebcc package implements various coupled cluster (CC) models for both purely electronic and coupled electron-boson models, with a focus on generality and model extensibility. For a summary of the implemented models, see the FEATURES.md file. Installation From PyPI: pip install ebcc From source: git clone https://github.com/BoothGroup/ebcc pip install . Usage The implemented models are built upon the mean-field objects of pyscf : from pyscf import gto, scf from ebcc import EBCC mol = gto.M(atom=\"H 0 0 0; H 0 0 1\", basis=\"cc-pvdz\") mf = scf.RHF(mol) mf.kernel() ccsd = EBCC(mf, ansatz=\"CCSD\") ccsd.kernel() Many ansatzes for both fermionic and electron-boson coupled cluster calculations are available. For more details see the tutorials and examples directories. Code generation The models implemented are generated algorithmically from expressions over second quantized operators. The scripts for generating these models are found in the codegen directory on the bootstrap branch. User-inputted models should operate seamlessly with the solvers by adding files under ebcc/codegen , so long as they satisfy the interface.","title":"Home"},{"location":"#ebcc-coupled-cluster-calculations-on-electron-boson-systems","text":"The ebcc package implements various coupled cluster (CC) models for both purely electronic and coupled electron-boson models, with a focus on generality and model extensibility. For a summary of the implemented models, see the FEATURES.md file.","title":"ebcc: Coupled cluster calculations on electron-boson systems"},{"location":"#installation","text":"From PyPI: pip install ebcc From source: git clone https://github.com/BoothGroup/ebcc pip install .","title":"Installation"},{"location":"#usage","text":"The implemented models are built upon the mean-field objects of pyscf : from pyscf import gto, scf from ebcc import EBCC mol = gto.M(atom=\"H 0 0 0; H 0 0 1\", basis=\"cc-pvdz\") mf = scf.RHF(mol) mf.kernel() ccsd = EBCC(mf, ansatz=\"CCSD\") ccsd.kernel() Many ansatzes for both fermionic and electron-boson coupled cluster calculations are available. For more details see the tutorials and examples directories.","title":"Usage"},{"location":"#code-generation","text":"The models implemented are generated algorithmically from expressions over second quantized operators. The scripts for generating these models are found in the codegen directory on the bootstrap branch. User-inputted models should operate seamlessly with the solvers by adding files under ebcc/codegen , so long as they satisfy the interface.","title":"Code generation"},{"location":"features/","text":"Coupled cluster calculations using a wide range of ansatzes, as summarised below Lambda equation solver Equation-of-motion solver Density matrices Frozen and active space constraints Brueckner orbital calculations Frozen natural orbital calculations Single- and mixed-precision calculations Externally corrected and tailored coupled cluster calculations The following table summarises the available methods and routines for the ansatz currently treated by code generation, in the three spin cases: Ansatz E T \u039b IP EA EE DM1 DM2 BDM MP2 RUG - - RUG RUG G RUG RUG - MP3 RUG - CCD RUG RUG RUG RUG RUG G RUG RUG - CCSD RUG RUG RUG RUG RUG G RUG RUG - CCSDT RUG RUG RUG RUG RUG - CCSDTQ g g - CCSD(T) RUG RUG - CCSDt' RUG RUG - CC2 RUG RUG RUG RUG RUG G RUG RUG - CC3 RUG RUG - LCCD RUG RUG - LCCSD RUG RUG - QCISD RUG RUG - DCD RU RU - DCSD RU RU - DF-CCD RU RU RU RU RU RU RU - DF-CCSD RU RU RU RU RU RU RU - DF-CC2 RU RU RU RU RU RU RU - DF-LCCD RU RU - DF-LCCSD RU RU - DF-QCISD RU RU - DF-DCD RU RU - DF-DCSD RU RU - CCSD-S-1-1 RUG RUG RUG RUG RUG RUG CCSD-SD-1-1 RUG RUG RUG RUG RUG RUG CCSD-SD-1-2 RUG RUG RUG RUG RUG RUG R, U, G indicate availability of restricted, unrestricted, and generalised codes. Capital letters (R rather than r) indicates that the expressions are optimised for contraction order and subexpression elimination. DF in the ansatz name indicates methods specialised for density-fitted integrals. E is the correlation energy. T, \u039b are the excitation and de-excitation amplitude availabilities, respectively, the former allowing the coupled cluster solver and the latter allowing the lambda solver. IP, EA, EE indicate availability of the corresponding equation of motion (EOM) functionalities. DM1, DM2 indicate availability of the one- and two-particle reduced density matrices. BDM availability includes the single boson density matrix, bosonic one-particle reduced density matrix, and the electron-boson coupling reduced density matrix.","title":"Features"},{"location":"reference/","text":"ebcc: Coupled cluster calculations on electron-boson systems The ebcc package implements various coupled cluster (CC) models for application to electron-boson systems, with a focus on generality and model extensibility. Installation From the python package index: pip install ebcc From source: git clone https://github.com/BoothGroup/ebcc pip install . Usage The implemented models are built upon the mean-field objects of PySCF <https://github.com/pyscf/pyscf> _: from pyscf import gto, scf from ebcc import EBCC mol = gto.M(atom=\"H 0 0 0; H 0 0 1\", basis=\"cc-pvdz\") mf = scf.RHF(mol) mf.kernel() ccsd = EBCC(mf) ccsd.kernel() ebcc.__version__ = '1.6.1' module-attribute List of supported ansatz types. ebcc.EBCC(mf, *args, **kwargs) Construct an EBCC object for the given mean-field object. Source code in ebcc/__init__.py def EBCC(mf: SCF, *args: Any, **kwargs: Any) -> BaseEBCC: \"\"\"Construct an EBCC object for the given mean-field object.\"\"\" from pyscf import scf if isinstance(mf, scf.uhf.UHF): return UEBCC(mf, *args, **kwargs) elif isinstance(mf, scf.ghf.GHF): return GEBCC(mf, *args, **kwargs) else: return REBCC(mf, *args, **kwargs) ebcc.available_models(verbose=True) List available coupled-cluster models for each spin type. Source code in ebcc/__init__.py def available_models( verbose: bool = True, ) -> tuple[tuple[str, ...], tuple[str, ...], tuple[str, ...]]: # pragma: no cover \"\"\"List available coupled-cluster models for each spin type.\"\"\" cd = os.path.dirname(os.path.realpath(__file__)) path = os.path.join(cd, \"codegen\") _, _, files = list(os.walk(path))[0] from ebcc.core.ansatz import identifier_to_name rhf = [] uhf = [] ghf = [] for f in files: if f.endswith(\".py\"): f = f.rstrip(\".py\") f = f.replace(\"_\", \"-\") f = identifier_to_name(f) if f.startswith(\"R\"): rhf.append(f) elif f.startswith(\"U\"): uhf.append(f) elif f.startswith(\"G\"): ghf.append(f) rhf = sorted(rhf) uhf = sorted(uhf) ghf = sorted(ghf) if verbose: sys.stderr.write(\"RHF:\\n %s\\n\" % \", \".join(rhf)) sys.stderr.write(\"UHF:\\n %s\\n\" % \", \".join(uhf)) sys.stderr.write(\"GHF:\\n %s\\n\" % \", \".join(ghf)) return tuple(rhf), tuple(uhf), tuple(ghf)","title":"Index"},{"location":"reference/#ebcc--installation","text":"From the python package index: pip install ebcc From source: git clone https://github.com/BoothGroup/ebcc pip install .","title":"Installation"},{"location":"reference/#ebcc--usage","text":"The implemented models are built upon the mean-field objects of PySCF <https://github.com/pyscf/pyscf> _: from pyscf import gto, scf from ebcc import EBCC mol = gto.M(atom=\"H 0 0 0; H 0 0 1\", basis=\"cc-pvdz\") mf = scf.RHF(mol) mf.kernel() ccsd = EBCC(mf) ccsd.kernel()","title":"Usage"},{"location":"reference/#ebcc.__version__","text":"List of supported ansatz types.","title":"__version__"},{"location":"reference/#ebcc.EBCC","text":"Construct an EBCC object for the given mean-field object. Source code in ebcc/__init__.py def EBCC(mf: SCF, *args: Any, **kwargs: Any) -> BaseEBCC: \"\"\"Construct an EBCC object for the given mean-field object.\"\"\" from pyscf import scf if isinstance(mf, scf.uhf.UHF): return UEBCC(mf, *args, **kwargs) elif isinstance(mf, scf.ghf.GHF): return GEBCC(mf, *args, **kwargs) else: return REBCC(mf, *args, **kwargs)","title":"EBCC"},{"location":"reference/#ebcc.available_models","text":"List available coupled-cluster models for each spin type. Source code in ebcc/__init__.py def available_models( verbose: bool = True, ) -> tuple[tuple[str, ...], tuple[str, ...], tuple[str, ...]]: # pragma: no cover \"\"\"List available coupled-cluster models for each spin type.\"\"\" cd = os.path.dirname(os.path.realpath(__file__)) path = os.path.join(cd, \"codegen\") _, _, files = list(os.walk(path))[0] from ebcc.core.ansatz import identifier_to_name rhf = [] uhf = [] ghf = [] for f in files: if f.endswith(\".py\"): f = f.rstrip(\".py\") f = f.replace(\"_\", \"-\") f = identifier_to_name(f) if f.startswith(\"R\"): rhf.append(f) elif f.startswith(\"U\"): uhf.append(f) elif f.startswith(\"G\"): ghf.append(f) rhf = sorted(rhf) uhf = sorted(uhf) ghf = sorted(ghf) if verbose: sys.stderr.write(\"RHF:\\n %s\\n\" % \", \".join(rhf)) sys.stderr.write(\"UHF:\\n %s\\n\" % \", \".join(uhf)) sys.stderr.write(\"GHF:\\n %s\\n\" % \", \".join(ghf)) return tuple(rhf), tuple(uhf), tuple(ghf)","title":"available_models"},{"location":"reference/cc/","text":"Coupled cluster solvers.","title":"Index"},{"location":"reference/cc/base/","text":"Base classes for ebcc.cc . ebcc.cc.base.T = floating module-attribute Defines the type for the eris argument in functions. ebcc.cc.base.ERIsInputType = Any module-attribute Defines the type for arrays, including spin labels. ebcc.cc.base.SpinArrayType = Any module-attribute Defines the type for the spaces, including spin labels. ebcc.cc.base.BaseOptions(e_tol=1e-08, t_tol=1e-08, max_iter=200, diis_space=9, diis_min_space=1, damping=0.0, shift=True) dataclass Bases: _BaseOptions Options for EBCC calculations. Parameters: e_tol ( float , default: 1e-08 ) \u2013 Threshold for convergence in the correlation energy. t_tol ( float , default: 1e-08 ) \u2013 Threshold for convergence in the amplitude norm. max_iter ( int , default: 200 ) \u2013 Maximum number of iterations. diis_space ( int , default: 9 ) \u2013 Number of amplitudes to use in DIIS extrapolation. diis_min_space ( int , default: 1 ) \u2013 Minimum number of amplitudes to use in DIIS extrapolation. damping ( float , default: 0.0 ) \u2013 Damping factor for DIIS extrapolation. shift ( bool , default: True ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. ebcc.cc.base.BaseEBCC(mf, log=None, ansatz='CCSD', options=None, space=None, omega=None, g=None, G=None, mo_coeff=None, mo_occ=None, fock=None, **kwargs) Bases: ABC Base class for electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\") ebcc.cc.base.BaseEBCC.spin_type: str abstractmethod property Get a string representation of the spin type. ebcc.cc.base.BaseEBCC.name: str property Get the name of the method. ebcc.cc.base.BaseEBCC.fermion_ansatz: str property Get a string representation of the fermion ansatz. ebcc.cc.base.BaseEBCC.boson_ansatz: str property Get a string representation of the boson ansatz. ebcc.cc.base.BaseEBCC.fermion_coupling_rank: int property Get an integer representation of the fermion coupling rank. ebcc.cc.base.BaseEBCC.boson_coupling_rank: int property Get an integer representation of the boson coupling rank. ebcc.cc.base.BaseEBCC.xi: NDArray[T] abstractmethod property Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators. ebcc.cc.base.BaseEBCC.const: float property Get the shift in energy from moving to the polaritonic basis. Returns: float \u2013 Constant energy shift due to the polaritonic basis. ebcc.cc.base.BaseEBCC.mo_coeff: NDArray[T] property Get the molecular orbital coefficients. Returns: NDArray [ T ] \u2013 Molecular orbital coefficients. ebcc.cc.base.BaseEBCC.mo_occ: NDArray[T] property Get the molecular orbital occupation numbers. Returns: NDArray [ T ] \u2013 Molecular orbital occupation numbers. ebcc.cc.base.BaseEBCC.nmo: Any abstractmethod property Get the number of molecular orbitals. Returns: Any \u2013 Number of molecular orbitals. ebcc.cc.base.BaseEBCC.nocc: Any abstractmethod property Get the number of occupied molecular orbitals. Returns: Any \u2013 Number of occupied molecular orbitals. ebcc.cc.base.BaseEBCC.nvir: Any abstractmethod property Get the number of virtual molecular orbitals. Returns: Any \u2013 Number of virtual molecular orbitals. ebcc.cc.base.BaseEBCC.nbos: int property Get the number of bosonic modes. Returns: int \u2013 Number of bosonic modes. ebcc.cc.base.BaseEBCC.e_tot: float property Get the total energy (mean-field plus correlation). Returns: float \u2013 Total energy. ebcc.cc.base.BaseEBCC.t1: Any property Get the T1 amplitudes. ebcc.cc.base.BaseEBCC.t2: Any property Get the T2 amplitudes. ebcc.cc.base.BaseEBCC.t3: Any property Get the T3 amplitudes. ebcc.cc.base.BaseEBCC.l1: Any property Get the L1 amplitudes. ebcc.cc.base.BaseEBCC.l2: Any property Get the L2 amplitudes. ebcc.cc.base.BaseEBCC.l3: Any property Get the L3 amplitudes. ebcc.cc.base.BaseEBCC.kernel(eris=None) Run the coupled cluster calculation. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def kernel(self, eris: Optional[ERIsInputType] = None) -> float: \"\"\"Run the coupled cluster calculation. Args: eris: Electron repulsion integrals. Returns: Correlation energy. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.get_eris(eris) # Get the amplitude guesses: amplitudes = self.amplitudes if not amplitudes: amplitudes = self.init_amps(eris=eris) # Get the initial energy: e_cc = self.energy(amplitudes=amplitudes, eris=eris) self.log.output(\"Solving for excitation amplitudes.\") self.log.debug(\"\") self.log.info( f\"{ANSI.B}{'Iter':>4s} {'Energy (corr.)':>16s} {'Energy (tot.)':>18s} \" f\"{'\u0394(Energy)':>13s} {'\u0394(Ampl.)':>13s}{ANSI.R}\" ) self.log.info(\"%4d %16.10f %18.10f\", 0, e_cc, e_cc + self.mf.e_tot) if not self.ansatz.is_one_shot: # Set up damping: damping = self.Damping(options=self.options) converged = False for niter in range(1, self.options.max_iter + 1): # Update the amplitudes, extrapolate with DIIS and calculate change: amplitudes_prev = amplitudes amplitudes = self.update_amps(amplitudes=amplitudes, eris=eris) vector = self.amplitudes_to_vector(amplitudes) vector = damping(vector) amplitudes = self.vector_to_amplitudes(vector) dt = np.linalg.norm( np.abs(vector - self.amplitudes_to_vector(amplitudes_prev)), ord=np.inf ) # Update the energy and calculate change: e_prev = e_cc e_cc = self.energy(amplitudes=amplitudes, eris=eris) de = abs(e_prev - e_cc) # Log the iteration: converged_e = bool(de < self.options.e_tol) converged_t = bool(dt < self.options.t_tol) self.log.info( f\"%4d %16.10f %18.10f {[ANSI.r, ANSI.g][int(converged_e)]}%13.3e{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_t)]}%13.3e{ANSI.R}\", niter, e_cc, e_cc + self.mf.e_tot, de, dt, ) # Check for convergence: converged = converged_e and converged_t if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") # Include perturbative correction if required: if self.ansatz.has_perturbative_correction: self.log.debug(\"\") self.log.info(\"Computing perturbative energy correction.\") e_pert = self.energy_perturbative(amplitudes=amplitudes, eris=eris) e_cc += e_pert self.log.info(\"E(pert) = %.10f\", e_pert) else: converged = True # Update attributes: self.e_corr = e_cc self.amplitudes = amplitudes self.converged = converged self.log.debug(\"\") self.log.output(\"E(corr) = %.10f\", self.e_corr) self.log.output(\"E(tot) = %.10f\", self.e_corr + self.mf.e_tot) self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") return e_cc ebcc.cc.base.BaseEBCC.solve_lambda(amplitudes=None, eris=None) Solve for the lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Source code in ebcc/cc/base.py def solve_lambda( self, amplitudes: Optional[Namespace[SpinArrayType]] = None, eris: Optional[ERIsInputType] = None, ) -> None: \"\"\"Solve for the lambda amplitudes. Args: amplitudes: Cluster amplitudes. eris: Electron repulsion integrals. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.get_eris(eris) # Get the amplitudes: amplitudes = self.amplitudes if not amplitudes: amplitudes = self.init_amps(eris=eris) # If needed, get the perturbative part of the lambda amplitudes: lambdas_pert = None if self.ansatz.has_perturbative_correction: lambdas_pert = self.update_lams(eris=eris, amplitudes=amplitudes, perturbative=True) # Get the initial lambda amplitudes: lambdas = self.lambdas if not lambdas: lambdas = self.init_lams(amplitudes=amplitudes) self.log.output(\"Solving for de-excitation (lambda) amplitudes.\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}{'Iter':>4s} {'\u0394(Ampl.)':>13s}{ANSI.R}\") # Set up damping: damping = self.Damping(options=self.options) converged = False for niter in range(1, self.options.max_iter + 1): # Update the lambda amplitudes, extrapolate with DIIS and calculate change: lambdas_prev = lambdas lambdas = self.update_lams( amplitudes=amplitudes, lambdas=lambdas, lambdas_pert=lambdas_pert, eris=eris, ) vector = self.lambdas_to_vector(lambdas) vector = damping(vector) lambdas = self.vector_to_lambdas(vector) dl = np.linalg.norm(np.abs(vector - self.lambdas_to_vector(lambdas_prev)), ord=np.inf) # Log the iteration: converged = bool(dl < self.options.t_tol) self.log.info(f\"%4d {[ANSI.r, ANSI.g][int(converged)]}%13.3e{ANSI.R}\", niter, dl) # Check for convergence: if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") self.log.debug(\"\") # Update attributes: self.lambdas = lambdas self.converged_lambda = converged ebcc.cc.base.BaseEBCC.ip_eom(**kwargs) abstractmethod Get the IP-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 IP-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ip_eom(self, **kwargs: Any) -> Any: \"\"\"Get the IP-EOM object. Args: **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" pass ebcc.cc.base.BaseEBCC.ea_eom(**kwargs) abstractmethod Get the EA-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 EA-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ea_eom(self, **kwargs: Any) -> Any: \"\"\"Get the EA-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" pass ebcc.cc.base.BaseEBCC.ee_eom(**kwargs) abstractmethod Get the EE-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 EE-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ee_eom(self, **kwargs: Any) -> Any: \"\"\"Get the EE-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" pass ebcc.cc.base.BaseEBCC.brueckner(*args, **kwargs) Run a Brueckner orbital coupled cluster calculation. The coupled cluster object will be updated in-place. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the Brueckner object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the Brueckner object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def brueckner(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run a Brueckner orbital coupled cluster calculation. The coupled cluster object will be updated in-place. Args: *args: Arguments to pass to the Brueckner object. **kwargs: Keyword arguments to pass to the Brueckner object. Returns: Correlation energy. \"\"\" bcc = self.Brueckner(self, *args, **kwargs) return bcc.kernel() ebcc.cc.base.BaseEBCC.external_correction(*args, **kwargs) Run an externally corrected coupled cluster calculation. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the external correction object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the external correction object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def external_correction(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run an externally corrected coupled cluster calculation. Args: *args: Arguments to pass to the external correction object. **kwargs: Keyword arguments to pass to the external correction object. Returns: Correlation energy. \"\"\" with self.ExternalCorrection(self, *args, **kwargs): return self.kernel() ebcc.cc.base.BaseEBCC.tailor(*args, **kwargs) Run a tailored coupled cluster calculation. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the tailored object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the tailored object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def tailor(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run a tailored coupled cluster calculation. Args: *args: Arguments to pass to the tailored object. **kwargs: Keyword arguments to pass to the tailored object. Returns: Correlation energy. \"\"\" with self.Tailor(self, *args, **kwargs): return self.kernel() ebcc.cc.base.BaseEBCC.write(file) Write the EBCC object to a file. Parameters: file ( str ) \u2013 File to write the object to. Source code in ebcc/cc/base.py def write(self, file: str) -> None: \"\"\"Write the EBCC object to a file. Args: file: File to write the object to. \"\"\" writer = Dump(file) writer.write(self) ebcc.cc.base.BaseEBCC.read(file, log=None) classmethod Read the EBCC object from a file. Parameters: file ( str ) \u2013 File to read the object from. log ( Optional [ Logger ] , default: None ) \u2013 Logger to use for new object. Returns: BaseEBCC \u2013 EBCC object. Source code in ebcc/cc/base.py @classmethod def read(cls, file: str, log: Optional[Logger] = None) -> BaseEBCC: \"\"\"Read the EBCC object from a file. Args: file: File to read the object from. log: Logger to use for new object. Returns: EBCC object. \"\"\" reader = Dump(file) return reader.read(cls=cls, log=log) ebcc.cc.base.BaseEBCC.init_amps(eris=None) abstractmethod Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.init_lams(amplitudes=None) abstractmethod Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.energy(eris=None, amplitudes=None) Calculate the correlation energy. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def energy( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> float: \"\"\"Calculate the correlation energy. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Correlation energy. \"\"\" func, kwargs = self._load_function( \"energy\", eris=eris, amplitudes=amplitudes, ) res: float = np.real(ensure_scalar(func(**kwargs))) return astype(res, float) ebcc.cc.base.BaseEBCC.energy_perturbative(eris=None, amplitudes=None, lambdas=None) Calculate the perturbative correction to the correlation energy. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. Returns: float \u2013 Perturbative energy correction. Source code in ebcc/cc/base.py def energy_perturbative( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, ) -> float: \"\"\"Calculate the perturbative correction to the correlation energy. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. Returns: Perturbative energy correction. \"\"\" func, kwargs = self._load_function( \"energy_perturbative\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: float = np.real(ensure_scalar(func(**kwargs))) return res ebcc.cc.base.BaseEBCC.update_amps(eris=None, amplitudes=None) abstractmethod Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.update_lams(eris=None, amplitudes=None, lambdas=None, lambdas_pert=None, perturbative=False) abstractmethod Update the cluster lambda amplitudes. Parameters: eris ( ERIsInputType , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def update_lams( self, eris: ERIsInputType = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.make_sing_b_dm(eris=None, amplitudes=None, lambdas=None) Make the single boson density matrix :math: \\langle b \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Single boson density matrix. Source code in ebcc/cc/base.py def make_sing_b_dm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, ) -> NDArray[T]: r\"\"\"Make the single boson density matrix :math:`\\langle b \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. Returns: Single boson density matrix. \"\"\" func, kwargs = self._load_function( \"make_sing_b_dm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: NDArray[T] = func(**kwargs) return res ebcc.cc.base.BaseEBCC.make_rdm1_b(eris=None, amplitudes=None, lambdas=None, unshifted=True, hermitise=True) Make the one-particle boson reduced density matrix :math: \\langle b^+ c \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 One-particle boson reduced density matrix. Source code in ebcc/cc/base.py def make_rdm1_b( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the one-particle boson reduced density matrix :math:`\\langle b^+ c \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: One-particle boson reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_b\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 if unshifted and self.options.shift: xi = self.xi dm_b = util.einsum(\"ni->i\", self.make_sing_b_dm()) dm -= util.einsum(\"ij,i->ij\", np.eye(dm.shape[0]), xi * dm_b - xi**2.0) return dm ebcc.cc.base.BaseEBCC.make_rdm1_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) abstractmethod Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> Any: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" pass ebcc.cc.base.BaseEBCC.make_rdm2_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) abstractmethod Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> Any: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" pass ebcc.cc.base.BaseEBCC.make_eb_coup_rdm(eris=None, amplitudes=None, lambdas=None, unshifted=True, hermitise=True) abstractmethod Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> Any: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" pass ebcc.cc.base.BaseEBCC.energy_sum(*args, signs_dict=None) abstractmethod Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Subclass should specify a subscript, and optionally spins. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/base.py @abstractmethod def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Subclass should specify a subscript, and optionally spins. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" pass ebcc.cc.base.BaseEBCC.amplitudes_to_vector(amplitudes) abstractmethod Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/base.py @abstractmethod def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" pass ebcc.cc.base.BaseEBCC.vector_to_amplitudes(vector) abstractmethod Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.lambdas_to_vector(lambdas) abstractmethod Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/base.py @abstractmethod def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" pass ebcc.cc.base.BaseEBCC.vector_to_lambdas(vector) abstractmethod Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" pass ebcc.cc.base.BaseEBCC.init_space() abstractmethod Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/base.py @abstractmethod def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" pass ebcc.cc.base.BaseEBCC.get_fock() Get the Fock matrix. Returns: BaseFock \u2013 Fock matrix. Source code in ebcc/cc/base.py def get_fock(self) -> BaseFock: \"\"\"Get the Fock matrix. Returns: Fock matrix. \"\"\" return self.Fock( self.mf, space=(self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff), g=self.g, shift=self.options.shift, xi=self.xi if self.boson_ansatz else None, ) ebcc.cc.base.BaseEBCC.get_eris(eris=None) Get the electron repulsion integrals. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Input electron repulsion integrals. Returns: BaseERIs \u2013 Electron repulsion integrals. Source code in ebcc/cc/base.py def get_eris(self, eris: Optional[ERIsInputType] = None) -> BaseERIs: \"\"\"Get the electron repulsion integrals. Args: eris: Input electron repulsion integrals. Returns: Electron repulsion integrals. \"\"\" use_df = getattr(self.mf, \"with_df\", None) is not None if isinstance(eris, BaseERIs): return eris elif eris is not None: raise TypeError(f\"`eris` must be an `BaseERIs` object, got {eris.__class__.__name__}.\") elif use_df: return self.CDERIs( self.mf, space=(self.space, self.space, self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff, self.mo_coeff, self.mo_coeff), ) else: return self.ERIs( self.mf, space=(self.space, self.space, self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff, self.mo_coeff, self.mo_coeff), ) ebcc.cc.base.BaseEBCC.get_g() Get the blocks of the electron-boson coupling matrix. This matrix corresponds to the bosonic annihilation operator. Returns: BaseElectronBoson \u2013 Electron-boson coupling matrix. Source code in ebcc/cc/base.py def get_g(self) -> BaseElectronBoson: \"\"\"Get the blocks of the electron-boson coupling matrix. This matrix corresponds to the bosonic annihilation operator. Returns: Electron-boson coupling matrix. \"\"\" if self.bare_g is None: raise ValueError(\"Bare electron-boson coupling matrix not provided.\") return self.ElectronBoson( self.mf, self.bare_g, (self.space, self.space), (self.mo_coeff, self.mo_coeff), ) ebcc.cc.base.BaseEBCC.get_mean_field_G() abstractmethod Get the mean-field boson non-conserving term. Returns: Any \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/base.py @abstractmethod def get_mean_field_G(self) -> Any: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" pass","title":"Base"},{"location":"reference/cc/base/#ebcc.cc.base.T","text":"Defines the type for the eris argument in functions.","title":"T"},{"location":"reference/cc/base/#ebcc.cc.base.ERIsInputType","text":"Defines the type for arrays, including spin labels.","title":"ERIsInputType"},{"location":"reference/cc/base/#ebcc.cc.base.SpinArrayType","text":"Defines the type for the spaces, including spin labels.","title":"SpinArrayType"},{"location":"reference/cc/base/#ebcc.cc.base.BaseOptions","text":"Bases: _BaseOptions Options for EBCC calculations. Parameters: e_tol ( float , default: 1e-08 ) \u2013 Threshold for convergence in the correlation energy. t_tol ( float , default: 1e-08 ) \u2013 Threshold for convergence in the amplitude norm. max_iter ( int , default: 200 ) \u2013 Maximum number of iterations. diis_space ( int , default: 9 ) \u2013 Number of amplitudes to use in DIIS extrapolation. diis_min_space ( int , default: 1 ) \u2013 Minimum number of amplitudes to use in DIIS extrapolation. damping ( float , default: 0.0 ) \u2013 Damping factor for DIIS extrapolation. shift ( bool , default: True ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift.","title":"BaseOptions"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC","text":"Bases: ABC Base class for electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\")","title":"BaseEBCC"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.spin_type","text":"Get a string representation of the spin type.","title":"spin_type"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.name","text":"Get the name of the method.","title":"name"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.fermion_ansatz","text":"Get a string representation of the fermion ansatz.","title":"fermion_ansatz"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.boson_ansatz","text":"Get a string representation of the boson ansatz.","title":"boson_ansatz"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.fermion_coupling_rank","text":"Get an integer representation of the fermion coupling rank.","title":"fermion_coupling_rank"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.boson_coupling_rank","text":"Get an integer representation of the boson coupling rank.","title":"boson_coupling_rank"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.xi","text":"Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators.","title":"xi"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.const","text":"Get the shift in energy from moving to the polaritonic basis. Returns: float \u2013 Constant energy shift due to the polaritonic basis.","title":"const"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.mo_coeff","text":"Get the molecular orbital coefficients. Returns: NDArray [ T ] \u2013 Molecular orbital coefficients.","title":"mo_coeff"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.mo_occ","text":"Get the molecular orbital occupation numbers. Returns: NDArray [ T ] \u2013 Molecular orbital occupation numbers.","title":"mo_occ"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.nmo","text":"Get the number of molecular orbitals. Returns: Any \u2013 Number of molecular orbitals.","title":"nmo"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.nocc","text":"Get the number of occupied molecular orbitals. Returns: Any \u2013 Number of occupied molecular orbitals.","title":"nocc"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.nvir","text":"Get the number of virtual molecular orbitals. Returns: Any \u2013 Number of virtual molecular orbitals.","title":"nvir"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.nbos","text":"Get the number of bosonic modes. Returns: int \u2013 Number of bosonic modes.","title":"nbos"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.e_tot","text":"Get the total energy (mean-field plus correlation). Returns: float \u2013 Total energy.","title":"e_tot"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.t1","text":"Get the T1 amplitudes.","title":"t1"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.t2","text":"Get the T2 amplitudes.","title":"t2"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.t3","text":"Get the T3 amplitudes.","title":"t3"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.l1","text":"Get the L1 amplitudes.","title":"l1"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.l2","text":"Get the L2 amplitudes.","title":"l2"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.l3","text":"Get the L3 amplitudes.","title":"l3"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.kernel","text":"Run the coupled cluster calculation. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def kernel(self, eris: Optional[ERIsInputType] = None) -> float: \"\"\"Run the coupled cluster calculation. Args: eris: Electron repulsion integrals. Returns: Correlation energy. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.get_eris(eris) # Get the amplitude guesses: amplitudes = self.amplitudes if not amplitudes: amplitudes = self.init_amps(eris=eris) # Get the initial energy: e_cc = self.energy(amplitudes=amplitudes, eris=eris) self.log.output(\"Solving for excitation amplitudes.\") self.log.debug(\"\") self.log.info( f\"{ANSI.B}{'Iter':>4s} {'Energy (corr.)':>16s} {'Energy (tot.)':>18s} \" f\"{'\u0394(Energy)':>13s} {'\u0394(Ampl.)':>13s}{ANSI.R}\" ) self.log.info(\"%4d %16.10f %18.10f\", 0, e_cc, e_cc + self.mf.e_tot) if not self.ansatz.is_one_shot: # Set up damping: damping = self.Damping(options=self.options) converged = False for niter in range(1, self.options.max_iter + 1): # Update the amplitudes, extrapolate with DIIS and calculate change: amplitudes_prev = amplitudes amplitudes = self.update_amps(amplitudes=amplitudes, eris=eris) vector = self.amplitudes_to_vector(amplitudes) vector = damping(vector) amplitudes = self.vector_to_amplitudes(vector) dt = np.linalg.norm( np.abs(vector - self.amplitudes_to_vector(amplitudes_prev)), ord=np.inf ) # Update the energy and calculate change: e_prev = e_cc e_cc = self.energy(amplitudes=amplitudes, eris=eris) de = abs(e_prev - e_cc) # Log the iteration: converged_e = bool(de < self.options.e_tol) converged_t = bool(dt < self.options.t_tol) self.log.info( f\"%4d %16.10f %18.10f {[ANSI.r, ANSI.g][int(converged_e)]}%13.3e{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_t)]}%13.3e{ANSI.R}\", niter, e_cc, e_cc + self.mf.e_tot, de, dt, ) # Check for convergence: converged = converged_e and converged_t if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") # Include perturbative correction if required: if self.ansatz.has_perturbative_correction: self.log.debug(\"\") self.log.info(\"Computing perturbative energy correction.\") e_pert = self.energy_perturbative(amplitudes=amplitudes, eris=eris) e_cc += e_pert self.log.info(\"E(pert) = %.10f\", e_pert) else: converged = True # Update attributes: self.e_corr = e_cc self.amplitudes = amplitudes self.converged = converged self.log.debug(\"\") self.log.output(\"E(corr) = %.10f\", self.e_corr) self.log.output(\"E(tot) = %.10f\", self.e_corr + self.mf.e_tot) self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") return e_cc","title":"kernel"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.solve_lambda","text":"Solve for the lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Source code in ebcc/cc/base.py def solve_lambda( self, amplitudes: Optional[Namespace[SpinArrayType]] = None, eris: Optional[ERIsInputType] = None, ) -> None: \"\"\"Solve for the lambda amplitudes. Args: amplitudes: Cluster amplitudes. eris: Electron repulsion integrals. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.get_eris(eris) # Get the amplitudes: amplitudes = self.amplitudes if not amplitudes: amplitudes = self.init_amps(eris=eris) # If needed, get the perturbative part of the lambda amplitudes: lambdas_pert = None if self.ansatz.has_perturbative_correction: lambdas_pert = self.update_lams(eris=eris, amplitudes=amplitudes, perturbative=True) # Get the initial lambda amplitudes: lambdas = self.lambdas if not lambdas: lambdas = self.init_lams(amplitudes=amplitudes) self.log.output(\"Solving for de-excitation (lambda) amplitudes.\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}{'Iter':>4s} {'\u0394(Ampl.)':>13s}{ANSI.R}\") # Set up damping: damping = self.Damping(options=self.options) converged = False for niter in range(1, self.options.max_iter + 1): # Update the lambda amplitudes, extrapolate with DIIS and calculate change: lambdas_prev = lambdas lambdas = self.update_lams( amplitudes=amplitudes, lambdas=lambdas, lambdas_pert=lambdas_pert, eris=eris, ) vector = self.lambdas_to_vector(lambdas) vector = damping(vector) lambdas = self.vector_to_lambdas(vector) dl = np.linalg.norm(np.abs(vector - self.lambdas_to_vector(lambdas_prev)), ord=np.inf) # Log the iteration: converged = bool(dl < self.options.t_tol) self.log.info(f\"%4d {[ANSI.r, ANSI.g][int(converged)]}%13.3e{ANSI.R}\", niter, dl) # Check for convergence: if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") self.log.debug(\"\") # Update attributes: self.lambdas = lambdas self.converged_lambda = converged","title":"solve_lambda"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.ip_eom","text":"Get the IP-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 IP-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ip_eom(self, **kwargs: Any) -> Any: \"\"\"Get the IP-EOM object. Args: **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" pass","title":"ip_eom"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.ea_eom","text":"Get the EA-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 EA-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ea_eom(self, **kwargs: Any) -> Any: \"\"\"Get the EA-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" pass","title":"ea_eom"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.ee_eom","text":"Get the EE-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: Any \u2013 EE-EOM object. Source code in ebcc/cc/base.py @abstractmethod def ee_eom(self, **kwargs: Any) -> Any: \"\"\"Get the EE-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" pass","title":"ee_eom"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.brueckner","text":"Run a Brueckner orbital coupled cluster calculation. The coupled cluster object will be updated in-place. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the Brueckner object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the Brueckner object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def brueckner(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run a Brueckner orbital coupled cluster calculation. The coupled cluster object will be updated in-place. Args: *args: Arguments to pass to the Brueckner object. **kwargs: Keyword arguments to pass to the Brueckner object. Returns: Correlation energy. \"\"\" bcc = self.Brueckner(self, *args, **kwargs) return bcc.kernel()","title":"brueckner"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.external_correction","text":"Run an externally corrected coupled cluster calculation. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the external correction object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the external correction object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def external_correction(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run an externally corrected coupled cluster calculation. Args: *args: Arguments to pass to the external correction object. **kwargs: Keyword arguments to pass to the external correction object. Returns: Correlation energy. \"\"\" with self.ExternalCorrection(self, *args, **kwargs): return self.kernel()","title":"external_correction"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.tailor","text":"Run a tailored coupled cluster calculation. Parameters: *args ( Any , default: () ) \u2013 Arguments to pass to the tailored object. **kwargs ( Any , default: {} ) \u2013 Keyword arguments to pass to the tailored object. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def tailor(self, *args: Any, **kwargs: Any) -> float: \"\"\"Run a tailored coupled cluster calculation. Args: *args: Arguments to pass to the tailored object. **kwargs: Keyword arguments to pass to the tailored object. Returns: Correlation energy. \"\"\" with self.Tailor(self, *args, **kwargs): return self.kernel()","title":"tailor"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.write","text":"Write the EBCC object to a file. Parameters: file ( str ) \u2013 File to write the object to. Source code in ebcc/cc/base.py def write(self, file: str) -> None: \"\"\"Write the EBCC object to a file. Args: file: File to write the object to. \"\"\" writer = Dump(file) writer.write(self)","title":"write"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.read","text":"Read the EBCC object from a file. Parameters: file ( str ) \u2013 File to read the object from. log ( Optional [ Logger ] , default: None ) \u2013 Logger to use for new object. Returns: BaseEBCC \u2013 EBCC object. Source code in ebcc/cc/base.py @classmethod def read(cls, file: str, log: Optional[Logger] = None) -> BaseEBCC: \"\"\"Read the EBCC object from a file. Args: file: File to read the object from. log: Logger to use for new object. Returns: EBCC object. \"\"\" reader = Dump(file) return reader.read(cls=cls, log=log)","title":"read"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.init_amps","text":"Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" pass","title":"init_amps"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.init_lams","text":"Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" pass","title":"init_lams"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.energy","text":"Calculate the correlation energy. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: float \u2013 Correlation energy. Source code in ebcc/cc/base.py def energy( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> float: \"\"\"Calculate the correlation energy. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Correlation energy. \"\"\" func, kwargs = self._load_function( \"energy\", eris=eris, amplitudes=amplitudes, ) res: float = np.real(ensure_scalar(func(**kwargs))) return astype(res, float)","title":"energy"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.energy_perturbative","text":"Calculate the perturbative correction to the correlation energy. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. Returns: float \u2013 Perturbative energy correction. Source code in ebcc/cc/base.py def energy_perturbative( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, ) -> float: \"\"\"Calculate the perturbative correction to the correlation energy. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. Returns: Perturbative energy correction. \"\"\" func, kwargs = self._load_function( \"energy_perturbative\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: float = np.real(ensure_scalar(func(**kwargs))) return res","title":"energy_perturbative"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.update_amps","text":"Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" pass","title":"update_amps"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.update_lams","text":"Update the cluster lambda amplitudes. Parameters: eris ( ERIsInputType , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def update_lams( self, eris: ERIsInputType = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" pass","title":"update_lams"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.make_sing_b_dm","text":"Make the single boson density matrix :math: \\langle b \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Single boson density matrix. Source code in ebcc/cc/base.py def make_sing_b_dm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, ) -> NDArray[T]: r\"\"\"Make the single boson density matrix :math:`\\langle b \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. Returns: Single boson density matrix. \"\"\" func, kwargs = self._load_function( \"make_sing_b_dm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: NDArray[T] = func(**kwargs) return res","title":"make_sing_b_dm"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.make_rdm1_b","text":"Make the one-particle boson reduced density matrix :math: \\langle b^+ c \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 One-particle boson reduced density matrix. Source code in ebcc/cc/base.py def make_rdm1_b( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the one-particle boson reduced density matrix :math:`\\langle b^+ c \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: One-particle boson reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_b\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 if unshifted and self.options.shift: xi = self.xi dm_b = util.einsum(\"ni->i\", self.make_sing_b_dm()) dm -= util.einsum(\"ij,i->ij\", np.eye(dm.shape[0]), xi * dm_b - xi**2.0) return dm","title":"make_rdm1_b"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.make_rdm1_f","text":"Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> Any: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" pass","title":"make_rdm1_f"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.make_rdm2_f","text":"Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> Any: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" pass","title":"make_rdm2_f"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.make_eb_coup_rdm","text":"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: Any \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/base.py @abstractmethod def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> Any: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" pass","title":"make_eb_coup_rdm"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.energy_sum","text":"Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Subclass should specify a subscript, and optionally spins. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/base.py @abstractmethod def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Subclass should specify a subscript, and optionally spins. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" pass","title":"energy_sum"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.amplitudes_to_vector","text":"Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/base.py @abstractmethod def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" pass","title":"amplitudes_to_vector"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.vector_to_amplitudes","text":"Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/base.py @abstractmethod def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" pass","title":"vector_to_amplitudes"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.lambdas_to_vector","text":"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/base.py @abstractmethod def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" pass","title":"lambdas_to_vector"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.vector_to_lambdas","text":"Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/base.py @abstractmethod def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" pass","title":"vector_to_lambdas"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.init_space","text":"Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/base.py @abstractmethod def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" pass","title":"init_space"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.get_fock","text":"Get the Fock matrix. Returns: BaseFock \u2013 Fock matrix. Source code in ebcc/cc/base.py def get_fock(self) -> BaseFock: \"\"\"Get the Fock matrix. Returns: Fock matrix. \"\"\" return self.Fock( self.mf, space=(self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff), g=self.g, shift=self.options.shift, xi=self.xi if self.boson_ansatz else None, )","title":"get_fock"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.get_eris","text":"Get the electron repulsion integrals. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Input electron repulsion integrals. Returns: BaseERIs \u2013 Electron repulsion integrals. Source code in ebcc/cc/base.py def get_eris(self, eris: Optional[ERIsInputType] = None) -> BaseERIs: \"\"\"Get the electron repulsion integrals. Args: eris: Input electron repulsion integrals. Returns: Electron repulsion integrals. \"\"\" use_df = getattr(self.mf, \"with_df\", None) is not None if isinstance(eris, BaseERIs): return eris elif eris is not None: raise TypeError(f\"`eris` must be an `BaseERIs` object, got {eris.__class__.__name__}.\") elif use_df: return self.CDERIs( self.mf, space=(self.space, self.space, self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff, self.mo_coeff, self.mo_coeff), ) else: return self.ERIs( self.mf, space=(self.space, self.space, self.space, self.space), mo_coeff=(self.mo_coeff, self.mo_coeff, self.mo_coeff, self.mo_coeff), )","title":"get_eris"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.get_g","text":"Get the blocks of the electron-boson coupling matrix. This matrix corresponds to the bosonic annihilation operator. Returns: BaseElectronBoson \u2013 Electron-boson coupling matrix. Source code in ebcc/cc/base.py def get_g(self) -> BaseElectronBoson: \"\"\"Get the blocks of the electron-boson coupling matrix. This matrix corresponds to the bosonic annihilation operator. Returns: Electron-boson coupling matrix. \"\"\" if self.bare_g is None: raise ValueError(\"Bare electron-boson coupling matrix not provided.\") return self.ElectronBoson( self.mf, self.bare_g, (self.space, self.space), (self.mo_coeff, self.mo_coeff), )","title":"get_g"},{"location":"reference/cc/base/#ebcc.cc.base.BaseEBCC.get_mean_field_G","text":"Get the mean-field boson non-conserving term. Returns: Any \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/base.py @abstractmethod def get_mean_field_G(self) -> Any: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" pass","title":"get_mean_field_G"},{"location":"reference/cc/gebcc/","text":"Generalised electron-boson coupled cluster. ebcc.cc.gebcc.GEBCC(mf, log=None, ansatz='CCSD', options=None, space=None, omega=None, g=None, G=None, mo_coeff=None, mo_occ=None, fock=None, **kwargs) Bases: BaseEBCC Restricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\") ebcc.cc.gebcc.GEBCC.spin_type: str property Get a string representation of the spin type. ebcc.cc.gebcc.GEBCC.xi: NDArray[T] property Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators. ebcc.cc.gebcc.GEBCC.nmo: int property Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals. ebcc.cc.gebcc.GEBCC.nocc: int property Get the number of occupied molecular orbitals. Returns: int \u2013 Number of occupied molecular orbitals. ebcc.cc.gebcc.GEBCC.nvir: int property Get the number of virtual molecular orbitals. Returns: int \u2013 Number of virtual molecular orbitals. ebcc.cc.gebcc.GEBCC.ip_eom(**kwargs) Get the IP-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_GEOM \u2013 IP-EOM object. Source code in ebcc/cc/gebcc.py def ip_eom(self, **kwargs: Any) -> IP_GEOM: \"\"\"Get the IP-EOM object. Args: **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_GEOM(self, **kwargs) ebcc.cc.gebcc.GEBCC.ea_eom(**kwargs) Get the EA-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_GEOM \u2013 EA-EOM object. Source code in ebcc/cc/gebcc.py def ea_eom(self, **kwargs: Any) -> EA_GEOM: \"\"\"Get the EA-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_GEOM(self, **kwargs) ebcc.cc.gebcc.GEBCC.ee_eom(**kwargs) Get the EE-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_GEOM \u2013 EE-EOM object. Source code in ebcc/cc/gebcc.py def ee_eom(self, **kwargs: Any) -> EE_GEOM: \"\"\"Get the EE-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_GEOM(self, **kwargs) ebcc.cc.gebcc.GEBCC.from_uebcc(ucc) classmethod Initialise a GEBCC object from an UEBCC object. Parameters: ucc ( UEBCC ) \u2013 Unrestricted electron-boson coupled cluster object. Returns: GEBCC \u2013 GEBCC object. Source code in ebcc/cc/gebcc.py @classmethod def from_uebcc(cls, ucc: UEBCC) -> GEBCC: \"\"\"Initialise a `GEBCC` object from an `UEBCC` object. Args: ucc: Unrestricted electron-boson coupled cluster object. Returns: GEBCC object. \"\"\" orbspin = np.asarray(scf.addons.get_ghf_orbspin(ucc.mf.mo_energy, ucc.mf.mo_occ, False)) nocc = ucc.space[0].nocc + ucc.space[1].nocc nvir = ucc.space[0].nvir + ucc.space[1].nvir nbos = ucc.nbos sa = np.where(orbspin == 0)[0] sb = np.where(orbspin == 1)[0] occupied = np.zeros((nocc + nvir,), dtype=np.bool_) occupied = _put(occupied, sa, np.copy(ucc.space[0]._occupied)) occupied = _put(occupied, sb, np.copy(ucc.space[1]._occupied)) frozen = np.zeros((nocc + nvir,), dtype=np.bool_) frozen = _put(frozen, sa, np.copy(ucc.space[0]._frozen)) frozen = _put(frozen, sb, np.copy(ucc.space[1]._frozen)) active = np.zeros((nocc + nvir,), dtype=np.bool_) active = _put(active, sa, np.copy(ucc.space[0]._active)) active = _put(active, sb, np.copy(ucc.space[1]._active)) space = Space(occupied, frozen, active) slices = util.Namespace( a=util.Namespace(**{k: np.where(orbspin[space.mask(k)] == 0)[0] for k in \"oOivVa\"}), b=util.Namespace(**{k: np.where(orbspin[space.mask(k)] == 1)[0] for k in \"oOivVa\"}), ) g: Optional[NDArray[T]] = None if ucc.bare_g is not None: if ucc.bare_g.ndim == 3: bare_g_a = bare_g_b = ucc.bare_g else: bare_g_a, bare_g_b = ucc.bare_g g = np.zeros((ucc.nbos, ucc.nmo * 2, ucc.nmo * 2), dtype=types[float]) g = _put(g, np.ix_(np.arange(ucc.nbos), sa, sa), np.copy(bare_g_a)) g = _put(g, np.ix_(np.arange(ucc.nbos), sb, sb), np.copy(bare_g_b)) gcc = cls( ucc.mf, log=ucc.log, ansatz=ucc.ansatz, space=space, omega=ucc.omega, g=g, G=ucc.bare_G, options=ucc.options, ) gcc.e_corr = ucc.e_corr gcc.converged = ucc.converged gcc.converged_lambda = ucc.converged_lambda has_amps = bool(ucc.amplitudes) has_lams = bool(ucc.lambdas) if has_amps: amplitudes: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): shape = tuple(space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(n, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(n))): for uperm, usign in util.permutations_with_signs(tuple(range(n))): combn = util.permute_string(comb[:n], lperm) combn += util.permute_string(comb[n:], uperm) if combn in done: continue mask = np.ix_(*[slices[s][k] for s, k in zip(combn, key)]) transpose = tuple(lperm) + tuple(p + n for p in uperm) amp = ( np.transpose(getattr(ucc.amplitudes[name], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(n))): transpose = tuple(perm) + tuple(range(n, 2 * n)) if util.permute_string(comb[:n], perm) == comb[:n]: amplitudes[name] = _put( amplitudes[name], mask, amplitudes[name][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = np.copy(ucc.amplitudes[name]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): shape = (nbos,) * nb + tuple(space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(nf): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(nf))): for uperm, usign in util.permutations_with_signs(tuple(range(nf))): combn = util.permute_string(comb[:nf], lperm) combn += util.permute_string(comb[nf:], uperm) if combn in done: continue mask = np.ix_( *([np.arange(nbos)] * nb), *[slices[s][k] for s, k in zip(combn, key[nb:])], ) transpose = ( tuple(range(nb)) + tuple(p + nb for p in lperm) + tuple(p + nb + nf for p in uperm) ) amp = ( np.transpose(getattr(ucc.amplitudes[name], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(nf))): transpose = ( tuple(range(nb)) + tuple(p + nb for p in perm) + tuple(range(nb + nf, nb + 2 * nf)) ) if util.permute_string(comb[:nf], perm) == comb[:nf]: amplitudes[name] = _put( amplitudes[name], mask, amplitudes[name][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) gcc.amplitudes = amplitudes if has_lams: lambdas = gcc.init_lams() # Easier this way - but have to build ERIs... for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): lname = name.replace(\"t\", \"l\") shape = tuple(space.size(k) for k in key[n:] + key[:n]) lambdas[lname] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(n, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(n))): for uperm, usign in util.permutations_with_signs(tuple(range(n))): combn = util.permute_string(comb[:n], lperm) combn += util.permute_string(comb[n:], uperm) if combn in done: continue mask = np.ix_(*[slices[s][k] for s, k in zip(combn, key[n:] + key[:n])]) transpose = tuple(lperm) + tuple(p + n for p in uperm) amp = ( np.transpose(getattr(ucc.lambdas[lname], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(n))): transpose = tuple(perm) + tuple(range(n, 2 * n)) if util.permute_string(comb[:n], perm) == comb[:n]: lambdas[lname] = _put( lambdas[lname], mask, lambdas[lname][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = np.copy(ucc.lambdas[lname]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name shape = (nbos,) * nb + tuple( space.size(k) for k in key[nb + nf :] + key[nb : nb + nf] ) lambdas[lname] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(nf, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(nf))): for uperm, usign in util.permutations_with_signs(tuple(range(nf))): combn = util.permute_string(comb[:nf], lperm) combn += util.permute_string(comb[nf:], uperm) if combn in done: continue mask = np.ix_( *([np.arange(nbos)] * nb), *[ slices[s][k] for s, k in zip(combn, key[nb + nf :] + key[nb : nb + nf]) ], ) transpose = ( tuple(range(nb)) + tuple(p + nb for p in lperm) + tuple(p + nb + nf for p in uperm) ) amp = ( np.transpose(getattr(ucc.lambdas[lname], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(nf))): transpose = ( tuple(range(nb)) + tuple(p + nb for p in perm) + tuple(range(nb + nf, nb + 2 * nf)) ) if util.permute_string(comb[:nf], perm) == comb[:nf]: lambdas[lname] = _put( lambdas[lname], mask, lambdas[lname][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) gcc.lambdas = lambdas return gcc ebcc.cc.gebcc.GEBCC.from_rebcc(rcc) classmethod Initialise a GEBCC object from an REBCC object. Parameters: rcc ( REBCC ) \u2013 Restricted electron-boson coupled cluster object. Returns: GEBCC \u2013 GEBCC object. Source code in ebcc/cc/gebcc.py @classmethod def from_rebcc(cls, rcc: REBCC) -> GEBCC: \"\"\"Initialise a `GEBCC` object from an `REBCC` object. Args: rcc: Restricted electron-boson coupled cluster object. Returns: GEBCC object. \"\"\" from ebcc.cc.uebcc import UEBCC ucc = UEBCC.from_rebcc(rcc) gcc = cls.from_uebcc(ucc) return gcc ebcc.cc.gebcc.GEBCC.init_space() Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/gebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = Space( self.mo_occ > 0, np.zeros(self.mo_occ.shape, dtype=np.bool_), np.zeros(self.mo_occ.shape, dtype=np.bool_), ) return space ebcc.cc.gebcc.GEBCC.init_amps(eris=None) Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/gebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): if n == 1: amplitudes[name] = getattr(self.fock, key) / self.energy_sum(key) elif n == 2: amplitudes[name] = getattr(eris, key) / self.energy_sum(key) else: shape = tuple(self.space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if n == 1: amplitudes[name] = self.g[key] / self.energy_sum(key) else: shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) return amplitudes ebcc.cc.gebcc.GEBCC.init_lams(amplitudes=None) Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = np.transpose(amplitudes[name], perm) # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lname = \"l\" + name lambdas[lname] = amplitudes[name] # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented lname = \"l\" + name perm = list(range(nb)) + [nb + 1, nb] lambdas[lname] = np.transpose(amplitudes[name], perm) return lambdas ebcc.cc.gebcc.GEBCC.update_amps(eris=None, amplitudes=None) Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/gebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) res[name] += amplitudes[name] return res ebcc.cc.gebcc.GEBCC.update_lams(eris=None, amplitudes=None, lambdas=None, lambdas_pert=None, perturbative=False) Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) if lambdas_pert is not None: lambdas.update(lambdas_pert) func, kwargs = self._load_function( \"update_lams%s\" % (\"_perturbative\" if perturbative else \"\"), eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] if perturbative: res = Namespace(**{key + \"pert\": val for key, val in res.items()}) return res ebcc.cc.gebcc.GEBCC.make_rdm1_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/gebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 return dm ebcc.cc.gebcc.GEBCC.make_rdm2_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/gebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm ebcc.cc.gebcc.GEBCC.make_eb_coup_rdm(eris=None, amplitudes=None, lambdas=None, unshifted=True, hermitise=True) Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/gebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: SpinArrayType = func(**kwargs) if hermitise: dm_eb = np.array( [ (dm_eb[0] + np.transpose(dm_eb[1], (0, 2, 1))) * 0.5, (dm_eb[1] + np.transpose(dm_eb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f) dm_eb -= shift[None] return dm_eb ebcc.cc.gebcc.GEBCC.energy_sum(*args, signs_dict=None) Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript only. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/gebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript only. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" (subscript,) = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key in subscript: factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum ebcc.cc.gebcc.GEBCC.amplitudes_to_vector(amplitudes) Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/gebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) return np.concatenate(vectors) ebcc.cc.gebcc.GEBCC.vector_to_amplitudes(vector) Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/gebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return amplitudes ebcc.cc.gebcc.GEBCC.lambdas_to_vector(lambdas) Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/gebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) return np.concatenate(vectors) ebcc.cc.gebcc.GEBCC.vector_to_lambdas(vector) Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return lambdas ebcc.cc.gebcc.GEBCC.get_mean_field_G() Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/gebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" assert self.g is not None assert self.omega is not None # FIXME should this also sum in frozen orbitals? boo: NDArray[T] = self.g.boo val = util.einsum(\"Ipp->I\", boo) val -= self.xi * self.omega if self.bare_G is not None: val += self.bare_G return val","title":"Generalised"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC","text":"Bases: BaseEBCC Restricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\")","title":"GEBCC"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.spin_type","text":"Get a string representation of the spin type.","title":"spin_type"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.xi","text":"Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators.","title":"xi"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.nmo","text":"Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals.","title":"nmo"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.nocc","text":"Get the number of occupied molecular orbitals. Returns: int \u2013 Number of occupied molecular orbitals.","title":"nocc"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.nvir","text":"Get the number of virtual molecular orbitals. Returns: int \u2013 Number of virtual molecular orbitals.","title":"nvir"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.ip_eom","text":"Get the IP-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_GEOM \u2013 IP-EOM object. Source code in ebcc/cc/gebcc.py def ip_eom(self, **kwargs: Any) -> IP_GEOM: \"\"\"Get the IP-EOM object. Args: **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_GEOM(self, **kwargs)","title":"ip_eom"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.ea_eom","text":"Get the EA-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_GEOM \u2013 EA-EOM object. Source code in ebcc/cc/gebcc.py def ea_eom(self, **kwargs: Any) -> EA_GEOM: \"\"\"Get the EA-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_GEOM(self, **kwargs)","title":"ea_eom"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.ee_eom","text":"Get the EE-EOM object. Parameters: **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_GEOM \u2013 EE-EOM object. Source code in ebcc/cc/gebcc.py def ee_eom(self, **kwargs: Any) -> EE_GEOM: \"\"\"Get the EE-EOM object. Args: **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_GEOM(self, **kwargs)","title":"ee_eom"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.from_uebcc","text":"Initialise a GEBCC object from an UEBCC object. Parameters: ucc ( UEBCC ) \u2013 Unrestricted electron-boson coupled cluster object. Returns: GEBCC \u2013 GEBCC object. Source code in ebcc/cc/gebcc.py @classmethod def from_uebcc(cls, ucc: UEBCC) -> GEBCC: \"\"\"Initialise a `GEBCC` object from an `UEBCC` object. Args: ucc: Unrestricted electron-boson coupled cluster object. Returns: GEBCC object. \"\"\" orbspin = np.asarray(scf.addons.get_ghf_orbspin(ucc.mf.mo_energy, ucc.mf.mo_occ, False)) nocc = ucc.space[0].nocc + ucc.space[1].nocc nvir = ucc.space[0].nvir + ucc.space[1].nvir nbos = ucc.nbos sa = np.where(orbspin == 0)[0] sb = np.where(orbspin == 1)[0] occupied = np.zeros((nocc + nvir,), dtype=np.bool_) occupied = _put(occupied, sa, np.copy(ucc.space[0]._occupied)) occupied = _put(occupied, sb, np.copy(ucc.space[1]._occupied)) frozen = np.zeros((nocc + nvir,), dtype=np.bool_) frozen = _put(frozen, sa, np.copy(ucc.space[0]._frozen)) frozen = _put(frozen, sb, np.copy(ucc.space[1]._frozen)) active = np.zeros((nocc + nvir,), dtype=np.bool_) active = _put(active, sa, np.copy(ucc.space[0]._active)) active = _put(active, sb, np.copy(ucc.space[1]._active)) space = Space(occupied, frozen, active) slices = util.Namespace( a=util.Namespace(**{k: np.where(orbspin[space.mask(k)] == 0)[0] for k in \"oOivVa\"}), b=util.Namespace(**{k: np.where(orbspin[space.mask(k)] == 1)[0] for k in \"oOivVa\"}), ) g: Optional[NDArray[T]] = None if ucc.bare_g is not None: if ucc.bare_g.ndim == 3: bare_g_a = bare_g_b = ucc.bare_g else: bare_g_a, bare_g_b = ucc.bare_g g = np.zeros((ucc.nbos, ucc.nmo * 2, ucc.nmo * 2), dtype=types[float]) g = _put(g, np.ix_(np.arange(ucc.nbos), sa, sa), np.copy(bare_g_a)) g = _put(g, np.ix_(np.arange(ucc.nbos), sb, sb), np.copy(bare_g_b)) gcc = cls( ucc.mf, log=ucc.log, ansatz=ucc.ansatz, space=space, omega=ucc.omega, g=g, G=ucc.bare_G, options=ucc.options, ) gcc.e_corr = ucc.e_corr gcc.converged = ucc.converged gcc.converged_lambda = ucc.converged_lambda has_amps = bool(ucc.amplitudes) has_lams = bool(ucc.lambdas) if has_amps: amplitudes: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): shape = tuple(space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(n, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(n))): for uperm, usign in util.permutations_with_signs(tuple(range(n))): combn = util.permute_string(comb[:n], lperm) combn += util.permute_string(comb[n:], uperm) if combn in done: continue mask = np.ix_(*[slices[s][k] for s, k in zip(combn, key)]) transpose = tuple(lperm) + tuple(p + n for p in uperm) amp = ( np.transpose(getattr(ucc.amplitudes[name], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(n))): transpose = tuple(perm) + tuple(range(n, 2 * n)) if util.permute_string(comb[:n], perm) == comb[:n]: amplitudes[name] = _put( amplitudes[name], mask, amplitudes[name][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = np.copy(ucc.amplitudes[name]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): shape = (nbos,) * nb + tuple(space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(nf): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(nf))): for uperm, usign in util.permutations_with_signs(tuple(range(nf))): combn = util.permute_string(comb[:nf], lperm) combn += util.permute_string(comb[nf:], uperm) if combn in done: continue mask = np.ix_( *([np.arange(nbos)] * nb), *[slices[s][k] for s, k in zip(combn, key[nb:])], ) transpose = ( tuple(range(nb)) + tuple(p + nb for p in lperm) + tuple(p + nb + nf for p in uperm) ) amp = ( np.transpose(getattr(ucc.amplitudes[name], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(nf))): transpose = ( tuple(range(nb)) + tuple(p + nb for p in perm) + tuple(range(nb + nf, nb + 2 * nf)) ) if util.permute_string(comb[:nf], perm) == comb[:nf]: amplitudes[name] = _put( amplitudes[name], mask, amplitudes[name][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) gcc.amplitudes = amplitudes if has_lams: lambdas = gcc.init_lams() # Easier this way - but have to build ERIs... for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): lname = name.replace(\"t\", \"l\") shape = tuple(space.size(k) for k in key[n:] + key[:n]) lambdas[lname] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(n, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(n))): for uperm, usign in util.permutations_with_signs(tuple(range(n))): combn = util.permute_string(comb[:n], lperm) combn += util.permute_string(comb[n:], uperm) if combn in done: continue mask = np.ix_(*[slices[s][k] for s, k in zip(combn, key[n:] + key[:n])]) transpose = tuple(lperm) + tuple(p + n for p in uperm) amp = ( np.transpose(getattr(ucc.lambdas[lname], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(n))): transpose = tuple(perm) + tuple(range(n, 2 * n)) if util.permute_string(comb[:n], perm) == comb[:n]: lambdas[lname] = _put( lambdas[lname], mask, lambdas[lname][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = np.copy(ucc.lambdas[lname]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name shape = (nbos,) * nb + tuple( space.size(k) for k in key[nb + nf :] + key[nb : nb + nf] ) lambdas[lname] = np.zeros(shape, dtype=types[float]) for comb in util.generate_spin_combinations(nf, unique=True): done = set() for lperm, lsign in util.permutations_with_signs(tuple(range(nf))): for uperm, usign in util.permutations_with_signs(tuple(range(nf))): combn = util.permute_string(comb[:nf], lperm) combn += util.permute_string(comb[nf:], uperm) if combn in done: continue mask = np.ix_( *([np.arange(nbos)] * nb), *[ slices[s][k] for s, k in zip(combn, key[nb + nf :] + key[nb : nb + nf]) ], ) transpose = ( tuple(range(nb)) + tuple(p + nb for p in lperm) + tuple(p + nb + nf for p in uperm) ) amp = ( np.transpose(getattr(ucc.lambdas[lname], comb), transpose) * lsign * usign ) for perm, sign in util.permutations_with_signs(tuple(range(nf))): transpose = ( tuple(range(nb)) + tuple(p + nb for p in perm) + tuple(range(nb + nf, nb + 2 * nf)) ) if util.permute_string(comb[:nf], perm) == comb[:nf]: lambdas[lname] = _put( lambdas[lname], mask, lambdas[lname][mask] + np.transpose(amp, transpose) * sign, ) done.add(combn) gcc.lambdas = lambdas return gcc","title":"from_uebcc"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.from_rebcc","text":"Initialise a GEBCC object from an REBCC object. Parameters: rcc ( REBCC ) \u2013 Restricted electron-boson coupled cluster object. Returns: GEBCC \u2013 GEBCC object. Source code in ebcc/cc/gebcc.py @classmethod def from_rebcc(cls, rcc: REBCC) -> GEBCC: \"\"\"Initialise a `GEBCC` object from an `REBCC` object. Args: rcc: Restricted electron-boson coupled cluster object. Returns: GEBCC object. \"\"\" from ebcc.cc.uebcc import UEBCC ucc = UEBCC.from_rebcc(rcc) gcc = cls.from_uebcc(ucc) return gcc","title":"from_rebcc"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.init_space","text":"Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/gebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = Space( self.mo_occ > 0, np.zeros(self.mo_occ.shape, dtype=np.bool_), np.zeros(self.mo_occ.shape, dtype=np.bool_), ) return space","title":"init_space"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.init_amps","text":"Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/gebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): if n == 1: amplitudes[name] = getattr(self.fock, key) / self.energy_sum(key) elif n == 2: amplitudes[name] = getattr(eris, key) / self.energy_sum(key) else: shape = tuple(self.space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if n == 1: amplitudes[name] = self.g[key] / self.energy_sum(key) else: shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) return amplitudes","title":"init_amps"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.init_lams","text":"Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = np.transpose(amplitudes[name], perm) # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lname = \"l\" + name lambdas[lname] = amplitudes[name] # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented lname = \"l\" + name perm = list(range(nb)) + [nb + 1, nb] lambdas[lname] = np.transpose(amplitudes[name], perm) return lambdas","title":"init_lams"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.update_amps","text":"Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/gebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) res[name] += amplitudes[name] return res","title":"update_amps"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.update_lams","text":"Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) if lambdas_pert is not None: lambdas.update(lambdas_pert) func, kwargs = self._load_function( \"update_lams%s\" % (\"_perturbative\" if perturbative else \"\"), eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] if perturbative: res = Namespace(**{key + \"pert\": val for key, val in res.items()}) return res","title":"update_lams"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.make_rdm1_f","text":"Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/gebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 return dm","title":"make_rdm1_f"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.make_rdm2_f","text":"Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/gebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm","title":"make_rdm2_f"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.make_eb_coup_rdm","text":"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/gebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: SpinArrayType = func(**kwargs) if hermitise: dm_eb = np.array( [ (dm_eb[0] + np.transpose(dm_eb[1], (0, 2, 1))) * 0.5, (dm_eb[1] + np.transpose(dm_eb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f) dm_eb -= shift[None] return dm_eb","title":"make_eb_coup_rdm"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.energy_sum","text":"Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript only. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/gebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript only. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" (subscript,) = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key in subscript: factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum","title":"energy_sum"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.amplitudes_to_vector","text":"Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/gebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.vector_to_amplitudes","text":"Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/gebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.lambdas_to_vector","text":"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/gebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) return np.concatenate(vectors)","title":"lambdas_to_vector"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.vector_to_lambdas","text":"Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/gebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return lambdas","title":"vector_to_lambdas"},{"location":"reference/cc/gebcc/#ebcc.cc.gebcc.GEBCC.get_mean_field_G","text":"Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/gebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" assert self.g is not None assert self.omega is not None # FIXME should this also sum in frozen orbitals? boo: NDArray[T] = self.g.boo val = util.einsum(\"Ipp->I\", boo) val -= self.xi * self.omega if self.bare_G is not None: val += self.bare_G return val","title":"get_mean_field_G"},{"location":"reference/cc/rebcc/","text":"Restricted electron-boson coupled cluster. ebcc.cc.rebcc.REBCC(mf, log=None, ansatz='CCSD', options=None, space=None, omega=None, g=None, G=None, mo_coeff=None, mo_occ=None, fock=None, **kwargs) Bases: BaseEBCC Restricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\") ebcc.cc.rebcc.REBCC.spin_type: str property Get a string representation of the spin type. ebcc.cc.rebcc.REBCC.xi: NDArray[T] property Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators. ebcc.cc.rebcc.REBCC.nmo: int property Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals. ebcc.cc.rebcc.REBCC.nocc: int property Get the number of occupied molecular orbitals. Returns: int \u2013 Number of occupied molecular orbitals. ebcc.cc.rebcc.REBCC.nvir: int property Get the number of virtual molecular orbitals. Returns: int \u2013 Number of virtual molecular orbitals. ebcc.cc.rebcc.REBCC.ip_eom(**kwargs) Get the IP-EOM object. Parameters: options \u2013 Options for the IP-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_REOM \u2013 IP-EOM object. Source code in ebcc/cc/rebcc.py def ip_eom(self, **kwargs: Any) -> IP_REOM: \"\"\"Get the IP-EOM object. Args: options: Options for the IP-EOM calculation. **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_REOM(self, **kwargs) ebcc.cc.rebcc.REBCC.ea_eom(**kwargs) Get the EA-EOM object. Parameters: options \u2013 Options for the EA-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_REOM \u2013 EA-EOM object. Source code in ebcc/cc/rebcc.py def ea_eom(self, **kwargs: Any) -> EA_REOM: \"\"\"Get the EA-EOM object. Args: options: Options for the EA-EOM calculation. **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_REOM(self, **kwargs) ebcc.cc.rebcc.REBCC.ee_eom(**kwargs) Get the EE-EOM object. Parameters: options \u2013 Options for the EE-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_REOM \u2013 EE-EOM object. Source code in ebcc/cc/rebcc.py def ee_eom(self, **kwargs: Any) -> EE_REOM: \"\"\"Get the EE-EOM object. Args: options: Options for the EE-EOM calculation. **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_REOM(self, **kwargs) ebcc.cc.rebcc.REBCC.init_space() Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/rebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = Space( self.mo_occ > 0, np.zeros(self.mo_occ.shape, dtype=np.bool_), np.zeros(self.mo_occ.shape, dtype=np.bool_), ) return space ebcc.cc.rebcc.REBCC.init_amps(eris=None) Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/rebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): if n == 1: amplitudes[name] = self.fock[key] / self.energy_sum(key) elif n == 2: key_t = key[0] + key[2] + key[1] + key[3] amplitudes[name] = np.transpose(eris[key_t], (0, 2, 1, 3)) / self.energy_sum(key) else: shape = tuple(self.space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if nb == 1: amplitudes[name] = self.g[key] / self.energy_sum(key) else: shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) return amplitudes ebcc.cc.rebcc.REBCC.init_lams(amplitudes=None) Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = np.transpose(amplitudes[name], perm) # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lname = \"l\" + name lambdas[lname] = amplitudes[name] # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented lname = \"l\" + name perm = list(range(nb)) + [nb + 1, nb] lambdas[lname] = np.transpose(amplitudes[name], perm) return lambdas ebcc.cc.rebcc.REBCC.update_amps(eris=None, amplitudes=None) Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/rebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) res[name] += amplitudes[name] return res ebcc.cc.rebcc.REBCC.update_lams(eris=None, amplitudes=None, lambdas=None, lambdas_pert=None, perturbative=False) Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) if lambdas_pert is not None: lambdas.update(lambdas_pert) func, kwargs = self._load_function( \"update_lams%s\" % (\"_perturbative\" if perturbative else \"\"), eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] if perturbative: res = util.Namespace(**{key + \"pert\": val for key, val in res.items()}) return res ebcc.cc.rebcc.REBCC.make_rdm1_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/rebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 return dm ebcc.cc.rebcc.REBCC.make_rdm2_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/rebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm ebcc.cc.rebcc.REBCC.make_eb_coup_rdm(eris=None, amplitudes=None, lambdas=None, unshifted=True, hermitise=True) Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/rebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: NDArray[T] = func(**kwargs) if hermitise: dm_eb = np.array( [ (dm_eb[0] + np.transpose(dm_eb[1], (0, 2, 1))) * 0.5, (dm_eb[1] + np.transpose(dm_eb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f) dm_eb -= shift[None] return dm_eb ebcc.cc.rebcc.REBCC.energy_sum(*args, signs_dict=None) Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript only. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/rebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript only. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" (subscript,) = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key in subscript: factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum ebcc.cc.rebcc.REBCC.amplitudes_to_vector(amplitudes) Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/rebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) return np.concatenate(vectors) ebcc.cc.rebcc.REBCC.vector_to_amplitudes(vector) Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/rebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return amplitudes ebcc.cc.rebcc.REBCC.lambdas_to_vector(lambdas) Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/rebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) return np.concatenate(vectors) ebcc.cc.rebcc.REBCC.vector_to_lambdas(vector) Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return lambdas ebcc.cc.rebcc.REBCC.get_mean_field_G() Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/rebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" # FIXME should this also sum in frozen orbitals? assert self.omega is not None assert self.g is not None boo: NDArray[T] = self.g.boo val = util.einsum(\"Ipp->I\", boo) * 2.0 val -= self.xi * self.omega if self.bare_G is not None: val += self.bare_G return val","title":"Restricted"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC","text":"Bases: BaseEBCC Restricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\")","title":"REBCC"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.spin_type","text":"Get a string representation of the spin type.","title":"spin_type"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.xi","text":"Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators.","title":"xi"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.nmo","text":"Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals.","title":"nmo"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.nocc","text":"Get the number of occupied molecular orbitals. Returns: int \u2013 Number of occupied molecular orbitals.","title":"nocc"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.nvir","text":"Get the number of virtual molecular orbitals. Returns: int \u2013 Number of virtual molecular orbitals.","title":"nvir"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.ip_eom","text":"Get the IP-EOM object. Parameters: options \u2013 Options for the IP-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_REOM \u2013 IP-EOM object. Source code in ebcc/cc/rebcc.py def ip_eom(self, **kwargs: Any) -> IP_REOM: \"\"\"Get the IP-EOM object. Args: options: Options for the IP-EOM calculation. **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_REOM(self, **kwargs)","title":"ip_eom"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.ea_eom","text":"Get the EA-EOM object. Parameters: options \u2013 Options for the EA-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_REOM \u2013 EA-EOM object. Source code in ebcc/cc/rebcc.py def ea_eom(self, **kwargs: Any) -> EA_REOM: \"\"\"Get the EA-EOM object. Args: options: Options for the EA-EOM calculation. **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_REOM(self, **kwargs)","title":"ea_eom"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.ee_eom","text":"Get the EE-EOM object. Parameters: options \u2013 Options for the EE-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_REOM \u2013 EE-EOM object. Source code in ebcc/cc/rebcc.py def ee_eom(self, **kwargs: Any) -> EE_REOM: \"\"\"Get the EE-EOM object. Args: options: Options for the EE-EOM calculation. **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_REOM(self, **kwargs)","title":"ee_eom"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.init_space","text":"Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/rebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = Space( self.mo_occ > 0, np.zeros(self.mo_occ.shape, dtype=np.bool_), np.zeros(self.mo_occ.shape, dtype=np.bool_), ) return space","title":"init_space"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.init_amps","text":"Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/rebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): if n == 1: amplitudes[name] = self.fock[key] / self.energy_sum(key) elif n == 2: key_t = key[0] + key[2] + key[1] + key[3] amplitudes[name] = np.transpose(eris[key_t], (0, 2, 1, 3)) / self.energy_sum(key) else: shape = tuple(self.space.size(k) for k in key) amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if nb == 1: amplitudes[name] = self.g[key] / self.energy_sum(key) else: shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) amplitudes[name] = np.zeros(shape, dtype=types[float]) return amplitudes","title":"init_amps"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.init_lams","text":"Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = np.transpose(amplitudes[name], perm) # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lname = \"l\" + name lambdas[lname] = amplitudes[name] # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented lname = \"l\" + name perm = list(range(nb)) + [nb + 1, nb] lambdas[lname] = np.transpose(amplitudes[name], perm) return lambdas","title":"init_lams"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.update_amps","text":"Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/rebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key) res[name] += amplitudes[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) res[name] += amplitudes[name] return res","title":"update_amps"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.update_lams","text":"Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) if lambdas_pert is not None: lambdas.update(lambdas_pert) func, kwargs = self._load_function( \"update_lams%s\" % (\"_perturbative\" if perturbative else \"\"), eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented res[name] /= self.energy_sum(key) if not perturbative: res[name] += lambdas[name] if perturbative: res = util.Namespace(**{key + \"pert\": val for key, val in res.items()}) return res","title":"update_lams"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.make_rdm1_f","text":"Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/rebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (dm + np.transpose(dm)) * 0.5 return dm","title":"make_rdm1_f"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.make_rdm2_f","text":"Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/rebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: NDArray[T] = func(**kwargs) if hermitise: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm","title":"make_rdm2_f"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.make_eb_coup_rdm","text":"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: NDArray [ T ] \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/rebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> NDArray[T]: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: NDArray[T] = func(**kwargs) if hermitise: dm_eb = np.array( [ (dm_eb[0] + np.transpose(dm_eb[1], (0, 2, 1))) * 0.5, (dm_eb[1] + np.transpose(dm_eb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f) dm_eb -= shift[None] return dm_eb","title":"make_eb_coup_rdm"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.energy_sum","text":"Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript only. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/rebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript only. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" (subscript,) = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key in subscript: factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum","title":"energy_sum"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.amplitudes_to_vector","text":"Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/rebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.vector_to_amplitudes","text":"Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/rebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.lambdas_to_vector","text":"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/rebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): vectors.append(np.ravel(lambdas[name])) return np.concatenate(vectors)","title":"lambdas_to_vector"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.vector_to_lambdas","text":"Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/rebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): shape = (self.nbos,) * nb + tuple(self.space.size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size return lambdas","title":"vector_to_lambdas"},{"location":"reference/cc/rebcc/#ebcc.cc.rebcc.REBCC.get_mean_field_G","text":"Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/rebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" # FIXME should this also sum in frozen orbitals? assert self.omega is not None assert self.g is not None boo: NDArray[T] = self.g.boo val = util.einsum(\"Ipp->I\", boo) * 2.0 val -= self.xi * self.omega if self.bare_G is not None: val += self.bare_G return val","title":"get_mean_field_G"},{"location":"reference/cc/uebcc/","text":"Unrestricted electron-boson coupled cluster. ebcc.cc.uebcc.UEBCC(mf, log=None, ansatz='CCSD', options=None, space=None, omega=None, g=None, G=None, mo_coeff=None, mo_occ=None, fock=None, **kwargs) Bases: BaseEBCC Unrestricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\") ebcc.cc.uebcc.UEBCC.spin_type: str property Get a string representation of the spin type. ebcc.cc.uebcc.UEBCC.xi: NDArray[T] property Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators. ebcc.cc.uebcc.UEBCC.nmo: int property Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals. ebcc.cc.uebcc.UEBCC.nocc: tuple[int, int] property Get the number of occupied molecular orbitals. Returns: tuple [ int , int ] \u2013 Number of occupied molecular orbitals for each spin. ebcc.cc.uebcc.UEBCC.nvir: tuple[int, int] property Get the number of virtual molecular orbitals. Returns: tuple [ int , int ] \u2013 Number of virtual molecular orbitals for each spin. ebcc.cc.uebcc.UEBCC.ip_eom(**kwargs) Get the IP-EOM object. Parameters: options \u2013 Options for the IP-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_UEOM \u2013 IP-EOM object. Source code in ebcc/cc/uebcc.py def ip_eom(self, **kwargs: Any) -> IP_UEOM: \"\"\"Get the IP-EOM object. Args: options: Options for the IP-EOM calculation. **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_UEOM(self, **kwargs) ebcc.cc.uebcc.UEBCC.ea_eom(**kwargs) Get the EA-EOM object. Parameters: options \u2013 Options for the EA-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_UEOM \u2013 EA-EOM object. Source code in ebcc/cc/uebcc.py def ea_eom(self, **kwargs: Any) -> EA_UEOM: \"\"\"Get the EA-EOM object. Args: options: Options for the EA-EOM calculation. **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_UEOM(self, **kwargs) ebcc.cc.uebcc.UEBCC.ee_eom(**kwargs) Get the EE-EOM object. Parameters: options \u2013 Options for the EE-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_UEOM \u2013 EE-EOM object. Source code in ebcc/cc/uebcc.py def ee_eom(self, **kwargs: Any) -> EE_UEOM: \"\"\"Get the EE-EOM object. Args: options: Options for the EE-EOM calculation. **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_UEOM(self, **kwargs) ebcc.cc.uebcc.UEBCC.from_rebcc(rcc) classmethod Initialise an UEBCC object from an REBCC object. Parameters: rcc ( REBCC ) \u2013 Restricted electron-boson coupled cluster object. Returns: UEBCC \u2013 UEBCC object. Source code in ebcc/cc/uebcc.py @classmethod def from_rebcc(cls, rcc: REBCC) -> UEBCC: \"\"\"Initialise an `UEBCC` object from an `REBCC` object. Args: rcc: Restricted electron-boson coupled cluster object. Returns: UEBCC object. \"\"\" ucc = cls( rcc.mf, log=rcc.log, ansatz=rcc.ansatz, space=(rcc.space, rcc.space), omega=rcc.omega, g=rcc.bare_g, G=rcc.bare_G, options=rcc.options, ) ucc.e_corr = rcc.e_corr ucc.converged = rcc.converged ucc.converged_lambda = rcc.converged_lambda has_amps = bool(rcc.amplitudes) has_lams = bool(rcc.lambdas) if has_amps: amplitudes: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): if n > 3: # FIXME: Need to handle different RHF spin cases raise util.ModelNotImplemented( \"The conversion of amplitudes with n > 3 is not implemented.\" ) amplitudes[name] = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = rcc.amplitudes[name] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * 2 * n) amplitudes[name][comb] = tn for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = np.copy(rcc.amplitudes[name]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = util.Namespace() for comb in util.generate_spin_combinations(nf, unique=True): tn = rcc.amplitudes[name] amplitudes[name][comb] = tn ucc.amplitudes = amplitudes if has_lams: lambdas: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): lname = name.replace(\"t\", \"l\") lambdas[lname] = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = rcc.lambdas[lname] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * 2 * n) lambdas[lname][comb] = tn for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = np.copy(rcc.lambdas[lname]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = util.Namespace() for comb in util.generate_spin_combinations(nf, unique=True): tn = rcc.lambdas[lname] lambdas[lname][comb] = tn ucc.lambdas = lambdas return ucc ebcc.cc.uebcc.UEBCC.init_space() Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/uebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = ( Space( self.mo_occ[0] > 0, np.zeros(self.mo_occ[0].shape, dtype=np.bool_), np.zeros(self.mo_occ[0].shape, dtype=np.bool_), ), Space( self.mo_occ[1] > 0, np.zeros(self.mo_occ[1].shape, dtype=np.bool_), np.zeros(self.mo_occ[1].shape, dtype=np.bool_), ), ) return space ebcc.cc.uebcc.UEBCC.init_amps(eris=None) Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/uebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): tn: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): if n == 1: tn[comb] = self.fock[comb][key] / self.energy_sum(key, comb) elif n == 2: comb_t = comb[0] + comb[2] + comb[1] + comb[3] key_t = key[0] + key[2] + key[1] + key[3] tn[comb] = np.transpose(eris[comb_t][key_t], (0, 2, 1, 3)) / self.energy_sum( key, comb ) if comb in (\"aaaa\", \"bbbb\"): # TODO generalise: tn[comb] = (tn[comb] - np.transpose(tn[comb], (1, 0, 2, 3))) * 0.5 else: shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(comb, key)) tn[comb] = np.zeros(shape, dtype=types[float]) amplitudes[name] = tn # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega # type: ignore else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # type: ignore # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if nb == 1: tn = util.Namespace( aa=self.g.aa[key] / self.energy_sum(key, \"_aa\"), bb=self.g.bb[key] / self.energy_sum(key, \"_aa\"), ) amplitudes[name] = tn else: tn = util.Namespace( aa=np.zeros( (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]), dtype=types[float], ), bb=np.zeros( (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]), dtype=types[float], ), ) amplitudes[name] = tn return amplitudes ebcc.cc.uebcc.UEBCC.init_lams(amplitudes=None) Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = util.Namespace() for key in dict(amplitudes[name]).keys(): ln = np.transpose(amplitudes[name][key], perm) lambdas[lname][key] = ln # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lambdas[\"l\" + name] = amplitudes[name] # type: ignore # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented perm = list(range(nb)) + [nb + 1, nb] lambdas[\"l\" + name] = util.Namespace() for key in dict(amplitudes[name]).keys(): ln = np.transpose(amplitudes[name][key], perm) lambdas[\"l\" + name][key] = ln return lambdas ebcc.cc.uebcc.UEBCC.update_amps(eris=None, amplitudes=None) Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/uebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = res[name][comb] tn /= self.energy_sum(key, comb) tn += amplitudes[name][comb] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * (2 * n)) res[name][comb] = tn # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key, \"_\" * n) # type: ignore res[name] += amplitudes[name] # type: ignore # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented tn = res[name].aa tn /= self.energy_sum(key, \"_\" * nb + \"aa\") tn += amplitudes[name].aa res[name].aa = tn tn = res[name].bb tn /= self.energy_sum(key, \"_\" * nb + \"bb\") tn += amplitudes[name].bb res[name].bb = tn return res ebcc.cc.uebcc.UEBCC.update_lams(eris=None, amplitudes=None, lambdas=None, lambdas_pert=None, perturbative=False) Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) func, kwargs = self._load_function( \"update_lams\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, lambdas_pert=lambdas_pert, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = res[name][comb] tn /= self.energy_sum(key, comb) tn += lambdas[name][comb] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * (2 * n)) res[name][comb] = tn # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key, \"_\" * n) # type: ignore res[name] += lambdas[name] # type: ignore # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented tn = res[name].aa tn /= self.energy_sum(key, \"_\" * nb + \"aa\") tn += lambdas[name].aa res[name].aa = tn tn = res[name].bb tn /= self.energy_sum(key, \"_\" * nb + \"bb\") tn += lambdas[name].bb res[name].bb = tn return res ebcc.cc.uebcc.UEBCC.make_rdm1_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/uebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm.aa = (dm.aa + np.transpose(dm.aa)) * 0.5 dm.bb = (dm.bb + np.transpose(dm.bb)) * 0.5 return dm ebcc.cc.uebcc.UEBCC.make_rdm2_f(eris=None, amplitudes=None, lambdas=None, hermitise=True) Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/uebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: def transpose1(dm: NDArray[T]) -> NDArray[T]: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 return dm def transpose2(dm: NDArray[T]) -> NDArray[T]: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm dm.aaaa = transpose2(transpose1(dm.aaaa)) dm.aabb = transpose2(dm.aabb) dm.bbbb = transpose2(transpose1(dm.bbbb)) return dm ebcc.cc.uebcc.UEBCC.make_eb_coup_rdm(eris=None, amplitudes=None, lambdas=None, unshifted=True, hermitise=True) Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/uebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: SpinArrayType = func(**kwargs) if hermitise: dm_eb.aa = np.array( [ (dm_eb.aa[0] + np.transpose(dm_eb.aa[1], (0, 2, 1))) * 0.5, (dm_eb.aa[1] + np.transpose(dm_eb.aa[0], (0, 2, 1))) * 0.5, ] ) dm_eb.bb = np.array( [ (dm_eb.bb[0] + np.transpose(dm_eb.bb[1], (0, 2, 1))) * 0.5, (dm_eb.bb[1] + np.transpose(dm_eb.bb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f.aa) dm_eb.aa -= shift[None] shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f.bb) dm_eb.bb -= shift[None] return dm_eb ebcc.cc.uebcc.UEBCC.energy_sum(*args, signs_dict=None) Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript and spins. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/uebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript and spins. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" subscript, spins = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key, spin in zip(subscript, spins): factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[spin + spin][key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum ebcc.cc.uebcc.UEBCC.amplitudes_to_vector(amplitudes) Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/uebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for spin in util.generate_spin_combinations(n, unique=True): tn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, tn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) # type: ignore for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented vectors.append(np.ravel(amplitudes[name].aa)) vectors.append(np.ravel(amplitudes[name].bb)) return np.concatenate(vectors) ebcc.cc.uebcc.UEBCC.vector_to_amplitudes(vector) Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/uebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): amplitudes[name] = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) tn_tril = vector[i0 : i0 + size] tn = util.decompress_axes(subscript, tn_tril, shape=shape) amplitudes[name][spin] = tn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = self.nbos**n amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) # type: ignore i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented amplitudes[name] = util.Namespace() shape = (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name].aa = np.reshape(vector[i0 : i0 + size], shape) i0 += size shape = (self.nbos,) * nb + tuple(self.space[1].size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name].bb = np.reshape(vector[i0 : i0 + size], shape) i0 += size assert i0 == len(vector) return amplitudes ebcc.cc.uebcc.UEBCC.lambdas_to_vector(lambdas) Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/uebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): for spin in util.generate_spin_combinations(n, unique=True): tn = lambdas[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, tn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) # type: ignore for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented vectors.append(np.ravel(lambdas[name].aa)) vectors.append(np.ravel(lambdas[name].bb)) return np.concatenate(vectors) ebcc.cc.uebcc.UEBCC.vector_to_lambdas(vector) Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): lambdas[name] = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) tn_tril = vector[i0 : i0 + size] tn = util.decompress_axes(subscript, tn_tril, shape=shape) lambdas[name][spin] = tn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = self.nbos**n lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) # type: ignore i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented lambdas[name] = util.Namespace() shape = (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name].aa = np.reshape(vector[i0 : i0 + size], shape) i0 += size shape = (self.nbos,) * nb + tuple(self.space[1].size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name].bb = np.reshape(vector[i0 : i0 + size], shape) i0 += size assert i0 == len(vector) return lambdas ebcc.cc.uebcc.UEBCC.get_mean_field_G() Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/uebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" # FIXME should this also sum in frozen orbitals? assert self.omega is not None assert self.g is not None boo: tuple[NDArray[T], NDArray[T]] = (self.g.aa.boo, self.g.bb.boo) val = util.einsum(\"Ipp->I\", boo[0]) val += util.einsum(\"Ipp->I\", boo[1]) val -= self.xi * self.omega if self.bare_G is not None: # Require bare_G to have a spin index for now: assert self.bare_G.shape == val.shape val += self.bare_G return val","title":"Unrestricted"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC","text":"Bases: BaseEBCC Unrestricted electron-boson coupled cluster. Initialise the EBCC object. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. log ( Optional [ Logger ] , default: None ) \u2013 Log to write output to. Default is the global logger, outputting to stderr . ansatz ( Optional [ Union [ Ansatz , str ]] , default: 'CCSD' ) \u2013 Overall ansatz. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EBCC calculation. space ( Optional [ SpaceType ] , default: None ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega ( Optional [ NDArray [ T ]] , default: None ) \u2013 Bosonic frequencies. g ( Optional [ NDArray [ T ]] , default: None ) \u2013 Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math: g_{bpq} p^\\dagger q b . The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G ( Optional [ NDArray [ T ]] , default: None ) \u2013 Boson non-conserving term :math: G_{b} (b^\\dagger + b) . mo_coeff ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ ( Optional [ NDArray [ T ]] , default: None ) \u2013 Molecular orbital occupation numbers. Default is the mean-field occupation. fock ( Optional [ BaseFock ] , default: None ) \u2013 Fock matrix. Default is the mean-field Fock matrix. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/cc/base.py def __init__( self, mf: SCF, log: Optional[Logger] = None, ansatz: Optional[Union[Ansatz, str]] = \"CCSD\", options: Optional[BaseOptions] = None, space: Optional[SpaceType] = None, omega: Optional[NDArray[T]] = None, g: Optional[NDArray[T]] = None, G: Optional[NDArray[T]] = None, mo_coeff: Optional[NDArray[T]] = None, mo_occ: Optional[NDArray[T]] = None, fock: Optional[BaseFock] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the EBCC object. Args: mf: PySCF mean-field object. log: Log to write output to. Default is the global logger, outputting to `stderr`. ansatz: Overall ansatz. options: Options for the EBCC calculation. space: Space containing the frozen, correlated, and active fermionic spaces. Default assumes all electrons are correlated. omega: Bosonic frequencies. g: Electron-boson coupling matrix corresponding to the bosonic annihilation operator :math:`g_{bpq} p^\\dagger q b`. The creation part is assumed to be the fermionic conjugate transpose to retain Hermiticity in the Hamiltonian. G: Boson non-conserving term :math:`G_{b} (b^\\dagger + b)`. mo_coeff: Molecular orbital coefficients. Default is the mean-field coefficients. mo_occ: Molecular orbital occupation numbers. Default is the mean-field occupation. fock: Fock matrix. Default is the mean-field Fock matrix. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.log = default_log if log is None else log self.mf = self._convert_mf(mf) self._mo_coeff: Optional[NDArray[T]] = ( np.asarray(mo_coeff, dtype=types[float]) if mo_coeff is not None else None ) self._mo_occ: Optional[NDArray[T]] = ( np.asarray(mo_occ, dtype=types[float]) if mo_occ is not None else None ) # Ansatz: if isinstance(ansatz, Ansatz): self.ansatz = ansatz elif isinstance(ansatz, str): self.ansatz = Ansatz.from_string( ansatz, density_fitting=getattr(self.mf, \"with_df\", None) is not None ) else: raise TypeError(\"ansatz must be an Ansatz object or a string.\") self._eqns = self.ansatz._get_eqns(self.spin_type) # Space: if space is not None: self.space = space else: self.space = self.init_space() # Boson parameters: if bool(self.fermion_coupling_rank) != bool(self.boson_coupling_rank): raise ValueError( \"Fermionic and bosonic coupling ranks must both be zero, or both non-zero.\" ) self.omega = np.asarray(omega, dtype=types[float]) if omega is not None else None self.bare_g = np.asarray(g, dtype=types[float]) if g is not None else None self.bare_G = np.asarray(G, dtype=types[float]) if G is not None else None if self.boson_ansatz != \"\": self.g = self.get_g() self.G = self.get_mean_field_G() else: assert self.nbos == 0 self.options.shift = False self.g = None self.G = None # Fock matrix: if fock is None: self.fock = self.get_fock() else: self.fock = fock # Attributes: self.e_corr = 0.0 self.amplitudes = util.Namespace() self.converged = False self.lambdas = util.Namespace() self.converged_lambda = False # Logging: init_logging(self.log) self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") self.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") self.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Ansatz{ANSI.R}: {ANSI.m}{self.ansatz}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Space{ANSI.R}: {ANSI.m}{self.space}{ANSI.R}\") self.log.debug(\"\") if self.boson_ansatz != \"\": self.log.info(f\"{ANSI.B}Bosons{ANSI.R}: {ANSI.m}{self.nbos}{ANSI.R}\") self.log.info(\" > Energy shift due to polaritonic basis: %.10f\", self.const) self.log.debug(\"\")","title":"UEBCC"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.spin_type","text":"Get a string representation of the spin type.","title":"spin_type"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.xi","text":"Get the shift in the bosonic operators to diagonalise the photon Hamiltonian. Returns: NDArray [ T ] \u2013 Shift in the bosonic operators.","title":"xi"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.nmo","text":"Get the number of molecular orbitals. Returns: int \u2013 Number of molecular orbitals.","title":"nmo"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.nocc","text":"Get the number of occupied molecular orbitals. Returns: tuple [ int , int ] \u2013 Number of occupied molecular orbitals for each spin.","title":"nocc"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.nvir","text":"Get the number of virtual molecular orbitals. Returns: tuple [ int , int ] \u2013 Number of virtual molecular orbitals for each spin.","title":"nvir"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.ip_eom","text":"Get the IP-EOM object. Parameters: options \u2013 Options for the IP-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: IP_UEOM \u2013 IP-EOM object. Source code in ebcc/cc/uebcc.py def ip_eom(self, **kwargs: Any) -> IP_UEOM: \"\"\"Get the IP-EOM object. Args: options: Options for the IP-EOM calculation. **kwargs: Additional keyword arguments. Returns: IP-EOM object. \"\"\" return IP_UEOM(self, **kwargs)","title":"ip_eom"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.ea_eom","text":"Get the EA-EOM object. Parameters: options \u2013 Options for the EA-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EA_UEOM \u2013 EA-EOM object. Source code in ebcc/cc/uebcc.py def ea_eom(self, **kwargs: Any) -> EA_UEOM: \"\"\"Get the EA-EOM object. Args: options: Options for the EA-EOM calculation. **kwargs: Additional keyword arguments. Returns: EA-EOM object. \"\"\" return EA_UEOM(self, **kwargs)","title":"ea_eom"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.ee_eom","text":"Get the EE-EOM object. Parameters: options \u2013 Options for the EE-EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments. Returns: EE_UEOM \u2013 EE-EOM object. Source code in ebcc/cc/uebcc.py def ee_eom(self, **kwargs: Any) -> EE_UEOM: \"\"\"Get the EE-EOM object. Args: options: Options for the EE-EOM calculation. **kwargs: Additional keyword arguments. Returns: EE-EOM object. \"\"\" return EE_UEOM(self, **kwargs)","title":"ee_eom"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.from_rebcc","text":"Initialise an UEBCC object from an REBCC object. Parameters: rcc ( REBCC ) \u2013 Restricted electron-boson coupled cluster object. Returns: UEBCC \u2013 UEBCC object. Source code in ebcc/cc/uebcc.py @classmethod def from_rebcc(cls, rcc: REBCC) -> UEBCC: \"\"\"Initialise an `UEBCC` object from an `REBCC` object. Args: rcc: Restricted electron-boson coupled cluster object. Returns: UEBCC object. \"\"\" ucc = cls( rcc.mf, log=rcc.log, ansatz=rcc.ansatz, space=(rcc.space, rcc.space), omega=rcc.omega, g=rcc.bare_g, G=rcc.bare_G, options=rcc.options, ) ucc.e_corr = rcc.e_corr ucc.converged = rcc.converged ucc.converged_lambda = rcc.converged_lambda has_amps = bool(rcc.amplitudes) has_lams = bool(rcc.lambdas) if has_amps: amplitudes: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): if n > 3: # FIXME: Need to handle different RHF spin cases raise util.ModelNotImplemented( \"The conversion of amplitudes with n > 3 is not implemented.\" ) amplitudes[name] = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = rcc.amplitudes[name] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * 2 * n) amplitudes[name][comb] = tn for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = np.copy(rcc.amplitudes[name]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): amplitudes[name] = util.Namespace() for comb in util.generate_spin_combinations(nf, unique=True): tn = rcc.amplitudes[name] amplitudes[name][comb] = tn ucc.amplitudes = amplitudes if has_lams: lambdas: Namespace[SpinArrayType] = util.Namespace() for name, key, n in ucc.ansatz.fermionic_cluster_ranks(spin_type=ucc.spin_type): lname = name.replace(\"t\", \"l\") lambdas[lname] = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = rcc.lambdas[lname] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * 2 * n) lambdas[lname][comb] = tn for name, key, n in ucc.ansatz.bosonic_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = np.copy(rcc.lambdas[lname]) # type: ignore for name, key, nf, nb in ucc.ansatz.coupling_cluster_ranks(spin_type=ucc.spin_type): lname = \"l\" + name lambdas[lname] = util.Namespace() for comb in util.generate_spin_combinations(nf, unique=True): tn = rcc.lambdas[lname] lambdas[lname][comb] = tn ucc.lambdas = lambdas return ucc","title":"from_rebcc"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.init_space","text":"Initialise the fermionic space. Returns: SpaceType \u2013 Fermionic space. All fermionic degrees of freedom are assumed to be correlated. Source code in ebcc/cc/uebcc.py def init_space(self) -> SpaceType: \"\"\"Initialise the fermionic space. Returns: Fermionic space. All fermionic degrees of freedom are assumed to be correlated. \"\"\" space = ( Space( self.mo_occ[0] > 0, np.zeros(self.mo_occ[0].shape, dtype=np.bool_), np.zeros(self.mo_occ[0].shape, dtype=np.bool_), ), Space( self.mo_occ[1] > 0, np.zeros(self.mo_occ[1].shape, dtype=np.bool_), np.zeros(self.mo_occ[1].shape, dtype=np.bool_), ), ) return space","title":"init_space"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.init_amps","text":"Initialise the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster amplitudes. Source code in ebcc/cc/uebcc.py def init_amps(self, eris: Optional[ERIsInputType] = None) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster amplitudes. Args: eris: Electron repulsion integrals. Returns: Initial cluster amplitudes. \"\"\" eris = self.get_eris(eris) amplitudes: Namespace[SpinArrayType] = util.Namespace() # Build T amplitudes for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): tn: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): if n == 1: tn[comb] = self.fock[comb][key] / self.energy_sum(key, comb) elif n == 2: comb_t = comb[0] + comb[2] + comb[1] + comb[3] key_t = key[0] + key[2] + key[1] + key[3] tn[comb] = np.transpose(eris[comb_t][key_t], (0, 2, 1, 3)) / self.energy_sum( key, comb ) if comb in (\"aaaa\", \"bbbb\"): # TODO generalise: tn[comb] = (tn[comb] - np.transpose(tn[comb], (1, 0, 2, 3))) * 0.5 else: shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(comb, key)) tn[comb] = np.zeros(shape, dtype=types[float]) amplitudes[name] = tn # Build S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.G is None: raise ValueError(\"Bosonic parameters not set.\") if n == 1: amplitudes[name] = -self.G / self.omega # type: ignore else: shape = (self.nbos,) * n amplitudes[name] = np.zeros(shape, dtype=types[float]) # type: ignore # Build U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if self.omega is None or self.g is None: raise ValueError(\"Bosonic parameters not set.\") if nf != 1: raise util.ModelNotImplemented if nb == 1: tn = util.Namespace( aa=self.g.aa[key] / self.energy_sum(key, \"_aa\"), bb=self.g.bb[key] / self.energy_sum(key, \"_aa\"), ) amplitudes[name] = tn else: tn = util.Namespace( aa=np.zeros( (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]), dtype=types[float], ), bb=np.zeros( (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]), dtype=types[float], ), ) amplitudes[name] = tn return amplitudes","title":"init_amps"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.init_lams","text":"Initialise the cluster lambda amplitudes. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Initial cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def init_lams( self, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Initialise the cluster lambda amplitudes. Args: amplitudes: Cluster amplitudes. Returns: Initial cluster lambda amplitudes. \"\"\" if not amplitudes: amplitudes = self.amplitudes lambdas: Namespace[SpinArrayType] = util.Namespace() # Build L amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): lname = name.replace(\"t\", \"l\") perm = list(range(n, 2 * n)) + list(range(n)) lambdas[lname] = util.Namespace() for key in dict(amplitudes[name]).keys(): ln = np.transpose(amplitudes[name][key], perm) lambdas[lname][key] = ln # Build LS amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): lambdas[\"l\" + name] = amplitudes[name] # type: ignore # Build LU amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented perm = list(range(nb)) + [nb + 1, nb] lambdas[\"l\" + name] = util.Namespace() for key in dict(amplitudes[name]).keys(): ln = np.transpose(amplitudes[name][key], perm) lambdas[\"l\" + name][key] = ln return lambdas","title":"init_lams"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.update_amps","text":"Update the cluster amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster amplitudes. Source code in ebcc/cc/uebcc.py def update_amps( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. Returns: Updated cluster amplitudes. \"\"\" amplitudes = self._get_amps(amplitudes=amplitudes) func, kwargs = self._load_function( \"update_amps\", eris=eris, amplitudes=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = res[name][comb] tn /= self.energy_sum(key, comb) tn += amplitudes[name][comb] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * (2 * n)) res[name][comb] = tn # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): res[name] /= self.energy_sum(key, \"_\" * n) # type: ignore res[name] += amplitudes[name] # type: ignore # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented tn = res[name].aa tn /= self.energy_sum(key, \"_\" * nb + \"aa\") tn += amplitudes[name].aa res[name].aa = tn tn = res[name].bb tn /= self.energy_sum(key, \"_\" * nb + \"bb\") tn += amplitudes[name].bb res[name].bb = tn return res","title":"update_amps"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.update_lams","text":"Update the cluster lambda amplitudes. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. lambdas_pert ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Perturbative cluster lambda amplitudes. perturbative ( bool , default: False ) \u2013 Flag to include perturbative correction. Returns: Namespace [ SpinArrayType ] \u2013 Updated cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def update_lams( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, lambdas_pert: Optional[Namespace[SpinArrayType]] = None, perturbative: bool = False, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster lambda amplitudes. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. lambdas_pert: Perturbative cluster lambda amplitudes. perturbative: Flag to include perturbative correction. Returns: Updated cluster lambda amplitudes. \"\"\" # TODO active amplitudes = self._get_amps(amplitudes=amplitudes) lambdas = self._get_lams(lambdas=lambdas, amplitudes=amplitudes) func, kwargs = self._load_function( \"update_lams\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, lambdas_pert=lambdas_pert, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) # Divide T amplitudes: for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): for comb in util.generate_spin_combinations(n, unique=True): subscript, _ = util.combine_subscripts(key, comb) tn = res[name][comb] tn /= self.energy_sum(key, comb) tn += lambdas[name][comb] tn = util.symmetrise(subscript, tn, symmetry=\"-\" * (2 * n)) res[name][comb] = tn # Divide S amplitudes: for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): res[name] /= self.energy_sum(key, \"_\" * n) # type: ignore res[name] += lambdas[name] # type: ignore # Divide U amplitudes: for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented tn = res[name].aa tn /= self.energy_sum(key, \"_\" * nb + \"aa\") tn += lambdas[name].aa res[name].aa = tn tn = res[name].bb tn /= self.energy_sum(key, \"_\" * nb + \"bb\") tn += lambdas[name].bb res[name].bb = tn return res","title":"update_lams"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.make_rdm1_f","text":"Make the one-particle fermionic reduced density matrix :math: \\langle i^+ j \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 One-particle fermion reduced density matrix. Source code in ebcc/cc/uebcc.py def make_rdm1_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the one-particle fermionic reduced density matrix :math:`\\langle i^+ j \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: One-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm1_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: dm.aa = (dm.aa + np.transpose(dm.aa)) * 0.5 dm.bb = (dm.bb + np.transpose(dm.bb)) * 0.5 return dm","title":"make_rdm1_f"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.make_rdm2_f","text":"Make the two-particle fermionic reduced density matrix :math: \\langle i^+j^+lk \\rangle . Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Two-particle fermion reduced density matrix. Source code in ebcc/cc/uebcc.py def make_rdm2_f( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the two-particle fermionic reduced density matrix :math:`\\langle i^+j^+lk \\rangle`. Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. hermitise: Hermitise the density matrix. Returns: Two-particle fermion reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_rdm2_f\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm: SpinArrayType = func(**kwargs) if hermitise: def transpose1(dm: NDArray[T]) -> NDArray[T]: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (2, 3, 0, 1))) * 0.5 return dm def transpose2(dm: NDArray[T]) -> NDArray[T]: dm = (np.transpose(dm, (0, 1, 2, 3)) + np.transpose(dm, (1, 0, 3, 2))) * 0.5 return dm dm.aaaa = transpose2(transpose1(dm.aaaa)) dm.aabb = transpose2(dm.aabb) dm.bbbb = transpose2(transpose1(dm.bbbb)) return dm","title":"make_rdm2_f"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.make_eb_coup_rdm","text":"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electron repulsion integrals. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. lambdas ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster lambda amplitudes. unshifted ( bool , default: True ) \u2013 If self.options.shift is True , return the unshifted density matrix. Has no effect if self.options.shift is False . hermitise ( bool , default: True ) \u2013 Hermitise the density matrix. Returns: SpinArrayType \u2013 Electron-boson coupling reduced density matrix. Source code in ebcc/cc/uebcc.py def make_eb_coup_rdm( self, eris: Optional[ERIsInputType] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, lambdas: Optional[Namespace[SpinArrayType]] = None, unshifted: bool = True, hermitise: bool = True, ) -> SpinArrayType: r\"\"\"Make the electron-boson coupling reduced density matrix. .. math:: \\langle b^+ i^+ j \\rangle and .. math:: \\langle b i^+ j \\rangle Args: eris: Electron repulsion integrals. amplitudes: Cluster amplitudes. lambdas: Cluster lambda amplitudes. unshifted: If `self.options.shift` is `True`, return the unshifted density matrix. Has no effect if `self.options.shift` is `False`. hermitise: Hermitise the density matrix. Returns: Electron-boson coupling reduced density matrix. \"\"\" func, kwargs = self._load_function( \"make_eb_coup_rdm\", eris=eris, amplitudes=amplitudes, lambdas=lambdas, ) dm_eb: SpinArrayType = func(**kwargs) if hermitise: dm_eb.aa = np.array( [ (dm_eb.aa[0] + np.transpose(dm_eb.aa[1], (0, 2, 1))) * 0.5, (dm_eb.aa[1] + np.transpose(dm_eb.aa[0], (0, 2, 1))) * 0.5, ] ) dm_eb.bb = np.array( [ (dm_eb.bb[0] + np.transpose(dm_eb.bb[1], (0, 2, 1))) * 0.5, (dm_eb.bb[1] + np.transpose(dm_eb.bb[0], (0, 2, 1))) * 0.5, ] ) if unshifted and self.options.shift: rdm1_f = self.make_rdm1_f(hermitise=hermitise) shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f.aa) dm_eb.aa -= shift[None] shift = util.einsum(\"x,ij->xij\", self.xi, rdm1_f.bb) dm_eb.bb -= shift[None] return dm_eb","title":"make_eb_coup_rdm"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.energy_sum","text":"Get a direct sum of energies. Parameters: *args ( str , default: () ) \u2013 Energies to sum. Should specify a subscript and spins. signs_dict ( Optional [ dict [ str , str ]] , default: None ) \u2013 Signs of the energies in the sum. Default sets (\"o\", \"O\", \"i\") to be positive, and (\"v\", \"V\", \"a\", \"b\") to be negative. Returns: NDArray [ T ] \u2013 Sum of energies. Source code in ebcc/cc/uebcc.py def energy_sum(self, *args: str, signs_dict: Optional[dict[str, str]] = None) -> NDArray[T]: \"\"\"Get a direct sum of energies. Args: *args: Energies to sum. Should specify a subscript and spins. signs_dict: Signs of the energies in the sum. Default sets `(\"o\", \"O\", \"i\")` to be positive, and `(\"v\", \"V\", \"a\", \"b\")` to be negative. Returns: Sum of energies. \"\"\" subscript, spins = args n = 0 def next_char() -> str: nonlocal n if n < 26: char = chr(ord(\"a\") + n) else: char = chr(ord(\"A\") + n) n += 1 return char if signs_dict is None: signs_dict = {} for k, s in zip(\"vVaoOib\", \"---+++-\"): if k not in signs_dict: signs_dict[k] = s energies = [] for key, spin in zip(subscript, spins): factor = 1 if signs_dict[key] == \"+\" else -1 if key == \"b\": assert self.omega is not None energies.append(self.omega * types[float](factor)) else: energies.append(np.diag(self.fock[spin + spin][key + key]) * types[float](factor)) subscript = \",\".join([next_char() for k in subscript]) energy_sum = util.dirsum(subscript, *energies) return energy_sum","title":"energy_sum"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.amplitudes_to_vector","text":"Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/cc/uebcc.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for spin in util.generate_spin_combinations(n, unique=True): tn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, tn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): vectors.append(np.ravel(amplitudes[name])) # type: ignore for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented vectors.append(np.ravel(amplitudes[name].aa)) vectors.append(np.ravel(amplitudes[name].bb)) return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.vector_to_amplitudes","text":"Construct a namespace of amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/cc/uebcc.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): amplitudes[name] = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) tn_tril = vector[i0 : i0 + size] tn = util.decompress_axes(subscript, tn_tril, shape=shape) amplitudes[name][spin] = tn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): shape = (self.nbos,) * n size = self.nbos**n amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) # type: ignore i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): if nf != 1: raise util.ModelNotImplemented amplitudes[name] = util.Namespace() shape = (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name].aa = np.reshape(vector[i0 : i0 + size], shape) i0 += size shape = (self.nbos,) * nb + tuple(self.space[1].size(k) for k in key[nb:]) size = util.prod(shape) amplitudes[name].bb = np.reshape(vector[i0 : i0 + size], shape) i0 += size assert i0 == len(vector) return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.lambdas_to_vector","text":"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Parameters: lambdas ( Namespace [ SpinArrayType ] ) \u2013 Cluster lambda amplitudes. Returns: NDArray [ T ] \u2013 Cluster lambda amplitudes as a vector. Source code in ebcc/cc/uebcc.py def lambdas_to_vector(self, lambdas: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the lambda amplitudes used in the given ansatz. Args: lambdas: Cluster lambda amplitudes. Returns: Cluster lambda amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): for spin in util.generate_spin_combinations(n, unique=True): tn = lambdas[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, tn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): vectors.append(np.ravel(lambdas[name])) # type: ignore for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented vectors.append(np.ravel(lambdas[name].aa)) vectors.append(np.ravel(lambdas[name].bb)) return np.concatenate(vectors)","title":"lambdas_to_vector"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.vector_to_lambdas","text":"Construct a namespace of lambda amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster lambda amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster lambda amplitudes. Source code in ebcc/cc/uebcc.py def vector_to_lambdas(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of lambda amplitudes from a vector. Args: vector: Cluster lambda amplitudes as a vector. Returns: Cluster lambda amplitudes. \"\"\" lambdas: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): lambdas[name] = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) tn_tril = vector[i0 : i0 + size] tn = util.decompress_axes(subscript, tn_tril, shape=shape) lambdas[name][spin] = tn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"l\"): shape = (self.nbos,) * n size = self.nbos**n lambdas[name] = np.reshape(vector[i0 : i0 + size], shape) # type: ignore i0 += size for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"l\" ): if nf != 1: raise util.ModelNotImplemented lambdas[name] = util.Namespace() shape = (self.nbos,) * nb + tuple(self.space[0].size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name].aa = np.reshape(vector[i0 : i0 + size], shape) i0 += size shape = (self.nbos,) * nb + tuple(self.space[1].size(k) for k in key[nb:]) size = util.prod(shape) lambdas[name].bb = np.reshape(vector[i0 : i0 + size], shape) i0 += size assert i0 == len(vector) return lambdas","title":"vector_to_lambdas"},{"location":"reference/cc/uebcc/#ebcc.cc.uebcc.UEBCC.get_mean_field_G","text":"Get the mean-field boson non-conserving term. Returns: NDArray [ T ] \u2013 Mean-field boson non-conserving term. Source code in ebcc/cc/uebcc.py def get_mean_field_G(self) -> NDArray[T]: \"\"\"Get the mean-field boson non-conserving term. Returns: Mean-field boson non-conserving term. \"\"\" # FIXME should this also sum in frozen orbitals? assert self.omega is not None assert self.g is not None boo: tuple[NDArray[T], NDArray[T]] = (self.g.aa.boo, self.g.bb.boo) val = util.einsum(\"Ipp->I\", boo[0]) val += util.einsum(\"Ipp->I\", boo[1]) val -= self.xi * self.omega if self.bare_G is not None: # Require bare_G to have a spin index for now: assert self.bare_G.shape == val.shape val += self.bare_G return val","title":"get_mean_field_G"},{"location":"reference/core/","text":"Core functionality.","title":"Index"},{"location":"reference/core/ansatz/","text":"Ansatz definition. ebcc.core.ansatz.Ansatz(fermion_ansatz='CCSD', boson_ansatz='', fermion_coupling_rank=0, boson_coupling_rank=0, density_fitting=False, module_name=None) Ansatz class. Initialise the ansatz. Parameters: fermion_ansatz ( str , default: 'CCSD' ) \u2013 Fermionic ansatz. boson_ansatz ( str , default: '' ) \u2013 Rank of bosonic excitations. fermion_coupling_rank ( int , default: 0 ) \u2013 Rank of fermionic term in coupling. boson_coupling_rank ( int , default: 0 ) \u2013 Rank of bosonic term in coupling. density_fitting ( bool , default: False ) \u2013 Use density fitting. module_name ( Optional [ str ] , default: None ) \u2013 Name of the module containing the generated equations. Source code in ebcc/core/ansatz.py def __init__( self, fermion_ansatz: str = \"CCSD\", boson_ansatz: str = \"\", fermion_coupling_rank: int = 0, boson_coupling_rank: int = 0, density_fitting: bool = False, module_name: Optional[str] = None, ) -> None: \"\"\"Initialise the ansatz. Args: fermion_ansatz: Fermionic ansatz. boson_ansatz: Rank of bosonic excitations. fermion_coupling_rank: Rank of fermionic term in coupling. boson_coupling_rank: Rank of bosonic term in coupling. density_fitting: Use density fitting. module_name: Name of the module containing the generated equations. \"\"\" self.fermion_ansatz = fermion_ansatz self.boson_ansatz = boson_ansatz self.fermion_coupling_rank = fermion_coupling_rank self.boson_coupling_rank = boson_coupling_rank self.density_fitting = density_fitting self.module_name = module_name ebcc.core.ansatz.Ansatz.name: str property Get the name of the ansatz. ebcc.core.ansatz.Ansatz.has_perturbative_correction: bool property Get a boolean indicating if the ansatz includes a perturbative correction e.g. CCSD(T). Returns: perturbative ( bool ) \u2013 Boolean indicating if the ansatz is perturbatively corrected. ebcc.core.ansatz.Ansatz.is_one_shot: bool property Get a boolean indicating whether the ansatz is a one-shot energy calculation e.g. MP2. Returns: one_shot ( bool ) \u2013 Boolean indicating if the ansatz is a one-shot energy calculation. ebcc.core.ansatz.Ansatz.from_string(string, density_fitting=False) classmethod Build an Ansatz from a string for the default ansatzes. Parameters: string ( str ) \u2013 Input string. density_fitting ( bool , default: False ) \u2013 Use density fitting. Returns: Ansatz \u2013 Ansatz object. Source code in ebcc/core/ansatz.py @classmethod def from_string(cls, string: str, density_fitting: bool = False) -> Ansatz: \"\"\"Build an `Ansatz` from a string for the default ansatzes. Args: string: Input string. density_fitting: Use density fitting. Returns: Ansatz object. \"\"\" if string not in named_ansatzes: raise util.ModelNotImplemented(string) return cls(*named_ansatzes[string], density_fitting=density_fitting) ebcc.core.ansatz.Ansatz.__repr__() Get a string with the name of the method. Source code in ebcc/core/ansatz.py def __repr__(self) -> str: \"\"\"Get a string with the name of the method.\"\"\" name = \"\" if self.density_fitting: name += \"DF\" name += self.fermion_ansatz if self.boson_ansatz: name += \"-%s\" % self.boson_ansatz if self.fermion_coupling_rank or self.boson_coupling_rank: name += \"-%d\" % self.fermion_coupling_rank name += \"-%d\" % self.boson_coupling_rank return name ebcc.core.ansatz.Ansatz.fermionic_cluster_ranks(spin_type='G', which='t') Get a list of cluster operator ranks for the fermionic space. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator to return. Returns: list [ tuple [ str , str , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def fermionic_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int]]: \"\"\"Get a list of cluster operator ranks for the fermionic space. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator to return. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" ranks: list[tuple[str, str, int]] = [] if not self.fermion_ansatz: return ranks def _adapt_key(key: str) -> str: \"\"\"Adapt the key to the `which` argument.\"\"\" if which == \"ip\": return key[:-1] if which == \"ea\": n = len(key) // 2 key = key[n:] + key[: n - 1] if which == \"l\": n = len(key) // 2 key = key[n:] + key[:n] return key symbol = which if which in (\"t\", \"l\") else \"r\" notations = { \"S\": [(f\"{symbol}1\", _adapt_key(\"ov\"), 1)], \"D\": [(f\"{symbol}2\", _adapt_key(\"oovv\"), 2)], \"T\": [(f\"{symbol}3\", _adapt_key(\"ooovvv\"), 3)], \"t\": [(f\"{symbol}3\", _adapt_key(\"ooOvvV\"), 3)], \"t'\": [(f\"{symbol}3\", _adapt_key(\"OOOVVV\"), 3)], } if spin_type == \"R\": notations[\"Q\"] = [(f\"{symbol}4a\", \"oooovvvv\", 4), (f\"{symbol}4b\", \"oooovvvv\", 4)] else: notations[\"Q\"] = [(f\"{symbol}4\", \"oooovvvv\", 4)] notations[\"2\"] = notations[\"S\"] + notations[\"D\"] notations[\"3\"] = notations[\"2\"] + notations[\"T\"] notations[\"4\"] = notations[\"3\"] + notations[\"Q\"] # Remove any perturbative corrections op = self.fermion_ansatz while \"(\" in op: start = op.index(\"(\") end = op.index(\")\") op = op[:start] if (end + 1) < len(op): op += op[end + 1 :] # Check in order of longest to shortest string in case one # method name starts with a substring equal to the name of # another method for method_type in sorted(METHOD_TYPES, key=len)[::-1]: if op.startswith(method_type): op = op.replace(method_type, \"\", 1) break # If it's MP we only ever need to initialise second-order # amplitudes if method_type == \"MP\" and which in (\"t\", \"l\"): op = \"D\" # If it's for EOM-CCD we still need the singles if self.fermion_ansatz == \"CCD\" and which in (\"ip\", \"ea\", \"ee\"): op = \"SD\" # Determine the ranks for key in sorted(notations.keys(), key=len)[::-1]: if key in op: ranks += notations[key] op = op.replace(key, \"\") # Check there are no duplicates if len(ranks) != len(set(ranks)): raise util.ModelNotImplemented(\"Duplicate ranks in %s\" % self.fermion_ansatz) # Sort the ranks by the cluster operator dimension ranks = sorted(ranks, key=lambda x: x[2]) return ranks ebcc.core.ansatz.Ansatz.bosonic_cluster_ranks(spin_type='G', which='t') Get a list of cluster operator ranks for the bosonic space. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator. Returns: list [ tuple [ str , str , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def bosonic_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int]]: \"\"\"Get a list of cluster operator ranks for the bosonic space. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" ranks: list[tuple[str, str, int]] = [] if not self.boson_ansatz: return ranks symbol = \"s\" if which == \"t\" else \"ls\" notations = { \"S\": [(f\"{symbol}1\", \"b\", 1)], \"D\": [(f\"{symbol}2\", \"bb\", 2)], \"T\": [(f\"{symbol}3\", \"bbb\", 3)], } notations[\"2\"] = notations[\"S\"] + notations[\"D\"] notations[\"3\"] = notations[\"2\"] + notations[\"T\"] # Remove any perturbative corrections op = self.boson_ansatz while \"(\" in op: start = op.index(\"(\") end = op.index(\")\") op = op[:start] if (end + 1) < len(op): op += op[end + 1 :] # Determine the ranks for key in sorted(notations.keys(), key=len)[::-1]: if key in op: ranks += notations[key] op = op.replace(key, \"\") # Check there are no duplicates if len(ranks) != len(set(ranks)): raise util.ModelNotImplemented(\"Duplicate ranks in %s\" % self.boson_ansatz) # Sort the ranks by the cluster operator dimension ranks = sorted(ranks, key=lambda x: x[2]) return ranks ebcc.core.ansatz.Ansatz.coupling_cluster_ranks(spin_type='G', which='t') Get a list of cluster operator ranks for the coupling between fermions and bosons. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator to return. Returns: list [ tuple [ str , str , int , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def coupling_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int, int]]: \"\"\"Get a list of cluster operator ranks for the coupling between fermions and bosons. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator to return. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" def _adapt_key(key: str, fermion_rank: int, boson_rank: int) -> str: \"\"\"Adapt the key to the `which` argument.\"\"\" if which in (\"ip\", \"ea\", \"ee\"): raise util.ModelNotImplemented( \"Cluster ranks for coupling space not implemented for %s\" % which ) if which == \"l\": nf = fermion_rank nb = boson_rank key = key[:nb] + key[nb + nf :] + key[nb : nb + nf] return key symbol = \"u\" if which == \"t\" else \"lu\" ranks = [] for fermion_rank in range(1, self.fermion_coupling_rank + 1): for boson_rank in range(1, self.boson_coupling_rank + 1): name = f\"{symbol}{fermion_rank}{boson_rank}\" key = _adapt_key( \"b\" * boson_rank + \"o\" * fermion_rank + \"v\" * fermion_rank, fermion_rank, boson_rank, ) ranks.append((name, key, fermion_rank, boson_rank)) return ranks ebcc.core.ansatz.name_to_identifier(name) Convert an ansatz name to an identifier. The identifier is used as for the filename of the module containing the generated equations, where the name may contain illegal characters. Parameters: name ( str ) \u2013 Name of the ansatz. Returns: str \u2013 Identifier for the ansatz. Examples: >>> name_to_identifier(\"CCSD(T)\") 'CCSDxTx' >>> name_to_identifier(\"CCSD-SD-1-2\") 'CCSD_SD_1_2' >>> name_to_identifier(\"CCSDt'\") 'CCSDwtwp' Source code in ebcc/core/ansatz.py def name_to_identifier(name: str) -> str: \"\"\"Convert an ansatz name to an identifier. The identifier is used as for the filename of the module containing the generated equations, where the name may contain illegal characters. Args: name: Name of the ansatz. Returns: Identifier for the ansatz. Examples: >>> name_to_identifier(\"CCSD(T)\") 'CCSDxTx' >>> name_to_identifier(\"CCSD-SD-1-2\") 'CCSD_SD_1_2' >>> name_to_identifier(\"CCSDt'\") 'CCSDwtwp' \"\"\" iden = \"\".join([f\"w{c}w\" if c.isalpha() and c.islower() else c for c in name]) iden = iden.replace(\"(\", \"x\").replace(\")\", \"x\") iden = iden.replace(\"[\", \"y\").replace(\"]\", \"y\") iden = iden.replace(\"-\", \"_\") iden = iden.replace(\"'\", \"p\") return iden ebcc.core.ansatz.identifier_to_name(iden) Convert an ansatz identifier to a name. Inverse operation of name_to_identifier . Parameters: iden ( str ) \u2013 Identifier for the ansatz. Returns: str \u2013 Name of the ansatz. Examples: >>> identifier_to_name(\"CCSDxTx\") 'CCSD(T)' >>> identifier_to_name(\"CCSD_SD_1_2\") 'CCSD-SD-1-2' >>> identifier_to_name(\"CCSDwtwp\") \"CCSDt'\" Source code in ebcc/core/ansatz.py def identifier_to_name(iden: str) -> str: \"\"\"Convert an ansatz identifier to a name. Inverse operation of `name_to_identifier`. Args: iden: Identifier for the ansatz. Returns: Name of the ansatz. Examples: >>> identifier_to_name(\"CCSDxTx\") 'CCSD(T)' >>> identifier_to_name(\"CCSD_SD_1_2\") 'CCSD-SD-1-2' >>> identifier_to_name(\"CCSDwtwp\") \"CCSDt'\" \"\"\" name = iden.replace(\"-\", \"_\") name = name.replace(\"w\", \"\") while \"x\" in name: name = name.replace(\"x\", \"(\", 1).replace(\"x\", \")\", 1) while \"y\" in name: name = name.replace(\"y\", \"(\", 1).replace(\"y\", \")\", 1) name = name.replace(\"p\", \"'\") return name","title":"Ansatz"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz","text":"Ansatz class. Initialise the ansatz. Parameters: fermion_ansatz ( str , default: 'CCSD' ) \u2013 Fermionic ansatz. boson_ansatz ( str , default: '' ) \u2013 Rank of bosonic excitations. fermion_coupling_rank ( int , default: 0 ) \u2013 Rank of fermionic term in coupling. boson_coupling_rank ( int , default: 0 ) \u2013 Rank of bosonic term in coupling. density_fitting ( bool , default: False ) \u2013 Use density fitting. module_name ( Optional [ str ] , default: None ) \u2013 Name of the module containing the generated equations. Source code in ebcc/core/ansatz.py def __init__( self, fermion_ansatz: str = \"CCSD\", boson_ansatz: str = \"\", fermion_coupling_rank: int = 0, boson_coupling_rank: int = 0, density_fitting: bool = False, module_name: Optional[str] = None, ) -> None: \"\"\"Initialise the ansatz. Args: fermion_ansatz: Fermionic ansatz. boson_ansatz: Rank of bosonic excitations. fermion_coupling_rank: Rank of fermionic term in coupling. boson_coupling_rank: Rank of bosonic term in coupling. density_fitting: Use density fitting. module_name: Name of the module containing the generated equations. \"\"\" self.fermion_ansatz = fermion_ansatz self.boson_ansatz = boson_ansatz self.fermion_coupling_rank = fermion_coupling_rank self.boson_coupling_rank = boson_coupling_rank self.density_fitting = density_fitting self.module_name = module_name","title":"Ansatz"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.name","text":"Get the name of the ansatz.","title":"name"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.has_perturbative_correction","text":"Get a boolean indicating if the ansatz includes a perturbative correction e.g. CCSD(T). Returns: perturbative ( bool ) \u2013 Boolean indicating if the ansatz is perturbatively corrected.","title":"has_perturbative_correction"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.is_one_shot","text":"Get a boolean indicating whether the ansatz is a one-shot energy calculation e.g. MP2. Returns: one_shot ( bool ) \u2013 Boolean indicating if the ansatz is a one-shot energy calculation.","title":"is_one_shot"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.from_string","text":"Build an Ansatz from a string for the default ansatzes. Parameters: string ( str ) \u2013 Input string. density_fitting ( bool , default: False ) \u2013 Use density fitting. Returns: Ansatz \u2013 Ansatz object. Source code in ebcc/core/ansatz.py @classmethod def from_string(cls, string: str, density_fitting: bool = False) -> Ansatz: \"\"\"Build an `Ansatz` from a string for the default ansatzes. Args: string: Input string. density_fitting: Use density fitting. Returns: Ansatz object. \"\"\" if string not in named_ansatzes: raise util.ModelNotImplemented(string) return cls(*named_ansatzes[string], density_fitting=density_fitting)","title":"from_string"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.__repr__","text":"Get a string with the name of the method. Source code in ebcc/core/ansatz.py def __repr__(self) -> str: \"\"\"Get a string with the name of the method.\"\"\" name = \"\" if self.density_fitting: name += \"DF\" name += self.fermion_ansatz if self.boson_ansatz: name += \"-%s\" % self.boson_ansatz if self.fermion_coupling_rank or self.boson_coupling_rank: name += \"-%d\" % self.fermion_coupling_rank name += \"-%d\" % self.boson_coupling_rank return name","title":"__repr__"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.fermionic_cluster_ranks","text":"Get a list of cluster operator ranks for the fermionic space. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator to return. Returns: list [ tuple [ str , str , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def fermionic_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int]]: \"\"\"Get a list of cluster operator ranks for the fermionic space. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator to return. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" ranks: list[tuple[str, str, int]] = [] if not self.fermion_ansatz: return ranks def _adapt_key(key: str) -> str: \"\"\"Adapt the key to the `which` argument.\"\"\" if which == \"ip\": return key[:-1] if which == \"ea\": n = len(key) // 2 key = key[n:] + key[: n - 1] if which == \"l\": n = len(key) // 2 key = key[n:] + key[:n] return key symbol = which if which in (\"t\", \"l\") else \"r\" notations = { \"S\": [(f\"{symbol}1\", _adapt_key(\"ov\"), 1)], \"D\": [(f\"{symbol}2\", _adapt_key(\"oovv\"), 2)], \"T\": [(f\"{symbol}3\", _adapt_key(\"ooovvv\"), 3)], \"t\": [(f\"{symbol}3\", _adapt_key(\"ooOvvV\"), 3)], \"t'\": [(f\"{symbol}3\", _adapt_key(\"OOOVVV\"), 3)], } if spin_type == \"R\": notations[\"Q\"] = [(f\"{symbol}4a\", \"oooovvvv\", 4), (f\"{symbol}4b\", \"oooovvvv\", 4)] else: notations[\"Q\"] = [(f\"{symbol}4\", \"oooovvvv\", 4)] notations[\"2\"] = notations[\"S\"] + notations[\"D\"] notations[\"3\"] = notations[\"2\"] + notations[\"T\"] notations[\"4\"] = notations[\"3\"] + notations[\"Q\"] # Remove any perturbative corrections op = self.fermion_ansatz while \"(\" in op: start = op.index(\"(\") end = op.index(\")\") op = op[:start] if (end + 1) < len(op): op += op[end + 1 :] # Check in order of longest to shortest string in case one # method name starts with a substring equal to the name of # another method for method_type in sorted(METHOD_TYPES, key=len)[::-1]: if op.startswith(method_type): op = op.replace(method_type, \"\", 1) break # If it's MP we only ever need to initialise second-order # amplitudes if method_type == \"MP\" and which in (\"t\", \"l\"): op = \"D\" # If it's for EOM-CCD we still need the singles if self.fermion_ansatz == \"CCD\" and which in (\"ip\", \"ea\", \"ee\"): op = \"SD\" # Determine the ranks for key in sorted(notations.keys(), key=len)[::-1]: if key in op: ranks += notations[key] op = op.replace(key, \"\") # Check there are no duplicates if len(ranks) != len(set(ranks)): raise util.ModelNotImplemented(\"Duplicate ranks in %s\" % self.fermion_ansatz) # Sort the ranks by the cluster operator dimension ranks = sorted(ranks, key=lambda x: x[2]) return ranks","title":"fermionic_cluster_ranks"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.bosonic_cluster_ranks","text":"Get a list of cluster operator ranks for the bosonic space. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator. Returns: list [ tuple [ str , str , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def bosonic_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int]]: \"\"\"Get a list of cluster operator ranks for the bosonic space. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" ranks: list[tuple[str, str, int]] = [] if not self.boson_ansatz: return ranks symbol = \"s\" if which == \"t\" else \"ls\" notations = { \"S\": [(f\"{symbol}1\", \"b\", 1)], \"D\": [(f\"{symbol}2\", \"bb\", 2)], \"T\": [(f\"{symbol}3\", \"bbb\", 3)], } notations[\"2\"] = notations[\"S\"] + notations[\"D\"] notations[\"3\"] = notations[\"2\"] + notations[\"T\"] # Remove any perturbative corrections op = self.boson_ansatz while \"(\" in op: start = op.index(\"(\") end = op.index(\")\") op = op[:start] if (end + 1) < len(op): op += op[end + 1 :] # Determine the ranks for key in sorted(notations.keys(), key=len)[::-1]: if key in op: ranks += notations[key] op = op.replace(key, \"\") # Check there are no duplicates if len(ranks) != len(set(ranks)): raise util.ModelNotImplemented(\"Duplicate ranks in %s\" % self.boson_ansatz) # Sort the ranks by the cluster operator dimension ranks = sorted(ranks, key=lambda x: x[2]) return ranks","title":"bosonic_cluster_ranks"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.Ansatz.coupling_cluster_ranks","text":"Get a list of cluster operator ranks for the coupling between fermions and bosons. Parameters: spin_type ( str , default: 'G' ) \u2013 Spin type of the cluster operator. which ( Literal ['t', 'l', 'ip', 'ea', 'ee'] , default: 't' ) \u2013 Type of cluster operator to return. Returns: list [ tuple [ str , str , int , int ]] \u2013 List of cluster operator ranks, each element is a tuple containing the name, the slices list [ tuple [ str , str , int , int ]] \u2013 and the rank. Source code in ebcc/core/ansatz.py def coupling_cluster_ranks( self, spin_type: str = \"G\", which: Literal[\"t\", \"l\", \"ip\", \"ea\", \"ee\"] = \"t\", ) -> list[tuple[str, str, int, int]]: \"\"\"Get a list of cluster operator ranks for the coupling between fermions and bosons. Args: spin_type: Spin type of the cluster operator. which: Type of cluster operator to return. Returns: List of cluster operator ranks, each element is a tuple containing the name, the slices and the rank. \"\"\" def _adapt_key(key: str, fermion_rank: int, boson_rank: int) -> str: \"\"\"Adapt the key to the `which` argument.\"\"\" if which in (\"ip\", \"ea\", \"ee\"): raise util.ModelNotImplemented( \"Cluster ranks for coupling space not implemented for %s\" % which ) if which == \"l\": nf = fermion_rank nb = boson_rank key = key[:nb] + key[nb + nf :] + key[nb : nb + nf] return key symbol = \"u\" if which == \"t\" else \"lu\" ranks = [] for fermion_rank in range(1, self.fermion_coupling_rank + 1): for boson_rank in range(1, self.boson_coupling_rank + 1): name = f\"{symbol}{fermion_rank}{boson_rank}\" key = _adapt_key( \"b\" * boson_rank + \"o\" * fermion_rank + \"v\" * fermion_rank, fermion_rank, boson_rank, ) ranks.append((name, key, fermion_rank, boson_rank)) return ranks","title":"coupling_cluster_ranks"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.name_to_identifier","text":"Convert an ansatz name to an identifier. The identifier is used as for the filename of the module containing the generated equations, where the name may contain illegal characters. Parameters: name ( str ) \u2013 Name of the ansatz. Returns: str \u2013 Identifier for the ansatz. Examples: >>> name_to_identifier(\"CCSD(T)\") 'CCSDxTx' >>> name_to_identifier(\"CCSD-SD-1-2\") 'CCSD_SD_1_2' >>> name_to_identifier(\"CCSDt'\") 'CCSDwtwp' Source code in ebcc/core/ansatz.py def name_to_identifier(name: str) -> str: \"\"\"Convert an ansatz name to an identifier. The identifier is used as for the filename of the module containing the generated equations, where the name may contain illegal characters. Args: name: Name of the ansatz. Returns: Identifier for the ansatz. Examples: >>> name_to_identifier(\"CCSD(T)\") 'CCSDxTx' >>> name_to_identifier(\"CCSD-SD-1-2\") 'CCSD_SD_1_2' >>> name_to_identifier(\"CCSDt'\") 'CCSDwtwp' \"\"\" iden = \"\".join([f\"w{c}w\" if c.isalpha() and c.islower() else c for c in name]) iden = iden.replace(\"(\", \"x\").replace(\")\", \"x\") iden = iden.replace(\"[\", \"y\").replace(\"]\", \"y\") iden = iden.replace(\"-\", \"_\") iden = iden.replace(\"'\", \"p\") return iden","title":"name_to_identifier"},{"location":"reference/core/ansatz/#ebcc.core.ansatz.identifier_to_name","text":"Convert an ansatz identifier to a name. Inverse operation of name_to_identifier . Parameters: iden ( str ) \u2013 Identifier for the ansatz. Returns: str \u2013 Name of the ansatz. Examples: >>> identifier_to_name(\"CCSDxTx\") 'CCSD(T)' >>> identifier_to_name(\"CCSD_SD_1_2\") 'CCSD-SD-1-2' >>> identifier_to_name(\"CCSDwtwp\") \"CCSDt'\" Source code in ebcc/core/ansatz.py def identifier_to_name(iden: str) -> str: \"\"\"Convert an ansatz identifier to a name. Inverse operation of `name_to_identifier`. Args: iden: Identifier for the ansatz. Returns: Name of the ansatz. Examples: >>> identifier_to_name(\"CCSDxTx\") 'CCSD(T)' >>> identifier_to_name(\"CCSD_SD_1_2\") 'CCSD-SD-1-2' >>> identifier_to_name(\"CCSDwtwp\") \"CCSDt'\" \"\"\" name = iden.replace(\"-\", \"_\") name = name.replace(\"w\", \"\") while \"x\" in name: name = name.replace(\"x\", \"(\", 1).replace(\"x\", \")\", 1) while \"y\" in name: name = name.replace(\"y\", \"(\", 1).replace(\"y\", \")\", 1) name = name.replace(\"p\", \"'\") return name","title":"identifier_to_name"},{"location":"reference/core/damping/","text":"Damping and DIIS control. ebcc.core.damping.BaseDamping(*args, options=None, **kwargs) Bases: ABC Base class for damping. Initialise the damping object. Source code in ebcc/core/damping.py def __init__(self, *args: Any, options: Optional[_BaseOptions] = None, **kwargs: Any) -> None: \"\"\"Initialise the damping object.\"\"\" self._arrays = {} self._errors = {} self._counter = 0 ebcc.core.damping.BaseDamping.__call__(array, error=None) Apply damping to the array. Parameters: array ( NDArray [ T ] ) \u2013 The array to damp. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array. Returns: NDArray [ T ] \u2013 The damped array. Source code in ebcc/core/damping.py def __call__(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" self.push(array, error=error) return self.extrapolate() ebcc.core.damping.BaseDamping.push(array, error=None) abstractmethod Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py @abstractmethod def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" pass ebcc.core.damping.BaseDamping.extrapolate() abstractmethod Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py @abstractmethod def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" pass ebcc.core.damping.BaseDamping.reset() Reset the damping object. Source code in ebcc/core/damping.py def reset(self) -> None: \"\"\"Reset the damping object.\"\"\" self._arrays = {} self._errors = {} self._counter = 0 ebcc.core.damping.BaseDamping.__len__() Get the number of arrays stored in the damping object. Source code in ebcc/core/damping.py def __len__(self) -> int: \"\"\"Get the number of arrays stored in the damping object.\"\"\" return len(self._arrays) ebcc.core.damping.NoDamping(*args, options=None, **kwargs) Bases: BaseDamping No damping. Apply damping to the array. Parameters: array \u2013 The array to damp. error \u2013 The error array. Returns: None \u2013 The damped array. Source code in ebcc/core/damping.py def __init__(self, *args: Any, options: Optional[_BaseOptions] = None, **kwargs: Any) -> None: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" pass ebcc.core.damping.NoDamping.__call__(array, error=None) Apply damping to the array. Parameters: array ( NDArray [ T ] ) \u2013 The array to damp. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array. Returns: NDArray [ T ] \u2013 The damped array. Source code in ebcc/core/damping.py def __call__(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" return array ebcc.core.damping.NoDamping.push(array, error=None) Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" raise NotImplementedError ebcc.core.damping.NoDamping.extrapolate() Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" raise NotImplementedError ebcc.core.damping.LinearDamping(*args, factor=None, options=None) Bases: BaseDamping Linear damping. Initialise the damping object. Parameters: factor ( Optional [ float ] , default: None ) \u2013 The damping factor. If None , use options.damping , if available. Otherwise, use 0.5 . options ( Optional [ _BaseOptions ] , default: None ) \u2013 The options object. Source code in ebcc/core/damping.py def __init__( self, *args: Any, factor: Optional[float] = None, options: Optional[_BaseOptions] = None ) -> None: \"\"\"Initialise the damping object. Args: factor: The damping factor. If `None`, use `options.damping`, if available. Otherwise, use `0.5`. options: The options object. \"\"\" super().__init__() if factor is None: factor = getattr(options, \"damping\", 0.5) self.factor = factor ebcc.core.damping.LinearDamping.push(array, error=None) Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" if len(self) == 2: self._arrays.pop(min(self._arrays.keys())) self._arrays[self._counter] = array self._counter += 1 ebcc.core.damping.LinearDamping.extrapolate() Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" if len(self) < 2: return next(iter(self._arrays.values())) (_, previous), (_, current) = sorted(self._arrays.items()) return current * (1.0 - self.factor) + previous * self.factor ebcc.core.damping.DIIS(space=None, min_space=None, factor=None, options=None) Bases: BaseDamping Direct inversion in the iterative subspace. Initialize the DIIS object. Parameters: space ( Optional [ int ] , default: None ) \u2013 The number of vectors to store in the DIIS space. If None , use options.diis_space , if available. Otherwise, use 6 . min_space ( Optional [ int ] , default: None ) \u2013 The minimum number of vectors to store in the DIIS space. If None , use options.diis_min_space , if available. Otherwise, use 1 . factor ( Optional [ float ] , default: None ) \u2013 The damping factor. If None , use options.damping , if available. Otherwise, use 0.5 . options ( Optional [ _BaseOptions ] , default: None ) \u2013 The options object. Source code in ebcc/core/damping.py def __init__( self, space: Optional[int] = None, min_space: Optional[int] = None, factor: Optional[float] = None, options: Optional[_BaseOptions] = None, ) -> None: \"\"\"Initialize the DIIS object. Args: space: The number of vectors to store in the DIIS space. If `None`, use `options.diis_space`, if available. Otherwise, use `6`. min_space: The minimum number of vectors to store in the DIIS space. If `None`, use `options.diis_min_space`, if available. Otherwise, use `1`. factor: The damping factor. If `None`, use `options.damping`, if available. Otherwise, use `0.5`. options: The options object. \"\"\" super().__init__() if space is None: space = getattr(options, \"diis_space\", 6) if min_space is None: min_space = getattr(options, \"diis_min_space\", 1) if factor is None: factor = getattr(options, \"damping\", 0.5) self.space = space self.min_space = min_space self.factor = factor self._norm_cache: dict[tuple[int, int], T] = {} ebcc.core.damping.DIIS.push(array, error=None) Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" # Get the error if not provided if error is None and -1 in self._arrays: error = array - self._arrays[-1] elif error is None or len(self) == 0: self._arrays[-1] = array return # Push the array and error into the DIIS subspace self._arrays[self._counter] = array self._errors[self._counter] = error self._counter += 1 # Remove an array if the space is exceeded if len(self) > self.space: errors = { counter: self._error_norm(counter, counter) for counter in self._errors.keys() } counter = max(errors, key=errors.__getitem__) # type: ignore[arg-type] self._arrays.pop(counter) self._errors.pop(counter) ebcc.core.damping.DIIS.extrapolate() Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" # Return the last array if the space is less than the minimum space counters = sorted(self._errors.keys()) size = len(counters) if size < self.min_space: return self._arrays[-1] # Get the backend if USE_BACKEND: backend = np else: backend = numpy # Build the error matrix errors = backend.array( [ [self._error_norm(counter_i, counter_j) for counter_j in counters] for counter_i in counters ] ) zeros = backend.zeros((1, 1), dtype=errors.dtype) ones = backend.ones((size, 1), dtype=errors.dtype) matrix = backend.block([[errors, -ones], [-backend.transpose(ones), zeros]]) # Build the right-hand side zeros = backend.zeros((size,), dtype=errors.dtype) ones = backend.ones((1,), dtype=errors.dtype) residual = backend.block([zeros, -ones]) # Solve the linear problem try: c = backend.linalg.solve(matrix, residual) except Exception: w, v = backend.linalg.eigh(matrix) if backend.any(backend.abs(w) < 1e-14): # avoiding fancy indexing for compatibility for i in range(size + 1): if backend.abs(w[i]) < 1e-14: _put( v, backend.ix_(backend.arange(size + 1), backend.array([i])), backend.zeros_like(v[:, i]), ) c = util.einsum(\"pi,qi,i,q->p\", v, np.conj(v), w**-1.0, residual) # Construct the new array array = np.zeros_like(self._arrays[next(iter(self._arrays))]) for counter, coefficient in zip(counters, c): array += self._arrays[counter] * coefficient error = np.zeros_like(self._errors[next(iter(self._errors))]) for counter, coefficient in zip(counters, c): error += self._errors[counter] * coefficient # Apply the damping factor if self.factor: array = array * (1.0 - self.factor) + self._arrays[-1] * self.factor # Replace the previous array with the extrapolated array self._arrays[-1] = array self._arrays[self._counter] = array self._errors[self._counter] = error return array ebcc.core.damping.DIIS.reset() Reset the damping object. Source code in ebcc/core/damping.py def reset(self) -> None: \"\"\"Reset the damping object.\"\"\" super().reset() self._norm_cache = {}","title":"Damping"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping","text":"Bases: ABC Base class for damping. Initialise the damping object. Source code in ebcc/core/damping.py def __init__(self, *args: Any, options: Optional[_BaseOptions] = None, **kwargs: Any) -> None: \"\"\"Initialise the damping object.\"\"\" self._arrays = {} self._errors = {} self._counter = 0","title":"BaseDamping"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping.__call__","text":"Apply damping to the array. Parameters: array ( NDArray [ T ] ) \u2013 The array to damp. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array. Returns: NDArray [ T ] \u2013 The damped array. Source code in ebcc/core/damping.py def __call__(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" self.push(array, error=error) return self.extrapolate()","title":"__call__"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping.push","text":"Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py @abstractmethod def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" pass","title":"push"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping.extrapolate","text":"Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py @abstractmethod def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" pass","title":"extrapolate"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping.reset","text":"Reset the damping object. Source code in ebcc/core/damping.py def reset(self) -> None: \"\"\"Reset the damping object.\"\"\" self._arrays = {} self._errors = {} self._counter = 0","title":"reset"},{"location":"reference/core/damping/#ebcc.core.damping.BaseDamping.__len__","text":"Get the number of arrays stored in the damping object. Source code in ebcc/core/damping.py def __len__(self) -> int: \"\"\"Get the number of arrays stored in the damping object.\"\"\" return len(self._arrays)","title":"__len__"},{"location":"reference/core/damping/#ebcc.core.damping.NoDamping","text":"Bases: BaseDamping No damping. Apply damping to the array. Parameters: array \u2013 The array to damp. error \u2013 The error array. Returns: None \u2013 The damped array. Source code in ebcc/core/damping.py def __init__(self, *args: Any, options: Optional[_BaseOptions] = None, **kwargs: Any) -> None: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" pass","title":"NoDamping"},{"location":"reference/core/damping/#ebcc.core.damping.NoDamping.__call__","text":"Apply damping to the array. Parameters: array ( NDArray [ T ] ) \u2013 The array to damp. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array. Returns: NDArray [ T ] \u2013 The damped array. Source code in ebcc/core/damping.py def __call__(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Apply damping to the array. Args: array: The array to damp. error: The error array. Returns: The damped array. \"\"\" return array","title":"__call__"},{"location":"reference/core/damping/#ebcc.core.damping.NoDamping.push","text":"Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" raise NotImplementedError","title":"push"},{"location":"reference/core/damping/#ebcc.core.damping.NoDamping.extrapolate","text":"Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" raise NotImplementedError","title":"extrapolate"},{"location":"reference/core/damping/#ebcc.core.damping.LinearDamping","text":"Bases: BaseDamping Linear damping. Initialise the damping object. Parameters: factor ( Optional [ float ] , default: None ) \u2013 The damping factor. If None , use options.damping , if available. Otherwise, use 0.5 . options ( Optional [ _BaseOptions ] , default: None ) \u2013 The options object. Source code in ebcc/core/damping.py def __init__( self, *args: Any, factor: Optional[float] = None, options: Optional[_BaseOptions] = None ) -> None: \"\"\"Initialise the damping object. Args: factor: The damping factor. If `None`, use `options.damping`, if available. Otherwise, use `0.5`. options: The options object. \"\"\" super().__init__() if factor is None: factor = getattr(options, \"damping\", 0.5) self.factor = factor","title":"LinearDamping"},{"location":"reference/core/damping/#ebcc.core.damping.LinearDamping.push","text":"Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" if len(self) == 2: self._arrays.pop(min(self._arrays.keys())) self._arrays[self._counter] = array self._counter += 1","title":"push"},{"location":"reference/core/damping/#ebcc.core.damping.LinearDamping.extrapolate","text":"Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" if len(self) < 2: return next(iter(self._arrays.values())) (_, previous), (_, current) = sorted(self._arrays.items()) return current * (1.0 - self.factor) + previous * self.factor","title":"extrapolate"},{"location":"reference/core/damping/#ebcc.core.damping.DIIS","text":"Bases: BaseDamping Direct inversion in the iterative subspace. Initialize the DIIS object. Parameters: space ( Optional [ int ] , default: None ) \u2013 The number of vectors to store in the DIIS space. If None , use options.diis_space , if available. Otherwise, use 6 . min_space ( Optional [ int ] , default: None ) \u2013 The minimum number of vectors to store in the DIIS space. If None , use options.diis_min_space , if available. Otherwise, use 1 . factor ( Optional [ float ] , default: None ) \u2013 The damping factor. If None , use options.damping , if available. Otherwise, use 0.5 . options ( Optional [ _BaseOptions ] , default: None ) \u2013 The options object. Source code in ebcc/core/damping.py def __init__( self, space: Optional[int] = None, min_space: Optional[int] = None, factor: Optional[float] = None, options: Optional[_BaseOptions] = None, ) -> None: \"\"\"Initialize the DIIS object. Args: space: The number of vectors to store in the DIIS space. If `None`, use `options.diis_space`, if available. Otherwise, use `6`. min_space: The minimum number of vectors to store in the DIIS space. If `None`, use `options.diis_min_space`, if available. Otherwise, use `1`. factor: The damping factor. If `None`, use `options.damping`, if available. Otherwise, use `0.5`. options: The options object. \"\"\" super().__init__() if space is None: space = getattr(options, \"diis_space\", 6) if min_space is None: min_space = getattr(options, \"diis_min_space\", 1) if factor is None: factor = getattr(options, \"damping\", 0.5) self.space = space self.min_space = min_space self.factor = factor self._norm_cache: dict[tuple[int, int], T] = {}","title":"DIIS"},{"location":"reference/core/damping/#ebcc.core.damping.DIIS.push","text":"Push the array and error into the damping object. Parameters: array ( NDArray [ T ] ) \u2013 The array to push. error ( Optional [ NDArray [ T ]] , default: None ) \u2013 The error array to push. Source code in ebcc/core/damping.py def push(self, array: NDArray[T], error: Optional[NDArray[T]] = None) -> None: \"\"\"Push the array and error into the damping object. Args: array: The array to push. error: The error array to push. \"\"\" # Get the error if not provided if error is None and -1 in self._arrays: error = array - self._arrays[-1] elif error is None or len(self) == 0: self._arrays[-1] = array return # Push the array and error into the DIIS subspace self._arrays[self._counter] = array self._errors[self._counter] = error self._counter += 1 # Remove an array if the space is exceeded if len(self) > self.space: errors = { counter: self._error_norm(counter, counter) for counter in self._errors.keys() } counter = max(errors, key=errors.__getitem__) # type: ignore[arg-type] self._arrays.pop(counter) self._errors.pop(counter)","title":"push"},{"location":"reference/core/damping/#ebcc.core.damping.DIIS.extrapolate","text":"Extrapolate the next array. Returns: NDArray [ T ] \u2013 The extrapolated array. Source code in ebcc/core/damping.py def extrapolate(self) -> NDArray[T]: \"\"\"Extrapolate the next array. Returns: The extrapolated array. \"\"\" # Return the last array if the space is less than the minimum space counters = sorted(self._errors.keys()) size = len(counters) if size < self.min_space: return self._arrays[-1] # Get the backend if USE_BACKEND: backend = np else: backend = numpy # Build the error matrix errors = backend.array( [ [self._error_norm(counter_i, counter_j) for counter_j in counters] for counter_i in counters ] ) zeros = backend.zeros((1, 1), dtype=errors.dtype) ones = backend.ones((size, 1), dtype=errors.dtype) matrix = backend.block([[errors, -ones], [-backend.transpose(ones), zeros]]) # Build the right-hand side zeros = backend.zeros((size,), dtype=errors.dtype) ones = backend.ones((1,), dtype=errors.dtype) residual = backend.block([zeros, -ones]) # Solve the linear problem try: c = backend.linalg.solve(matrix, residual) except Exception: w, v = backend.linalg.eigh(matrix) if backend.any(backend.abs(w) < 1e-14): # avoiding fancy indexing for compatibility for i in range(size + 1): if backend.abs(w[i]) < 1e-14: _put( v, backend.ix_(backend.arange(size + 1), backend.array([i])), backend.zeros_like(v[:, i]), ) c = util.einsum(\"pi,qi,i,q->p\", v, np.conj(v), w**-1.0, residual) # Construct the new array array = np.zeros_like(self._arrays[next(iter(self._arrays))]) for counter, coefficient in zip(counters, c): array += self._arrays[counter] * coefficient error = np.zeros_like(self._errors[next(iter(self._errors))]) for counter, coefficient in zip(counters, c): error += self._errors[counter] * coefficient # Apply the damping factor if self.factor: array = array * (1.0 - self.factor) + self._arrays[-1] * self.factor # Replace the previous array with the extrapolated array self._arrays[-1] = array self._arrays[self._counter] = array self._errors[self._counter] = error return array","title":"extrapolate"},{"location":"reference/core/damping/#ebcc.core.damping.DIIS.reset","text":"Reset the damping object. Source code in ebcc/core/damping.py def reset(self) -> None: \"\"\"Reset the damping object.\"\"\" super().reset() self._norm_cache = {}","title":"reset"},{"location":"reference/core/davidson/","text":"Davidson algorithm. Adapted from PySCF. ebcc.core.davidson.make_diagonal_preconditioner(diag, level_shift=0.0, tol=1e-08) Generate the preconditioner function. Parameters: diag ( NDArray [ floating ] ) \u2013 The diagonal of the matrix. level_shift ( float , default: 0.0 ) \u2013 The level shift to use. tol ( float , default: 1e-08 ) \u2013 The tolerance to use to avoid division by zero. Returns: PreconditionerType [ T ] \u2013 The preconditioner function. Notes The default preconditioner approximates the inverse of the matrix by its diagonal. If the basis generated by the preconditioner is not linearly dependent, a level shift can be applied to break the correlation between the matrix and its diagonal. Source code in ebcc/core/davidson.py def make_diagonal_preconditioner( diag: NDArray[floating], level_shift: float = 0.0, tol: float = 1e-8 ) -> PreconditionerType[T]: \"\"\"Generate the preconditioner function. Args: diag: The diagonal of the matrix. level_shift: The level shift to use. tol: The tolerance to use to avoid division by zero. Returns: The preconditioner function. Notes: The default preconditioner approximates the inverse of the matrix by its diagonal. If the basis generated by the preconditioner is not linearly dependent, a level shift can be applied to break the correlation between the matrix and its diagonal. \"\"\" def preconditioner(dx: NDArray[T], e: Union[NDArray[T], T]) -> NDArray[T]: \"\"\"Precondition the solver.\"\"\" diag_shifted = diag - (e - level_shift) indices = np.ix_(np.abs(diag_shifted) < tol) _put( diag_shifted, indices, # type: ignore np.full(indices[0].shape, tol), ) return dx / diag_shifted return preconditioner ebcc.core.davidson.pick_real_eigenvalues(w, v, nroots, basis_vectors=None) Search for eigenvalues that are real or close to real. Parameters: w ( NDArray [ T ] ) \u2013 The eigenvalues. v ( NDArray [ T ] ) \u2013 The eigenvectors. nroots ( int ) \u2013 The number of roots to find. basis_vectors ( Optional [ NDArray [ T ]] , default: None ) \u2013 The basis vectors. Not used in this function. Returns: tuple [ NDArray [ floating ], NDArray [ T ], NDArray [ integer ]] \u2013 The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Source code in ebcc/core/davidson.py def pick_real_eigenvalues( w: NDArray[T], v: NDArray[T], nroots: int, basis_vectors: Optional[NDArray[T]] = None, ) -> tuple[NDArray[floating], NDArray[T], NDArray[integer]]: \"\"\"Search for eigenvalues that are real or close to real. Args: w: The eigenvalues. v: The eigenvectors. nroots: The number of roots to find. basis_vectors: The basis vectors. Not used in this function. Returns: The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. \"\"\" imaginary_tol = 1e-3 abs_imag = np.abs(np.imag(w)) max_imag_tol = max(imaginary_tol, np.sort(abs_imag)[min(w.size, nroots) - 1]) real_idx = np.where(abs_imag < max_imag_tol)[0] return make_eigenvectors_real(w, v, real_idx, real_eigenvectors=True) ebcc.core.davidson.make_eigenvectors_real(w, v, real_idx, real_eigenvectors=True) Transform the eigenvectors to be real-valued. If a complex eigenvalue has a small imaginary part, both the real and imaginary parts of the eigenvector can be used as the real eigenvector. Parameters: w ( NDArray [ T ] ) \u2013 The eigenvalues. v ( NDArray [ T ] ) \u2013 The eigenvectors. real_idx ( NDArray [ integer ] ) \u2013 The indices of the real eigenvalues. real_eigenvectors ( bool , default: True ) \u2013 Whether to return real eigenvectors. Returns: tuple [ NDArray [ floating ], NDArray [ T ], NDArray [ integer ]] \u2013 The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Notes If real_eigenvectors is set to True , this function can only be used for real matrices and real eigenvectors. It discards the imaginary part of the eigenvectors and returns only the real part of the eigenvectors. Source code in ebcc/core/davidson.py def make_eigenvectors_real( w: NDArray[T], v: NDArray[T], real_idx: NDArray[integer], real_eigenvectors: bool = True, ) -> tuple[NDArray[floating], NDArray[T], NDArray[integer]]: \"\"\"Transform the eigenvectors to be real-valued. If a complex eigenvalue has a small imaginary part, both the real and imaginary parts of the eigenvector can be used as the real eigenvector. Args: w: The eigenvalues. v: The eigenvectors. real_idx: The indices of the real eigenvalues. real_eigenvectors: Whether to return real eigenvectors. Returns: The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Notes: If `real_eigenvectors` is set to `True`, this function can only be used for real matrices and real eigenvectors. It discards the imaginary part of the eigenvectors and returns only the real part of the eigenvectors. \"\"\" idx = real_idx[np.argsort(np.real(w[real_idx]))] w = w[idx] v = v[:, idx] if real_eigenvectors: degen = np.where(np.imag(w) != 0)[0] if degen.size > 0: indices = np.ix_(np.arange(v.shape[0]), degen[1::2]) _put(v, indices, np.imag(v[indices])) v = np.real(v) return np.real(w), v, idx ebcc.core.davidson.davidson(matvec, vectors, diagonal, nroots=1, max_iter=50, max_space=20, max_trials=40, e_tol=1e-12, r_tol=None, lindep_tol=1e-14, left=False, pick=None, follow_state=False, level_shift=0.0, callback=None) Davidson algorithm for finding eigenvalues and eigenvectors. Source code in ebcc/core/davidson.py def davidson( matvec: Callable[[NDArray[T]], NDArray[T]], vectors: NDArray[T], diagonal: NDArray[floating], nroots: int = 1, max_iter: int = 50, max_space: int = 20, max_trials: int = 40, e_tol: float = 1e-12, r_tol: Optional[float] = None, lindep_tol: float = 1e-14, left: bool = False, pick: Optional[PickType[T]] = None, follow_state: bool = False, level_shift: float = 0.0, callback: Optional[Callable[[dict[str, Any]], None]] = None, ) -> tuple[list[bool], NDArray[floating], NDArray[T]]: \"\"\"Davidson algorithm for finding eigenvalues and eigenvectors.\"\"\" # Parse arguments loose_tol = r_tol if r_tol is not None else e_tol**0.5 max_space += (nroots - 1) * 6 preconditioner: PreconditionerType[T] = make_diagonal_preconditioner(diagonal) if pick is None: pick = pick_real_eigenvalues dim = diagonal.size def _empty_vector() -> NDArray[T]: \"\"\"Return an empty vector.\"\"\" return np.empty((0, dim), dtype=types[complex]) # Initialise variables w: NDArray[floating] = np.empty(0, dtype=types[float]) v: NDArray[T] = _empty_vector() conv: list[bool] = [False] * nroots w_prev = np.copy(w) v_prev = np.copy(v) conv_prev = conv.copy() matrix: NDArray[T] = np.empty((max_space + nroots, max_space + nroots), dtype=types[complex]) restart = True basis_vectors: NDArray[T] = _empty_vector() matrix_basis_vectors: NDArray[T] = _empty_vector() space = 0 for cycle in range(max_iter): # Get the trial vectors if restart: basis_vectors = _empty_vector() matrix_basis_vectors = _empty_vector() space = 0 trial_vectors = _orthonormalise_vectors(vectors, lindep_tol=lindep_tol) del vectors elif trial_vectors.shape[0] > 1: trial_vectors = _orthonormalise_vectors(trial_vectors, lindep_tol=lindep_tol) trial_vectors = trial_vectors[:max_trials] # Find the matrix-vector products for the trial vectors matrix_trial_vectors = np.stack( [matvec(trial_vectors[i]) for i in range(trial_vectors.shape[0])] ) # Add the trial vectors to the basis basis_vectors = np.concatenate((basis_vectors, trial_vectors)) matrix_basis_vectors = np.concatenate((matrix_basis_vectors, matrix_trial_vectors)) space += trial_vectors.shape[0] # Store the previous iteration results w_prev = w v_prev = v conv_prev = conv # Fill the matrix matrix = _fill_subspace_matrix( matrix, basis_vectors, matrix_basis_vectors, trial_vectors, matrix_trial_vectors ) del trial_vectors, matrix_trial_vectors # Solve the eigenvalue problem w, v, idx = pick( *np.linalg.eig(matrix[:space, :space]), nroots, basis_vectors=basis_vectors ) if not w.size: raise RuntimeError(\"Not enough eigenvalues found.\") # Sort the eigenvalues and eigenvectors w = w[:nroots] v = v[:, :nroots] conv = [False] * nroots if not restart: w_prev, conv_prev = _sort_eigenvalues(w_prev, conv_prev, v_prev, v) dw = w - w_prev if w_prev.size == w.size else w # Find the subspace vectors and matrix-vector products vectors = _outer_product_to_subspace(v, basis_vectors) matrix_vectors = _outer_product_to_subspace(v, matrix_basis_vectors) # Check convergence trial_vectors = matrix_vectors - w[:, None] * vectors norms = np.real(np.linalg.norm(trial_vectors, axis=1, ord=2)) conv = [np.abs(dw[k]) < e_tol and norms[k] < loose_tol for k in range(w.size)] del matrix_vectors if all(conv): break # Check for restart if follow_state and np.max(norms) > 1 and space > nroots + 4: vectors = _outer_product_to_subspace(v_prev, basis_vectors) restart = True continue # Remove subspace linear dependency and project out existing basis vectors trial_vectors = preconditioner(trial_vectors, w[0] - level_shift) trial_vectors = _project_vectors(trial_vectors, basis_vectors) trial_vectors = _normalise_vectors(trial_vectors, lindep_tol=lindep_tol) if trial_vectors.shape[0] == 0: conv = [conv[k] or (norm < loose_tol) for k, norm in enumerate(norms)] break # Check for restart restart = space + nroots > max_space # Call the callback if callback is not None: callback(locals()) if left: # Get the left eigenvectors instead wl, vl, v = scipy.linalg.eig(matrix[:space, :space], left=True) w, v, idx = pick(wl, v, nroots, basis_vectors=basis_vectors) if not w.size: raise RuntimeError(\"Not enough eigenvalues found.\") w = w[:nroots] vectors = _outer_product_to_subspace(vl[:, idx[:nroots]], basis_vectors) return conv, w, np.transpose(vectors)","title":"Davidson"},{"location":"reference/core/davidson/#ebcc.core.davidson.make_diagonal_preconditioner","text":"Generate the preconditioner function. Parameters: diag ( NDArray [ floating ] ) \u2013 The diagonal of the matrix. level_shift ( float , default: 0.0 ) \u2013 The level shift to use. tol ( float , default: 1e-08 ) \u2013 The tolerance to use to avoid division by zero. Returns: PreconditionerType [ T ] \u2013 The preconditioner function. Notes The default preconditioner approximates the inverse of the matrix by its diagonal. If the basis generated by the preconditioner is not linearly dependent, a level shift can be applied to break the correlation between the matrix and its diagonal. Source code in ebcc/core/davidson.py def make_diagonal_preconditioner( diag: NDArray[floating], level_shift: float = 0.0, tol: float = 1e-8 ) -> PreconditionerType[T]: \"\"\"Generate the preconditioner function. Args: diag: The diagonal of the matrix. level_shift: The level shift to use. tol: The tolerance to use to avoid division by zero. Returns: The preconditioner function. Notes: The default preconditioner approximates the inverse of the matrix by its diagonal. If the basis generated by the preconditioner is not linearly dependent, a level shift can be applied to break the correlation between the matrix and its diagonal. \"\"\" def preconditioner(dx: NDArray[T], e: Union[NDArray[T], T]) -> NDArray[T]: \"\"\"Precondition the solver.\"\"\" diag_shifted = diag - (e - level_shift) indices = np.ix_(np.abs(diag_shifted) < tol) _put( diag_shifted, indices, # type: ignore np.full(indices[0].shape, tol), ) return dx / diag_shifted return preconditioner","title":"make_diagonal_preconditioner"},{"location":"reference/core/davidson/#ebcc.core.davidson.pick_real_eigenvalues","text":"Search for eigenvalues that are real or close to real. Parameters: w ( NDArray [ T ] ) \u2013 The eigenvalues. v ( NDArray [ T ] ) \u2013 The eigenvectors. nroots ( int ) \u2013 The number of roots to find. basis_vectors ( Optional [ NDArray [ T ]] , default: None ) \u2013 The basis vectors. Not used in this function. Returns: tuple [ NDArray [ floating ], NDArray [ T ], NDArray [ integer ]] \u2013 The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Source code in ebcc/core/davidson.py def pick_real_eigenvalues( w: NDArray[T], v: NDArray[T], nroots: int, basis_vectors: Optional[NDArray[T]] = None, ) -> tuple[NDArray[floating], NDArray[T], NDArray[integer]]: \"\"\"Search for eigenvalues that are real or close to real. Args: w: The eigenvalues. v: The eigenvectors. nroots: The number of roots to find. basis_vectors: The basis vectors. Not used in this function. Returns: The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. \"\"\" imaginary_tol = 1e-3 abs_imag = np.abs(np.imag(w)) max_imag_tol = max(imaginary_tol, np.sort(abs_imag)[min(w.size, nroots) - 1]) real_idx = np.where(abs_imag < max_imag_tol)[0] return make_eigenvectors_real(w, v, real_idx, real_eigenvectors=True)","title":"pick_real_eigenvalues"},{"location":"reference/core/davidson/#ebcc.core.davidson.make_eigenvectors_real","text":"Transform the eigenvectors to be real-valued. If a complex eigenvalue has a small imaginary part, both the real and imaginary parts of the eigenvector can be used as the real eigenvector. Parameters: w ( NDArray [ T ] ) \u2013 The eigenvalues. v ( NDArray [ T ] ) \u2013 The eigenvectors. real_idx ( NDArray [ integer ] ) \u2013 The indices of the real eigenvalues. real_eigenvectors ( bool , default: True ) \u2013 Whether to return real eigenvectors. Returns: tuple [ NDArray [ floating ], NDArray [ T ], NDArray [ integer ]] \u2013 The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Notes If real_eigenvectors is set to True , this function can only be used for real matrices and real eigenvectors. It discards the imaginary part of the eigenvectors and returns only the real part of the eigenvectors. Source code in ebcc/core/davidson.py def make_eigenvectors_real( w: NDArray[T], v: NDArray[T], real_idx: NDArray[integer], real_eigenvectors: bool = True, ) -> tuple[NDArray[floating], NDArray[T], NDArray[integer]]: \"\"\"Transform the eigenvectors to be real-valued. If a complex eigenvalue has a small imaginary part, both the real and imaginary parts of the eigenvector can be used as the real eigenvector. Args: w: The eigenvalues. v: The eigenvectors. real_idx: The indices of the real eigenvalues. real_eigenvectors: Whether to return real eigenvectors. Returns: The eigenvalues, eigenvectors, and the indices of the chosen eigenvalues. Notes: If `real_eigenvectors` is set to `True`, this function can only be used for real matrices and real eigenvectors. It discards the imaginary part of the eigenvectors and returns only the real part of the eigenvectors. \"\"\" idx = real_idx[np.argsort(np.real(w[real_idx]))] w = w[idx] v = v[:, idx] if real_eigenvectors: degen = np.where(np.imag(w) != 0)[0] if degen.size > 0: indices = np.ix_(np.arange(v.shape[0]), degen[1::2]) _put(v, indices, np.imag(v[indices])) v = np.real(v) return np.real(w), v, idx","title":"make_eigenvectors_real"},{"location":"reference/core/davidson/#ebcc.core.davidson.davidson","text":"Davidson algorithm for finding eigenvalues and eigenvectors. Source code in ebcc/core/davidson.py def davidson( matvec: Callable[[NDArray[T]], NDArray[T]], vectors: NDArray[T], diagonal: NDArray[floating], nroots: int = 1, max_iter: int = 50, max_space: int = 20, max_trials: int = 40, e_tol: float = 1e-12, r_tol: Optional[float] = None, lindep_tol: float = 1e-14, left: bool = False, pick: Optional[PickType[T]] = None, follow_state: bool = False, level_shift: float = 0.0, callback: Optional[Callable[[dict[str, Any]], None]] = None, ) -> tuple[list[bool], NDArray[floating], NDArray[T]]: \"\"\"Davidson algorithm for finding eigenvalues and eigenvectors.\"\"\" # Parse arguments loose_tol = r_tol if r_tol is not None else e_tol**0.5 max_space += (nroots - 1) * 6 preconditioner: PreconditionerType[T] = make_diagonal_preconditioner(diagonal) if pick is None: pick = pick_real_eigenvalues dim = diagonal.size def _empty_vector() -> NDArray[T]: \"\"\"Return an empty vector.\"\"\" return np.empty((0, dim), dtype=types[complex]) # Initialise variables w: NDArray[floating] = np.empty(0, dtype=types[float]) v: NDArray[T] = _empty_vector() conv: list[bool] = [False] * nroots w_prev = np.copy(w) v_prev = np.copy(v) conv_prev = conv.copy() matrix: NDArray[T] = np.empty((max_space + nroots, max_space + nroots), dtype=types[complex]) restart = True basis_vectors: NDArray[T] = _empty_vector() matrix_basis_vectors: NDArray[T] = _empty_vector() space = 0 for cycle in range(max_iter): # Get the trial vectors if restart: basis_vectors = _empty_vector() matrix_basis_vectors = _empty_vector() space = 0 trial_vectors = _orthonormalise_vectors(vectors, lindep_tol=lindep_tol) del vectors elif trial_vectors.shape[0] > 1: trial_vectors = _orthonormalise_vectors(trial_vectors, lindep_tol=lindep_tol) trial_vectors = trial_vectors[:max_trials] # Find the matrix-vector products for the trial vectors matrix_trial_vectors = np.stack( [matvec(trial_vectors[i]) for i in range(trial_vectors.shape[0])] ) # Add the trial vectors to the basis basis_vectors = np.concatenate((basis_vectors, trial_vectors)) matrix_basis_vectors = np.concatenate((matrix_basis_vectors, matrix_trial_vectors)) space += trial_vectors.shape[0] # Store the previous iteration results w_prev = w v_prev = v conv_prev = conv # Fill the matrix matrix = _fill_subspace_matrix( matrix, basis_vectors, matrix_basis_vectors, trial_vectors, matrix_trial_vectors ) del trial_vectors, matrix_trial_vectors # Solve the eigenvalue problem w, v, idx = pick( *np.linalg.eig(matrix[:space, :space]), nroots, basis_vectors=basis_vectors ) if not w.size: raise RuntimeError(\"Not enough eigenvalues found.\") # Sort the eigenvalues and eigenvectors w = w[:nroots] v = v[:, :nroots] conv = [False] * nroots if not restart: w_prev, conv_prev = _sort_eigenvalues(w_prev, conv_prev, v_prev, v) dw = w - w_prev if w_prev.size == w.size else w # Find the subspace vectors and matrix-vector products vectors = _outer_product_to_subspace(v, basis_vectors) matrix_vectors = _outer_product_to_subspace(v, matrix_basis_vectors) # Check convergence trial_vectors = matrix_vectors - w[:, None] * vectors norms = np.real(np.linalg.norm(trial_vectors, axis=1, ord=2)) conv = [np.abs(dw[k]) < e_tol and norms[k] < loose_tol for k in range(w.size)] del matrix_vectors if all(conv): break # Check for restart if follow_state and np.max(norms) > 1 and space > nroots + 4: vectors = _outer_product_to_subspace(v_prev, basis_vectors) restart = True continue # Remove subspace linear dependency and project out existing basis vectors trial_vectors = preconditioner(trial_vectors, w[0] - level_shift) trial_vectors = _project_vectors(trial_vectors, basis_vectors) trial_vectors = _normalise_vectors(trial_vectors, lindep_tol=lindep_tol) if trial_vectors.shape[0] == 0: conv = [conv[k] or (norm < loose_tol) for k, norm in enumerate(norms)] break # Check for restart restart = space + nroots > max_space # Call the callback if callback is not None: callback(locals()) if left: # Get the left eigenvectors instead wl, vl, v = scipy.linalg.eig(matrix[:space, :space], left=True) w, v, idx = pick(wl, v, nroots, basis_vectors=basis_vectors) if not w.size: raise RuntimeError(\"Not enough eigenvalues found.\") w = w[:nroots] vectors = _outer_product_to_subspace(vl[:, idx[:nroots]], basis_vectors) return conv, w, np.transpose(vectors)","title":"davidson"},{"location":"reference/core/dump/","text":"File dumping and reading functionality. ebcc.core.dump.Dump(name) File handler for reading and writing EBCC calculations. Parameters: name ( str ) \u2013 The name of the file. Initialise the file handler. Parameters: name ( str ) \u2013 The name of the file. Source code in ebcc/core/dump.py def __init__(self, name: str) -> None: \"\"\"Initialise the file handler. Args: name: The name of the file. \"\"\" self.name = name ebcc.core.dump.Dump.write(ebcc) Write the EBCC object to the file. Parameters: ebcc ( BaseEBCC ) \u2013 The EBCC object to write. Source code in ebcc/core/dump.py def write(self, ebcc: BaseEBCC) -> None: \"\"\"Write the EBCC object to the file. Args: ebcc: The EBCC object to write. \"\"\" # Write the options dic = {} for key, val in ebcc.options.__dict__.items(): if val is not None: dic[key] = val dump(self.name, \"options\", dic) # Write the mean-field data dic = { \"e_tot\": ebcc.mf.e_tot, \"mo_energy\": ebcc.mf.mo_energy, \"mo_coeff\": ebcc.mf.mo_coeff, \"mo_occ\": ebcc.mf.mo_occ, } dump_mol(ebcc.mf.mol, self.name) dump(self.name, \"mean-field\", dic) # Write the MOs used dic = { \"mo_coeff\": ebcc.mo_coeff, \"mo_occ\": ebcc.mo_occ, } dump(self.name, \"mo\", dic) # Write the ansatz dic = { \"fermion_ansatz\": ebcc.ansatz.fermion_ansatz, \"boson_ansatz\": ebcc.ansatz.boson_ansatz, \"fermion_coupling_rank\": ebcc.ansatz.fermion_coupling_rank, \"boson_coupling_rank\": ebcc.ansatz.boson_coupling_rank, } if ebcc.ansatz.module_name is not None: dic[\"module_name\"] = ebcc.ansatz.module_name dump(self.name, \"ansatz\", dic) # Write the space if ebcc.spin_type == \"U\": dic = { \"occupied\": (ebcc.space[0]._occupied, ebcc.space[1]._occupied), \"frozen\": (ebcc.space[0]._frozen, ebcc.space[1]._frozen), \"active\": (ebcc.space[0]._active, ebcc.space[1]._active), } else: dic = { \"occupied\": ebcc.space._occupied, \"frozen\": ebcc.space._frozen, \"active\": ebcc.space._active, } dump(self.name, \"space\", dic) # Write the bosonic parameters dic = {} if ebcc.omega is not None: dic[\"omega\"] = ebcc.omega if ebcc.bare_g is not None: dic[\"bare_g\"] = ebcc.bare_g if ebcc.bare_G is not None: dic[\"bare_G\"] = ebcc.bare_G dump(self.name, \"bosons\", dic) # Write the Fock matrix # TODO write the Fock matrix class instead # Write miscellaneous data kwargs: dict[str, Any] = { \"spin_type\": ebcc.spin_type, } if ebcc.e_corr is not None: kwargs[\"e_corr\"] = ebcc.e_corr if ebcc.converged is not None: kwargs[\"converged\"] = ebcc.converged if ebcc.converged_lambda is not None: kwargs[\"converged_lambda\"] = ebcc.converged_lambda dump(self.name, \"misc\", kwargs) # Write the amplitudes if ebcc.spin_type == \"U\": if ebcc.amplitudes is not None: dump( self.name, \"amplitudes\", { key: ({**val} if isinstance(val, (util.Namespace, dict)) else val) for key, val in ebcc.amplitudes.items() }, ) if ebcc.lambdas is not None: dump( self.name, \"lambdas\", { key: ({**val} if isinstance(val, (util.Namespace, dict)) else val) for key, val in ebcc.lambdas.items() }, ) else: if ebcc.amplitudes is not None: dump(self.name, \"amplitudes\", {**ebcc.amplitudes}) if ebcc.lambdas is not None: dump(self.name, \"lambdas\", {**ebcc.lambdas}) ebcc.core.dump.Dump.read(cls, log=None) Load the file to an EBCC object. Parameters: cls ( type [ BaseEBCC ] ) \u2013 EBCC class to load the file to. log ( Optional [ Logger ] , default: None ) \u2013 Logger to assign to the EBCC object. Returns: BaseEBCC \u2013 The EBCC object loaded from the file. Source code in ebcc/core/dump.py def read(self, cls: type[BaseEBCC], log: Optional[Logger] = None) -> BaseEBCC: \"\"\"Load the file to an EBCC object. Args: cls: EBCC class to load the file to. log: Logger to assign to the EBCC object. Returns: The EBCC object loaded from the file. \"\"\" # Load the options dic = load(self.name, \"options\") options = cls.Options() for key, val in dic.items(): setattr(options, key, val) # Load the miscellaneous data misc = load(self.name, \"misc\") spin_type = misc.pop(\"spin_type\").decode(\"ascii\") # Load the mean-field data mf_cls = {\"G\": scf.GHF, \"U\": scf.UHF, \"R\": scf.RHF}[spin_type] mol = load_mol(self.name) dic = load(self.name, \"mean-field\") mf = mf_cls(mol) mf.__dict__.update(dic) # Load the MOs used dic = load(self.name, \"mo\") mo_coeff = dic.get(\"mo_coeff\", None) mo_occ = dic.get(\"mo_occ\", None) # Load the ansatz dic = load(self.name, \"ansatz\") module_name = dic.get(\"module_name\", None) if isinstance(module_name, str): module_name = module_name.encode(\"ascii\") ansatz = Ansatz( dic.get(\"fermion_ansatz\", b\"CCSD\").decode(\"ascii\"), dic.get(\"boson_ansatz\", b\"\").decode(\"ascii\"), dic.get(\"fermion_coupling_rank\", 0), dic.get(\"boson_coupling_rank\", 0), module_name, ) # Load the space dic = load(self.name, \"space\") space: Union[Space, tuple[Space, Space]] if spin_type == \"U\": space = ( Space( dic.get(\"occupied\", None)[0], dic.get(\"frozen\", None)[0], dic.get(\"active\", None)[0], ), Space( dic.get(\"occupied\", None)[1], dic.get(\"frozen\", None)[1], dic.get(\"active\", None)[1], ), ) else: space = Space( dic.get(\"occupied\", None), dic.get(\"frozen\", None), dic.get(\"active\", None), ) # Load the bosonic parameters dic = load(self.name, \"bosons\") omega = dic.get(\"omega\", None) bare_g = dic.get(\"bare_g\", None) bare_G = dic.get(\"bare_G\", None) # Load the Fock matrix # TODO load the Fock matrix class instead # Load the amplitudes amplitudes = load(self.name, \"amplitudes\") lambdas = load(self.name, \"lambdas\") if spin_type == \"U\": if amplitudes is not None: amplitudes = { key: (util.Namespace(**val) if isinstance(val, dict) else val) for key, val in amplitudes.items() } amplitudes = util.Namespace(**amplitudes) if lambdas is not None: lambdas = { key: (util.Namespace(**val) if isinstance(val, dict) else val) for key, val in lambdas.items() } lambdas = util.Namespace(**lambdas) else: if amplitudes is not None: amplitudes = util.Namespace(**amplitudes) if lambdas is not None: lambdas = util.Namespace(**lambdas) # Initialise the EBCC object cc = cls( mf, log=log, ansatz=ansatz, space=space, omega=omega, g=bare_g, G=bare_G, mo_coeff=mo_coeff, mo_occ=mo_occ, # fock=fock, options=options, ) cc.__dict__.update(misc) cc.amplitudes = amplitudes cc.lambdas = lambdas return cc","title":"Dumping"},{"location":"reference/core/dump/#ebcc.core.dump.Dump","text":"File handler for reading and writing EBCC calculations. Parameters: name ( str ) \u2013 The name of the file. Initialise the file handler. Parameters: name ( str ) \u2013 The name of the file. Source code in ebcc/core/dump.py def __init__(self, name: str) -> None: \"\"\"Initialise the file handler. Args: name: The name of the file. \"\"\" self.name = name","title":"Dump"},{"location":"reference/core/dump/#ebcc.core.dump.Dump.write","text":"Write the EBCC object to the file. Parameters: ebcc ( BaseEBCC ) \u2013 The EBCC object to write. Source code in ebcc/core/dump.py def write(self, ebcc: BaseEBCC) -> None: \"\"\"Write the EBCC object to the file. Args: ebcc: The EBCC object to write. \"\"\" # Write the options dic = {} for key, val in ebcc.options.__dict__.items(): if val is not None: dic[key] = val dump(self.name, \"options\", dic) # Write the mean-field data dic = { \"e_tot\": ebcc.mf.e_tot, \"mo_energy\": ebcc.mf.mo_energy, \"mo_coeff\": ebcc.mf.mo_coeff, \"mo_occ\": ebcc.mf.mo_occ, } dump_mol(ebcc.mf.mol, self.name) dump(self.name, \"mean-field\", dic) # Write the MOs used dic = { \"mo_coeff\": ebcc.mo_coeff, \"mo_occ\": ebcc.mo_occ, } dump(self.name, \"mo\", dic) # Write the ansatz dic = { \"fermion_ansatz\": ebcc.ansatz.fermion_ansatz, \"boson_ansatz\": ebcc.ansatz.boson_ansatz, \"fermion_coupling_rank\": ebcc.ansatz.fermion_coupling_rank, \"boson_coupling_rank\": ebcc.ansatz.boson_coupling_rank, } if ebcc.ansatz.module_name is not None: dic[\"module_name\"] = ebcc.ansatz.module_name dump(self.name, \"ansatz\", dic) # Write the space if ebcc.spin_type == \"U\": dic = { \"occupied\": (ebcc.space[0]._occupied, ebcc.space[1]._occupied), \"frozen\": (ebcc.space[0]._frozen, ebcc.space[1]._frozen), \"active\": (ebcc.space[0]._active, ebcc.space[1]._active), } else: dic = { \"occupied\": ebcc.space._occupied, \"frozen\": ebcc.space._frozen, \"active\": ebcc.space._active, } dump(self.name, \"space\", dic) # Write the bosonic parameters dic = {} if ebcc.omega is not None: dic[\"omega\"] = ebcc.omega if ebcc.bare_g is not None: dic[\"bare_g\"] = ebcc.bare_g if ebcc.bare_G is not None: dic[\"bare_G\"] = ebcc.bare_G dump(self.name, \"bosons\", dic) # Write the Fock matrix # TODO write the Fock matrix class instead # Write miscellaneous data kwargs: dict[str, Any] = { \"spin_type\": ebcc.spin_type, } if ebcc.e_corr is not None: kwargs[\"e_corr\"] = ebcc.e_corr if ebcc.converged is not None: kwargs[\"converged\"] = ebcc.converged if ebcc.converged_lambda is not None: kwargs[\"converged_lambda\"] = ebcc.converged_lambda dump(self.name, \"misc\", kwargs) # Write the amplitudes if ebcc.spin_type == \"U\": if ebcc.amplitudes is not None: dump( self.name, \"amplitudes\", { key: ({**val} if isinstance(val, (util.Namespace, dict)) else val) for key, val in ebcc.amplitudes.items() }, ) if ebcc.lambdas is not None: dump( self.name, \"lambdas\", { key: ({**val} if isinstance(val, (util.Namespace, dict)) else val) for key, val in ebcc.lambdas.items() }, ) else: if ebcc.amplitudes is not None: dump(self.name, \"amplitudes\", {**ebcc.amplitudes}) if ebcc.lambdas is not None: dump(self.name, \"lambdas\", {**ebcc.lambdas})","title":"write"},{"location":"reference/core/dump/#ebcc.core.dump.Dump.read","text":"Load the file to an EBCC object. Parameters: cls ( type [ BaseEBCC ] ) \u2013 EBCC class to load the file to. log ( Optional [ Logger ] , default: None ) \u2013 Logger to assign to the EBCC object. Returns: BaseEBCC \u2013 The EBCC object loaded from the file. Source code in ebcc/core/dump.py def read(self, cls: type[BaseEBCC], log: Optional[Logger] = None) -> BaseEBCC: \"\"\"Load the file to an EBCC object. Args: cls: EBCC class to load the file to. log: Logger to assign to the EBCC object. Returns: The EBCC object loaded from the file. \"\"\" # Load the options dic = load(self.name, \"options\") options = cls.Options() for key, val in dic.items(): setattr(options, key, val) # Load the miscellaneous data misc = load(self.name, \"misc\") spin_type = misc.pop(\"spin_type\").decode(\"ascii\") # Load the mean-field data mf_cls = {\"G\": scf.GHF, \"U\": scf.UHF, \"R\": scf.RHF}[spin_type] mol = load_mol(self.name) dic = load(self.name, \"mean-field\") mf = mf_cls(mol) mf.__dict__.update(dic) # Load the MOs used dic = load(self.name, \"mo\") mo_coeff = dic.get(\"mo_coeff\", None) mo_occ = dic.get(\"mo_occ\", None) # Load the ansatz dic = load(self.name, \"ansatz\") module_name = dic.get(\"module_name\", None) if isinstance(module_name, str): module_name = module_name.encode(\"ascii\") ansatz = Ansatz( dic.get(\"fermion_ansatz\", b\"CCSD\").decode(\"ascii\"), dic.get(\"boson_ansatz\", b\"\").decode(\"ascii\"), dic.get(\"fermion_coupling_rank\", 0), dic.get(\"boson_coupling_rank\", 0), module_name, ) # Load the space dic = load(self.name, \"space\") space: Union[Space, tuple[Space, Space]] if spin_type == \"U\": space = ( Space( dic.get(\"occupied\", None)[0], dic.get(\"frozen\", None)[0], dic.get(\"active\", None)[0], ), Space( dic.get(\"occupied\", None)[1], dic.get(\"frozen\", None)[1], dic.get(\"active\", None)[1], ), ) else: space = Space( dic.get(\"occupied\", None), dic.get(\"frozen\", None), dic.get(\"active\", None), ) # Load the bosonic parameters dic = load(self.name, \"bosons\") omega = dic.get(\"omega\", None) bare_g = dic.get(\"bare_g\", None) bare_G = dic.get(\"bare_G\", None) # Load the Fock matrix # TODO load the Fock matrix class instead # Load the amplitudes amplitudes = load(self.name, \"amplitudes\") lambdas = load(self.name, \"lambdas\") if spin_type == \"U\": if amplitudes is not None: amplitudes = { key: (util.Namespace(**val) if isinstance(val, dict) else val) for key, val in amplitudes.items() } amplitudes = util.Namespace(**amplitudes) if lambdas is not None: lambdas = { key: (util.Namespace(**val) if isinstance(val, dict) else val) for key, val in lambdas.items() } lambdas = util.Namespace(**lambdas) else: if amplitudes is not None: amplitudes = util.Namespace(**amplitudes) if lambdas is not None: lambdas = util.Namespace(**lambdas) # Initialise the EBCC object cc = cls( mf, log=log, ansatz=ansatz, space=space, omega=omega, g=bare_g, G=bare_G, mo_coeff=mo_coeff, mo_occ=mo_occ, # fock=fock, options=options, ) cc.__dict__.update(misc) cc.amplitudes = amplitudes cc.lambdas = lambdas return cc","title":"read"},{"location":"reference/core/logging/","text":"Logging. ebcc.core.logging.Logger(name, level=logging.INFO) Bases: Logger Logger with a custom output level. Initialise the logger. Source code in ebcc/core/logging.py def __init__(self, name: str, level: int = logging.INFO) -> None: \"\"\"Initialise the logger.\"\"\" super().__init__(name, level) ebcc.core.logging.Logger.output(msg, *args, **kwargs) Output a message at the \"OUTPUT\" level. Source code in ebcc/core/logging.py def output(self, msg: str, *args: Any, **kwargs: Any) -> None: \"\"\"Output a message at the `\"OUTPUT\"` level.\"\"\" if self.isEnabledFor(25): self._log(25, msg, args, **kwargs) ebcc.core.logging.NullLogger(*args, **kwargs) Bases: Logger A logger that does nothing. Initialise the logger. Source code in ebcc/core/logging.py def __init__(self, *args: Any, **kwargs: Any) -> None: \"\"\"Initialise the logger.\"\"\" super().__init__(\"null\") ebcc.core.logging.init_logging(log) Initialise the logging with a header. Source code in ebcc/core/logging.py def init_logging(log: Logger) -> None: \"\"\"Initialise the logging with a header.\"\"\" if globals().get(\"_EBCC_LOG_INITIALISED\", False): return # Print header header_size = max([len(line) for line in HEADER.split(\"\\n\")]) space = \" \" * (header_size - len(__version__)) log.info(f\"{ANSI.B}{HEADER}{ANSI.R}\" % f\"{space}{ANSI.B}{__version__}{ANSI.R}\") # Print versions of dependencies and ebcc def get_git_hash(directory: str) -> str: git_directory = os.path.join(directory, \".git\") cmd = [\"git\", \"--git-dir=%s\" % git_directory, \"rev-parse\", \"--short\", \"HEAD\"] try: git_hash = subprocess.check_output( cmd, universal_newlines=True, stderr=subprocess.STDOUT ).rstrip() except subprocess.CalledProcessError: git_hash = \"N/A\" return git_hash import numpy import pyscf log.info(\"numpy:\") log.info(\" > Version: %s\" % numpy.__version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(numpy.__file__), \"..\"))) log.info(\"pyscf:\") log.info(\" > Version: %s\" % pyscf.__version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(pyscf.__file__), \"..\"))) log.info(\"ebcc:\") log.info(\" > Version: %s\" % __version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(__file__), \"..\"))) # Environment variables log.info(\"OMP_NUM_THREADS = %s\" % os.environ.get(\"OMP_NUM_THREADS\", \"\")) log.debug(\"\") globals()[\"_EBCC_LOG_INITIALISED\"] = True","title":"Logging"},{"location":"reference/core/logging/#ebcc.core.logging.Logger","text":"Bases: Logger Logger with a custom output level. Initialise the logger. Source code in ebcc/core/logging.py def __init__(self, name: str, level: int = logging.INFO) -> None: \"\"\"Initialise the logger.\"\"\" super().__init__(name, level)","title":"Logger"},{"location":"reference/core/logging/#ebcc.core.logging.Logger.output","text":"Output a message at the \"OUTPUT\" level. Source code in ebcc/core/logging.py def output(self, msg: str, *args: Any, **kwargs: Any) -> None: \"\"\"Output a message at the `\"OUTPUT\"` level.\"\"\" if self.isEnabledFor(25): self._log(25, msg, args, **kwargs)","title":"output"},{"location":"reference/core/logging/#ebcc.core.logging.NullLogger","text":"Bases: Logger A logger that does nothing. Initialise the logger. Source code in ebcc/core/logging.py def __init__(self, *args: Any, **kwargs: Any) -> None: \"\"\"Initialise the logger.\"\"\" super().__init__(\"null\")","title":"NullLogger"},{"location":"reference/core/logging/#ebcc.core.logging.init_logging","text":"Initialise the logging with a header. Source code in ebcc/core/logging.py def init_logging(log: Logger) -> None: \"\"\"Initialise the logging with a header.\"\"\" if globals().get(\"_EBCC_LOG_INITIALISED\", False): return # Print header header_size = max([len(line) for line in HEADER.split(\"\\n\")]) space = \" \" * (header_size - len(__version__)) log.info(f\"{ANSI.B}{HEADER}{ANSI.R}\" % f\"{space}{ANSI.B}{__version__}{ANSI.R}\") # Print versions of dependencies and ebcc def get_git_hash(directory: str) -> str: git_directory = os.path.join(directory, \".git\") cmd = [\"git\", \"--git-dir=%s\" % git_directory, \"rev-parse\", \"--short\", \"HEAD\"] try: git_hash = subprocess.check_output( cmd, universal_newlines=True, stderr=subprocess.STDOUT ).rstrip() except subprocess.CalledProcessError: git_hash = \"N/A\" return git_hash import numpy import pyscf log.info(\"numpy:\") log.info(\" > Version: %s\" % numpy.__version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(numpy.__file__), \"..\"))) log.info(\"pyscf:\") log.info(\" > Version: %s\" % pyscf.__version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(pyscf.__file__), \"..\"))) log.info(\"ebcc:\") log.info(\" > Version: %s\" % __version__) log.info(\" > Git hash: %s\" % get_git_hash(os.path.join(os.path.dirname(__file__), \"..\"))) # Environment variables log.info(\"OMP_NUM_THREADS = %s\" % os.environ.get(\"OMP_NUM_THREADS\", \"\")) log.debug(\"\") globals()[\"_EBCC_LOG_INITIALISED\"] = True","title":"init_logging"},{"location":"reference/core/precision/","text":"Floating point precision control. ebcc.core.precision.astype(value, dtype) Cast a value to the current floating point type. Parameters: value ( T ) \u2013 The value to cast. dtype ( Type [ T ] ) \u2013 The type to cast to. Returns: T \u2013 The value cast to the current floating point type. Source code in ebcc/core/precision.py def astype(value: T, dtype: Type[T]) -> T: \"\"\"Cast a value to the current floating point type. Args: value: The value to cast. dtype: The type to cast to. Returns: The value cast to the current floating point type. \"\"\" if BACKEND == \"jax\" and not TYPE_CHECKING: # Value may be traced, can't cast directly to the type return value.astype(types[dtype]) # type: ignore else: out: T = types[dtype](value) return out ebcc.core.precision.set_precision(**kwargs) Set the floating point type. Parameters: float \u2013 The floating point type to use. complex \u2013 The complex type to use. Source code in ebcc/core/precision.py def set_precision(**kwargs: type) -> None: \"\"\"Set the floating point type. Args: float: The floating point type to use. complex: The complex type to use. \"\"\" types[float] = kwargs.get(\"float\", types[float]) types[complex] = kwargs.get(\"complex\", types[complex]) ebcc.core.precision.precision(**kwargs) Context manager for setting the floating point precision. Parameters: float \u2013 The floating point type to use. complex \u2013 The complex type to use. Source code in ebcc/core/precision.py @contextmanager def precision(**kwargs: type) -> Iterator[None]: \"\"\"Context manager for setting the floating point precision. Args: float: The floating point type to use. complex: The complex type to use. \"\"\" old = { \"float\": types[float], \"complex\": types[complex], } set_precision(**kwargs) yield set_precision(**old) ebcc.core.precision.single_precision() Context manager for setting the floating point precision to single precision. Source code in ebcc/core/precision.py @contextmanager def single_precision() -> Iterator[None]: \"\"\"Context manager for setting the floating point precision to single precision.\"\"\" with precision(float=np.float32, complex=np.complex64): yield","title":"Precision"},{"location":"reference/core/precision/#ebcc.core.precision.astype","text":"Cast a value to the current floating point type. Parameters: value ( T ) \u2013 The value to cast. dtype ( Type [ T ] ) \u2013 The type to cast to. Returns: T \u2013 The value cast to the current floating point type. Source code in ebcc/core/precision.py def astype(value: T, dtype: Type[T]) -> T: \"\"\"Cast a value to the current floating point type. Args: value: The value to cast. dtype: The type to cast to. Returns: The value cast to the current floating point type. \"\"\" if BACKEND == \"jax\" and not TYPE_CHECKING: # Value may be traced, can't cast directly to the type return value.astype(types[dtype]) # type: ignore else: out: T = types[dtype](value) return out","title":"astype"},{"location":"reference/core/precision/#ebcc.core.precision.set_precision","text":"Set the floating point type. Parameters: float \u2013 The floating point type to use. complex \u2013 The complex type to use. Source code in ebcc/core/precision.py def set_precision(**kwargs: type) -> None: \"\"\"Set the floating point type. Args: float: The floating point type to use. complex: The complex type to use. \"\"\" types[float] = kwargs.get(\"float\", types[float]) types[complex] = kwargs.get(\"complex\", types[complex])","title":"set_precision"},{"location":"reference/core/precision/#ebcc.core.precision.precision","text":"Context manager for setting the floating point precision. Parameters: float \u2013 The floating point type to use. complex \u2013 The complex type to use. Source code in ebcc/core/precision.py @contextmanager def precision(**kwargs: type) -> Iterator[None]: \"\"\"Context manager for setting the floating point precision. Args: float: The floating point type to use. complex: The complex type to use. \"\"\" old = { \"float\": types[float], \"complex\": types[complex], } set_precision(**kwargs) yield set_precision(**old)","title":"precision"},{"location":"reference/core/precision/#ebcc.core.precision.single_precision","text":"Context manager for setting the floating point precision to single precision. Source code in ebcc/core/precision.py @contextmanager def single_precision() -> Iterator[None]: \"\"\"Context manager for setting the floating point precision to single precision.\"\"\" with precision(float=np.float32, complex=np.complex64): yield","title":"single_precision"},{"location":"reference/eom/","text":"Equation-of-motion coupled cluster solvers.","title":"Index"},{"location":"reference/eom/base/","text":"Base classes for ebcc.eom . ebcc.eom.base.BaseOptions(nroots=5, e_tol=1e-06, max_iter=100, max_space=12, koopmans=False, left=False) dataclass Options for EOM calculations. Parameters: nroots ( int , default: 5 ) \u2013 Number of roots to solver for. e_tol ( float , default: 1e-06 ) \u2013 Threshold for convergence in the eigenvalues. max_iter ( int , default: 100 ) \u2013 Maximum number of iterations. max_space ( int , default: 12 ) \u2013 Maximum size of the Lanczos vector space. koopmans ( bool , default: False ) \u2013 Whether to use a Koopmans'-like guess. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. ebcc.eom.base.BaseEOM(ebcc, options=None, **kwargs) Bases: ABC Base class for equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.base.BaseEOM.excitation_type: str abstractmethod property Get the type of excitation. ebcc.eom.base.BaseEOM.spin_type: str property Get the spin type. ebcc.eom.base.BaseEOM.name: str property Get the name of the method. ebcc.eom.base.BaseEOM.nmo: Any property Get the number of MOs. ebcc.eom.base.BaseEOM.nocc: Any property Get the number of occupied MOs. ebcc.eom.base.BaseEOM.nvir: Any property Get the number of virtual MOs. ebcc.eom.base.BaseEOM.amplitudes_to_vector(amplitudes) abstractmethod Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/eom/base.py @abstractmethod def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" pass ebcc.eom.base.BaseEOM.vector_to_amplitudes(vector) abstractmethod Construct amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/eom/base.py @abstractmethod def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" pass ebcc.eom.base.BaseEOM.matvec(vector, eris=None, ints=None, left=False) abstractmethod Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py @abstractmethod def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" pass ebcc.eom.base.BaseEOM.matvec_intermediates(eris=None, left=False) abstractmethod Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py @abstractmethod def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" pass ebcc.eom.base.BaseEOM.diag(eris=None) abstractmethod Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/base.py @abstractmethod def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" pass ebcc.eom.base.BaseEOM.get_pick(guesses=None) Get the function to pick the eigenvalues matching the criteria. Parameters: guesses ( Optional [ NDArray [ T ]] , default: None ) \u2013 Initial guesses for the roots. Returns: PickType [ T ] \u2013 Function to pick the eigenvalues. Source code in ebcc/eom/base.py def get_pick(self, guesses: Optional[NDArray[T]] = None) -> PickType[T]: \"\"\"Get the function to pick the eigenvalues matching the criteria. Args: guesses: Initial guesses for the roots. Returns: Function to pick the eigenvalues. \"\"\" if self.options.koopmans: assert guesses is not None def pick( w: NDArray[T], v: NDArray[T], nroots: int, basis_vectors: Optional[NDArray[T]] = None, ) -> tuple[NDArray[T], NDArray[T], NDArray[integer]]: \"\"\"Pick the eigenvalues using the overlap with the guess vector.\"\"\" assert basis_vectors is not None x0 = _outer_product_to_subspace(v, basis_vectors) s = np.dot(np.conj(guesses), np.transpose(x0)) s = np.real(np.linalg.norm(s, axis=0)) idx = np.argsort(-s)[:nroots] return make_eigenvectors_real(w, v, idx) else: pick = pick_real_eigenvalues return pick ebcc.eom.base.BaseEOM.get_guesses(diag=None) Get the initial guesses vectors. Parameters: diag ( Optional [ NDArray [ T ]] , default: None ) \u2013 Diagonal of the Hamiltonian. Returns: NDArray [ T ] \u2013 Initial guesses. Source code in ebcc/eom/base.py def get_guesses(self, diag: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Get the initial guesses vectors. Args: diag: Diagonal of the Hamiltonian. Returns: Initial guesses. \"\"\" if diag is None: diag = self.diag() arg = self._argsort_guesses(diag) nroots = min(self.options.nroots, diag.size) guesses: list[NDArray[T]] = [] for root, guess in enumerate(arg[:nroots]): guesses.append(np.eye(1, diag.size, guess, dtype=types[float])[0]) return np.stack(guesses) ebcc.eom.base.BaseEOM.callback(envs) Callback function for the eigensolver. Source code in ebcc/eom/base.py def callback(self, envs: dict[str, Any]) -> None: # noqa: B027 \"\"\"Callback function for the eigensolver.\"\"\" # noqa: D401 pass ebcc.eom.base.BaseEOM.davidson(eris=None, guesses=None) Solve the EOM Hamiltonian using the Davidson solver. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. guesses ( Optional [ NDArray [ T ]] , default: None ) \u2013 Initial guesses for the roots. Transposed with respect to the usual eigenvector convention (#FIXME). Returns: NDArray [ T ] \u2013 Energies of the roots. Source code in ebcc/eom/base.py def davidson( self, eris: Optional[ERIsInputType] = None, guesses: Optional[NDArray[T]] = None, ) -> NDArray[T]: \"\"\"Solve the EOM Hamiltonian using the Davidson solver. Args: eris: Electronic repulsion integrals. guesses: Initial guesses for the roots. Transposed with respect to the usual eigenvector convention (#FIXME). Returns: Energies of the roots. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.ebcc.get_eris(eris) self.log.output( \"Solving for %s excitations using the Davidson solver.\", self.excitation_type.upper() ) # Get the matrix-vector products and the diagonal: ints = self.matvec_intermediates(eris=eris, left=self.options.left) matvec = lambda v: self.matvec(v, eris=eris, ints=ints, left=self.options.left) diag = self.diag(eris=eris) # Get the guesses: if guesses is None: guesses = self.get_guesses(diag=diag) # Solve the EOM Hamiltonian: nroots = min(guesses.shape[0], self.options.nroots) pick = self.get_pick(guesses=guesses) converged, e, v = davidson( matvec, guesses, diag, e_tol=self.options.e_tol, nroots=nroots, pick=pick, max_iter=self.options.max_iter, max_space=self.options.max_space, callback=self.callback, ) # Check for convergence: if all(converged): self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") else: self.log.debug(\"\") self.log.warning( f\"{ANSI.r}Failed to converge {sum(not c for c in converged)} roots{ANSI.R}.\" ) # Update attributes: self.converged = all(converged) self.e = np.asarray(np.real(e), dtype=types[float]) self.v = np.asarray(np.real(v), dtype=types[float]) self.log.debug(\"\") self.log.output( f\"{ANSI.B}{'Root':>4s} {'Energy':>16s} {'Weight':>13s} {'Conv.':>8s}{ANSI.R}\" ) for n, (en, vn, cn) in enumerate(zip(self.e, np.transpose(self.v), converged)): r1n = self.vector_to_amplitudes(vn)[\"r1\"] qpwt = self._quasiparticle_weight(r1n) self.log.output( f\"%4d %16.10f %13.5g {[ANSI.r, ANSI.g][bool(cn)]}%8s{ANSI.R}\", n, np.ravel(en)[0], qpwt, bool(cn), ) self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") return self.e ebcc.eom.base.BaseIP_EOM(ebcc, options=None, **kwargs) Bases: BaseEOM Base class for ionisation-potential EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.base.BaseIP_EOM.excitation_type: str property Get the type of excitation. ebcc.eom.base.BaseIP_EOM.matvec(vector, eris=None, ints=None, left=False) Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ip\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res) ebcc.eom.base.BaseIP_EOM.matvec_intermediates(eris=None, left=False) Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ip_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res ebcc.eom.base.BaseEA_EOM(ebcc, options=None, **kwargs) Bases: BaseEOM Base class for electron-affinity EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.base.BaseEA_EOM.excitation_type: str property Get the type of excitation. ebcc.eom.base.BaseEA_EOM.matvec(vector, eris=None, ints=None, left=False) Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ea\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res) ebcc.eom.base.BaseEA_EOM.matvec_intermediates(eris=None, left=False) Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ea_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res ebcc.eom.base.BaseEE_EOM(ebcc, options=None, **kwargs) Bases: BaseEOM Base class for electron-electron EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.base.BaseEE_EOM.excitation_type: str property Get the type of excitation. ebcc.eom.base.BaseEE_EOM.matvec(vector, eris=None, ints=None, left=False) Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ee\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res) ebcc.eom.base.BaseEE_EOM.matvec_intermediates(eris=None, left=False) Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ee_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res","title":"Base"},{"location":"reference/eom/base/#ebcc.eom.base.BaseOptions","text":"Options for EOM calculations. Parameters: nroots ( int , default: 5 ) \u2013 Number of roots to solver for. e_tol ( float , default: 1e-06 ) \u2013 Threshold for convergence in the eigenvalues. max_iter ( int , default: 100 ) \u2013 Maximum number of iterations. max_space ( int , default: 12 ) \u2013 Maximum size of the Lanczos vector space. koopmans ( bool , default: False ) \u2013 Whether to use a Koopmans'-like guess. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian.","title":"BaseOptions"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM","text":"Bases: ABC Base class for equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"BaseEOM"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.excitation_type","text":"Get the type of excitation.","title":"excitation_type"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.spin_type","text":"Get the spin type.","title":"spin_type"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.name","text":"Get the name of the method.","title":"name"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.nmo","text":"Get the number of MOs.","title":"nmo"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.nocc","text":"Get the number of occupied MOs.","title":"nocc"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.nvir","text":"Get the number of virtual MOs.","title":"nvir"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.amplitudes_to_vector","text":"Construct a vector containing all of the amplitudes used in the given ansatz. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. Returns: NDArray [ T ] \u2013 Cluster amplitudes as a vector. Source code in ebcc/eom/base.py @abstractmethod def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the amplitudes used in the given ansatz. Args: amplitudes: Cluster amplitudes. Returns: Cluster amplitudes as a vector. \"\"\" pass","title":"amplitudes_to_vector"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.vector_to_amplitudes","text":"Construct amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 Cluster amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes. Source code in ebcc/eom/base.py @abstractmethod def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct amplitudes from a vector. Args: vector: Cluster amplitudes as a vector. Returns: Cluster amplitudes. \"\"\" pass","title":"vector_to_amplitudes"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.matvec","text":"Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py @abstractmethod def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" pass","title":"matvec"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.matvec_intermediates","text":"Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py @abstractmethod def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" pass","title":"matvec_intermediates"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/base.py @abstractmethod def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" pass","title":"diag"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.get_pick","text":"Get the function to pick the eigenvalues matching the criteria. Parameters: guesses ( Optional [ NDArray [ T ]] , default: None ) \u2013 Initial guesses for the roots. Returns: PickType [ T ] \u2013 Function to pick the eigenvalues. Source code in ebcc/eom/base.py def get_pick(self, guesses: Optional[NDArray[T]] = None) -> PickType[T]: \"\"\"Get the function to pick the eigenvalues matching the criteria. Args: guesses: Initial guesses for the roots. Returns: Function to pick the eigenvalues. \"\"\" if self.options.koopmans: assert guesses is not None def pick( w: NDArray[T], v: NDArray[T], nroots: int, basis_vectors: Optional[NDArray[T]] = None, ) -> tuple[NDArray[T], NDArray[T], NDArray[integer]]: \"\"\"Pick the eigenvalues using the overlap with the guess vector.\"\"\" assert basis_vectors is not None x0 = _outer_product_to_subspace(v, basis_vectors) s = np.dot(np.conj(guesses), np.transpose(x0)) s = np.real(np.linalg.norm(s, axis=0)) idx = np.argsort(-s)[:nroots] return make_eigenvectors_real(w, v, idx) else: pick = pick_real_eigenvalues return pick","title":"get_pick"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.get_guesses","text":"Get the initial guesses vectors. Parameters: diag ( Optional [ NDArray [ T ]] , default: None ) \u2013 Diagonal of the Hamiltonian. Returns: NDArray [ T ] \u2013 Initial guesses. Source code in ebcc/eom/base.py def get_guesses(self, diag: Optional[NDArray[T]] = None) -> NDArray[T]: \"\"\"Get the initial guesses vectors. Args: diag: Diagonal of the Hamiltonian. Returns: Initial guesses. \"\"\" if diag is None: diag = self.diag() arg = self._argsort_guesses(diag) nroots = min(self.options.nroots, diag.size) guesses: list[NDArray[T]] = [] for root, guess in enumerate(arg[:nroots]): guesses.append(np.eye(1, diag.size, guess, dtype=types[float])[0]) return np.stack(guesses)","title":"get_guesses"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.callback","text":"Callback function for the eigensolver. Source code in ebcc/eom/base.py def callback(self, envs: dict[str, Any]) -> None: # noqa: B027 \"\"\"Callback function for the eigensolver.\"\"\" # noqa: D401 pass","title":"callback"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEOM.davidson","text":"Solve the EOM Hamiltonian using the Davidson solver. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. guesses ( Optional [ NDArray [ T ]] , default: None ) \u2013 Initial guesses for the roots. Transposed with respect to the usual eigenvector convention (#FIXME). Returns: NDArray [ T ] \u2013 Energies of the roots. Source code in ebcc/eom/base.py def davidson( self, eris: Optional[ERIsInputType] = None, guesses: Optional[NDArray[T]] = None, ) -> NDArray[T]: \"\"\"Solve the EOM Hamiltonian using the Davidson solver. Args: eris: Electronic repulsion integrals. guesses: Initial guesses for the roots. Transposed with respect to the usual eigenvector convention (#FIXME). Returns: Energies of the roots. \"\"\" timer = util.Timer() # Get the ERIs: eris = self.ebcc.get_eris(eris) self.log.output( \"Solving for %s excitations using the Davidson solver.\", self.excitation_type.upper() ) # Get the matrix-vector products and the diagonal: ints = self.matvec_intermediates(eris=eris, left=self.options.left) matvec = lambda v: self.matvec(v, eris=eris, ints=ints, left=self.options.left) diag = self.diag(eris=eris) # Get the guesses: if guesses is None: guesses = self.get_guesses(diag=diag) # Solve the EOM Hamiltonian: nroots = min(guesses.shape[0], self.options.nroots) pick = self.get_pick(guesses=guesses) converged, e, v = davidson( matvec, guesses, diag, e_tol=self.options.e_tol, nroots=nroots, pick=pick, max_iter=self.options.max_iter, max_space=self.options.max_space, callback=self.callback, ) # Check for convergence: if all(converged): self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") else: self.log.debug(\"\") self.log.warning( f\"{ANSI.r}Failed to converge {sum(not c for c in converged)} roots{ANSI.R}.\" ) # Update attributes: self.converged = all(converged) self.e = np.asarray(np.real(e), dtype=types[float]) self.v = np.asarray(np.real(v), dtype=types[float]) self.log.debug(\"\") self.log.output( f\"{ANSI.B}{'Root':>4s} {'Energy':>16s} {'Weight':>13s} {'Conv.':>8s}{ANSI.R}\" ) for n, (en, vn, cn) in enumerate(zip(self.e, np.transpose(self.v), converged)): r1n = self.vector_to_amplitudes(vn)[\"r1\"] qpwt = self._quasiparticle_weight(r1n) self.log.output( f\"%4d %16.10f %13.5g {[ANSI.r, ANSI.g][bool(cn)]}%8s{ANSI.R}\", n, np.ravel(en)[0], qpwt, bool(cn), ) self.log.debug(\"\") self.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.log.debug(\"\") return self.e","title":"davidson"},{"location":"reference/eom/base/#ebcc.eom.base.BaseIP_EOM","text":"Bases: BaseEOM Base class for ionisation-potential EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"BaseIP_EOM"},{"location":"reference/eom/base/#ebcc.eom.base.BaseIP_EOM.excitation_type","text":"Get the type of excitation.","title":"excitation_type"},{"location":"reference/eom/base/#ebcc.eom.base.BaseIP_EOM.matvec","text":"Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ip\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res)","title":"matvec"},{"location":"reference/eom/base/#ebcc.eom.base.BaseIP_EOM.matvec_intermediates","text":"Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ip_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res","title":"matvec_intermediates"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEA_EOM","text":"Bases: BaseEOM Base class for electron-affinity EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"BaseEA_EOM"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEA_EOM.excitation_type","text":"Get the type of excitation.","title":"excitation_type"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEA_EOM.matvec","text":"Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ea\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res)","title":"matvec"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEA_EOM.matvec_intermediates","text":"Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ea_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res","title":"matvec_intermediates"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEE_EOM","text":"Bases: BaseEOM Base class for electron-electron EOM-CC. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"BaseEE_EOM"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEE_EOM.excitation_type","text":"Get the type of excitation.","title":"excitation_type"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEE_EOM.matvec","text":"Apply the Hamiltonian to a vector. Parameters: vector ( NDArray [ T ] ) \u2013 State vector to apply the Hamiltonian to. eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. ints ( Optional [ Namespace [ NDArray [ T ]]] , default: None ) \u2013 Intermediate products. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: NDArray [ T ] \u2013 Resulting vector. Source code in ebcc/eom/base.py def matvec( self, vector: NDArray[T], eris: Optional[ERIsInputType] = None, ints: Optional[Namespace[NDArray[T]]] = None, left: bool = False, ) -> NDArray[T]: \"\"\"Apply the Hamiltonian to a vector. Args: vector: State vector to apply the Hamiltonian to. eris: Electronic repulsion integrals. ints: Intermediate products. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Resulting vector. \"\"\" if not ints: ints = self.matvec_intermediates(eris=eris, left=left) amplitudes = self.vector_to_amplitudes(vector) func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ee\", eris=eris, ints=ints, amplitudes=self.ebcc.amplitudes, excitations=amplitudes, ) res: Namespace[SpinArrayType] = func(**kwargs) res = util.Namespace(**{key.rstrip(\"new\"): val for key, val in res.items()}) return self.amplitudes_to_vector(res)","title":"matvec"},{"location":"reference/eom/base/#ebcc.eom.base.BaseEE_EOM.matvec_intermediates","text":"Get the intermediates for application of the Hamiltonian to a vector. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. left ( bool , default: False ) \u2013 Whether to apply the left-hand side of the Hamiltonian. Returns: Namespace [ NDArray [ T ]] \u2013 Intermediate products. Source code in ebcc/eom/base.py def matvec_intermediates( self, eris: Optional[ERIsInputType] = None, left: bool = False ) -> Namespace[NDArray[T]]: \"\"\"Get the intermediates for application of the Hamiltonian to a vector. Args: eris: Electronic repulsion integrals. left: Whether to apply the left-hand side of the Hamiltonian. Returns: Intermediate products. \"\"\" func, kwargs = self.ebcc._load_function( f\"hbar_{'l' if left else ''}matvec_ee_intermediates\", eris=eris, amplitudes=self.ebcc.amplitudes, ) res: Namespace[NDArray[T]] = util.Namespace(**func(**kwargs)) return res","title":"matvec_intermediates"},{"location":"reference/eom/geom/","text":"Generalised equation-of-motion coupled cluster. ebcc.eom.geom.GEOM(ebcc, options=None, **kwargs) Bases: BaseEOM Generalised equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.geom.IP_GEOM(ebcc, options=None, **kwargs) Bases: GEOM , BaseIP_EOM Generalised ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.geom.IP_GEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.geom.IP_GEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.geom.IP_GEOM.vector_to_amplitudes(vector) Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return amplitudes ebcc.eom.geom.EA_GEOM(ebcc, options=None, **kwargs) Bases: GEOM , BaseEA_EOM Generalised electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.geom.EA_GEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.geom.EA_GEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.geom.EA_GEOM.vector_to_amplitudes(vector) Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return amplitudes ebcc.eom.geom.EE_GEOM(ebcc, options=None, **kwargs) Bases: GEOM , BaseEE_EOM Generalised electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.geom.EE_GEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.geom.EE_GEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.geom.EE_GEOM.vector_to_amplitudes(vector) Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return amplitudes","title":"Generalised"},{"location":"reference/eom/geom/#ebcc.eom.geom.GEOM","text":"Bases: BaseEOM Generalised equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"GEOM"},{"location":"reference/eom/geom/#ebcc.eom.geom.IP_GEOM","text":"Bases: GEOM , BaseIP_EOM Generalised ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"IP_GEOM"},{"location":"reference/eom/geom/#ebcc.eom.geom.IP_GEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/geom/#ebcc.eom.geom.IP_GEOM.amplitudes_to_vector","text":"Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/geom/#ebcc.eom.geom.IP_GEOM.vector_to_amplitudes","text":"Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/geom/#ebcc.eom.geom.EA_GEOM","text":"Bases: GEOM , BaseEA_EOM Generalised electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EA_GEOM"},{"location":"reference/eom/geom/#ebcc.eom.geom.EA_GEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/geom/#ebcc.eom.geom.EA_GEOM.amplitudes_to_vector","text":"Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/geom/#ebcc.eom.geom.EA_GEOM.vector_to_amplitudes","text":"Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/geom/#ebcc.eom.geom.EE_GEOM","text":"Bases: GEOM , BaseEE_EOM Generalised electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EE_GEOM"},{"location":"reference/eom/geom/#ebcc.eom.geom.EE_GEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/geom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/geom/#ebcc.eom.geom.EE_GEOM.amplitudes_to_vector","text":"Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/geom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): vectors.append(np.ravel(util.compress_axes(key, amplitudes[name]))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/geom/#ebcc.eom.geom.EE_GEOM.vector_to_amplitudes","text":"Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/geom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): size = util.get_compressed_size(key, **{k: self.space.size(k) for k in set(key)}) shape = tuple(self.space.size(k) for k in key) vn_tril = vector[i0 : i0 + size] vn = util.decompress_axes(key, vn_tril, shape=shape) amplitudes[name] = vn i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/reom/","text":"Restricted equation-of-motion coupled cluster. ebcc.eom.reom.REOM(ebcc, options=None, **kwargs) Bases: BaseEOM Restricted equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.reom.IP_REOM(ebcc, options=None, **kwargs) Bases: REOM , BaseIP_EOM Restricted ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.reom.IP_REOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.reom.IP_REOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.reom.IP_REOM.vector_to_amplitudes(vector) Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return amplitudes ebcc.eom.reom.EA_REOM(ebcc, options=None, **kwargs) Bases: REOM , BaseEA_EOM Restricted electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.reom.EA_REOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.reom.EA_REOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.reom.EA_REOM.vector_to_amplitudes(vector) Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return amplitudes ebcc.eom.reom.EE_REOM(ebcc, options=None, **kwargs) Bases: REOM , BaseEE_EOM Restricted electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.reom.EE_REOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.reom.EE_REOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.reom.EE_REOM.vector_to_amplitudes(vector) Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return amplitudes","title":"Restricted"},{"location":"reference/eom/reom/#ebcc.eom.reom.REOM","text":"Bases: BaseEOM Restricted equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"REOM"},{"location":"reference/eom/reom/#ebcc.eom.reom.IP_REOM","text":"Bases: REOM , BaseIP_EOM Restricted ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"IP_REOM"},{"location":"reference/eom/reom/#ebcc.eom.reom.IP_REOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/reom/#ebcc.eom.reom.IP_REOM.amplitudes_to_vector","text":"Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/reom/#ebcc.eom.reom.IP_REOM.vector_to_amplitudes","text":"Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/reom/#ebcc.eom.reom.EA_REOM","text":"Bases: REOM , BaseEA_EOM Restricted electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EA_REOM"},{"location":"reference/eom/reom/#ebcc.eom.reom.EA_REOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): parts[name] = self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/reom/#ebcc.eom.reom.EA_REOM.amplitudes_to_vector","text":"Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/reom/#ebcc.eom.reom.EA_REOM.vector_to_amplitudes","text":"Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/reom/#ebcc.eom.reom.EE_REOM","text":"Bases: REOM , BaseEE_EOM Restricted electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EE_REOM"},{"location":"reference/eom/reom/#ebcc.eom.reom.EE_REOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/reom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): parts[name] = -self.ebcc.energy_sum(key) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/reom/#ebcc.eom.reom.EE_REOM.amplitudes_to_vector","text":"Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/reom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): vectors.append(np.ravel(amplitudes[name])) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/reom/#ebcc.eom.reom.EE_REOM.vector_to_amplitudes","text":"Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/reom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): shape = tuple(self.space.size(k) for k in key) size = util.prod(shape) amplitudes[name] = np.reshape(vector[i0 : i0 + size], shape) i0 += size for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/ueom/","text":"Unrestricted equation-of-motion coupled cluster. ebcc.eom.ueom.UEOM(ebcc, options=None, **kwargs) Bases: BaseEOM Unrestricted equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.ueom.IP_UEOM(ebcc, options=None, **kwargs) Bases: UEOM , BaseIP_EOM Unrestricted ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.ueom.IP_UEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, excited=True): spin_part[comb] = self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.ueom.IP_UEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): for spin in util.generate_spin_combinations(n, excited=True, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.ueom.IP_UEOM.vector_to_amplitudes(vector) Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, excited=True, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes ebcc.eom.ueom.EA_UEOM(ebcc, options=None, **kwargs) Bases: UEOM , BaseEA_EOM Unrestricted electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.ueom.EA_UEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, excited=True): spin_part[comb] = -self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.ueom.EA_UEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): for spin in util.generate_spin_combinations(n, excited=True, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.ueom.EA_UEOM.vector_to_amplitudes(vector) Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, excited=True, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes ebcc.eom.ueom.EE_UEOM(ebcc, options=None, **kwargs) Bases: UEOM , BaseEE_EOM Unrestricted electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\") ebcc.eom.ueom.EE_UEOM.diag(eris=None) Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): spin_part[comb] = self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts) ebcc.eom.ueom.EE_UEOM.amplitudes_to_vector(amplitudes) Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): for spin in util.generate_spin_combinations(n, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors) ebcc.eom.ueom.EE_UEOM.vector_to_amplitudes(vector) Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes","title":"Unrestricted"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.UEOM","text":"Bases: BaseEOM Unrestricted equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"UEOM"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.IP_UEOM","text":"Bases: UEOM , BaseIP_EOM Unrestricted ionisation potential equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"IP_UEOM"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.IP_UEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, excited=True): spin_part[comb] = self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.IP_UEOM.amplitudes_to_vector","text":"Construct a vector containing all of the IP-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 IP-EOM amplitudes. Returns: NDArray [ T ] \u2013 IP-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the IP-EOM amplitudes. Args: amplitudes: IP-EOM amplitudes. Returns: IP-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): for spin in util.generate_spin_combinations(n, excited=True, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.IP_UEOM.vector_to_amplitudes","text":"Construct a namespace of IP-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 IP-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 IP-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of IP-EOM amplitudes from a vector. Args: vector: IP-EOM amplitudes as a vector. Returns: IP-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, excited=True, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ip\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ip\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EA_UEOM","text":"Bases: UEOM , BaseEA_EOM Unrestricted electron affinity equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EA_UEOM"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EA_UEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, excited=True): spin_part[comb] = -self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EA_UEOM.amplitudes_to_vector","text":"Construct a vector containing all of the EA-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EA-EOM amplitudes. Returns: NDArray [ T ] \u2013 EA-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EA-EOM amplitudes. Args: amplitudes: EA-EOM amplitudes. Returns: EA-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): for spin in util.generate_spin_combinations(n, excited=True, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EA_UEOM.vector_to_amplitudes","text":"Construct a namespace of EA-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EA-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EA-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EA-EOM amplitudes from a vector. Args: vector: EA-EOM amplitudes as a vector. Returns: EA-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, excited=True, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ea\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ea\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EE_UEOM","text":"Bases: UEOM , BaseEE_EOM Unrestricted electron-electron equation-of-motion coupled cluster. Initialise the EOM object. Parameters: ebcc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/eom/base.py def __init__( self, ebcc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the EOM object. Args: ebcc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.ebcc = ebcc self.space = ebcc.space self.ansatz = ebcc.ansatz self.log = ebcc.log # Attributes: self.converged = False self.e: NDArray[T] = np.zeros((0,), dtype=types[float]) self.v: NDArray[T] = np.zeros((0, 0), dtype=types[float]) # Logging: self.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") self.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") self.log.debug(\"\") self.log.info(f\"{ANSI.B}Options{ANSI.R}:\") self.log.info(f\" > nroots: {ANSI.y}{self.options.nroots}{ANSI.R}\") self.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") self.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") self.log.info(f\" > max_space: {ANSI.y}{self.options.max_space}{ANSI.R}\") self.log.debug(\"\")","title":"EE_UEOM"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EE_UEOM.diag","text":"Get the diagonal of the Hamiltonian. Parameters: eris ( Optional [ ERIsInputType ] , default: None ) \u2013 Electronic repulsion integrals. Returns: NDArray [ T ] \u2013 Diagonal of the Hamiltonian. Source code in ebcc/eom/ueom.py def diag(self, eris: Optional[ERIsInputType] = None) -> NDArray[T]: \"\"\"Get the diagonal of the Hamiltonian. Args: eris: Electronic repulsion integrals. Returns: Diagonal of the Hamiltonian. \"\"\" parts: Namespace[SpinArrayType] = util.Namespace() for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): spin_part: SpinArrayType = util.Namespace() for comb in util.generate_spin_combinations(n, unique=True): spin_part[comb] = self.ebcc.energy_sum(key, comb) parts[name] = spin_part for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented return self.amplitudes_to_vector(parts)","title":"diag"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EE_UEOM.amplitudes_to_vector","text":"Construct a vector containing all of the EE-EOM amplitudes. Parameters: amplitudes ( Namespace [ SpinArrayType ] ) \u2013 EE-EOM amplitudes. Returns: NDArray [ T ] \u2013 EE-EOM amplitudes as a vector. Source code in ebcc/eom/ueom.py def amplitudes_to_vector(self, amplitudes: Namespace[SpinArrayType]) -> NDArray[T]: \"\"\"Construct a vector containing all of the EE-EOM amplitudes. Args: amplitudes: EE-EOM amplitudes. Returns: EE-EOM amplitudes as a vector. \"\"\" vectors = [] for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): for spin in util.generate_spin_combinations(n, unique=True): vn = amplitudes[name][spin] subscript, _ = util.combine_subscripts(key, spin) vectors.append(np.ravel(util.compress_axes(subscript, vn))) for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented return np.concatenate(vectors)","title":"amplitudes_to_vector"},{"location":"reference/eom/ueom/#ebcc.eom.ueom.EE_UEOM.vector_to_amplitudes","text":"Construct a namespace of EE-EOM amplitudes from a vector. Parameters: vector ( NDArray [ T ] ) \u2013 EE-EOM amplitudes as a vector. Returns: Namespace [ SpinArrayType ] \u2013 EE-EOM amplitudes. Source code in ebcc/eom/ueom.py def vector_to_amplitudes(self, vector: NDArray[T]) -> Namespace[SpinArrayType]: \"\"\"Construct a namespace of EE-EOM amplitudes from a vector. Args: vector: EE-EOM amplitudes as a vector. Returns: EE-EOM amplitudes. \"\"\" amplitudes: Namespace[SpinArrayType] = util.Namespace() i0 = 0 sizes: dict[tuple[str, ...], int] = { (o, s): self.space[i].size(o) for o in \"ovOVia\" for i, s in enumerate(\"ab\") } for name, key, n in self.ansatz.fermionic_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): amp: SpinArrayType = util.Namespace() for spin in util.generate_spin_combinations(n, unique=True): subscript, csizes = util.combine_subscripts(key, spin, sizes=sizes) size = util.get_compressed_size(subscript, **csizes) shape = tuple(self.space[\"ab\".index(s)].size(k) for s, k in zip(spin, key)) vn_tril = vector[i0 : i0 + size] factor = max( spin[:n].count(s) for s in set(spin[:n]) ) # FIXME why? untested for n > 2 vn = util.decompress_axes(subscript, vn_tril, shape=shape) / factor amp[spin] = vn i0 += size amplitudes[name] = amp for name, key, n in self.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type, which=\"ee\"): raise util.ModelNotImplemented for name, key, nf, nb in self.ansatz.coupling_cluster_ranks( spin_type=self.spin_type, which=\"ee\" ): raise util.ModelNotImplemented assert i0 == len(vector) return amplitudes","title":"vector_to_amplitudes"},{"location":"reference/ext/","text":"External corrections.","title":"Index"},{"location":"reference/ext/eccc/","text":"Externally corrected coupled cluster. ebcc.ext.eccc.BaseOptions(mixed_terms_strategy='fixed') dataclass Bases: _BaseOptions Options for ecCC calculations. Parameters: mixed_terms_strategy ( Literal ['fixed', 'update', 'ignore'] , default: 'fixed' ) \u2013 Strategy for mixed terms. If \"fixed\", the mixed terms are calculated once and kept fixed. If \"update\", the mixed terms are recalculated at each iteration. If \"ignore\", the mixed terms are not calculated at all. ebcc.ext.eccc.BaseExternalCorrection(cc, amplitudes, options=None, **kwargs) Bases: AbstractContextManager [None] Context manager for externally correcting an EBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\") ebcc.ext.eccc.BaseExternalCorrection.__enter__() Enter the context manager. Source code in ebcc/ext/eccc.py def __enter__(self) -> None: \"\"\"Enter the context manager.\"\"\" # Save the original update_amps method self._update_amps_old = self.cc.update_amps # Get the ERIs eris = self.cc.get_eris() # Get the fixed external corrections amplitudes = self._get_external_amplitudes() ext = self._update_external_corrections(eris=eris, amplitudes=amplitudes, which=\"external\") if self.options.mixed_terms_strategy != \"ignore\": mix = self._update_external_corrections(eris=eris, amplitudes=amplitudes, which=\"mixed\") def update_amps( eris: Optional[Any] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes.\"\"\" # Update the mixed terms if necessary nonlocal mix if self.options.mixed_terms_strategy == \"update\" or ( self.options.mixed_terms_strategy == \"fixed\" and mix is None ): if amplitudes is None: raise ValueError( \"Cannot update mixed terms of the external corrections without \" \"providing the cluster amplitudes.\" ) amplitudes_full = amplitudes.copy() for key, val in self.amplitudes.items(): if key not in amplitudes_full: amplitudes_full[key] = val mix = self._update_external_corrections( eris=eris, amplitudes=amplitudes_full, which=\"mixed\" ) # Perform the original update_amps method assert self._update_amps_old is not None amps = self._update_amps_old(eris=eris, amplitudes=amplitudes) # Add the external corrections self._add_to_amps(amps, ext) if self.options.mixed_terms_strategy != \"ignore\": self._add_to_amps(amps, mix) return amps # Replace the original update_amps method update_amps.__doc__ = self._update_amps_old.__doc__ self.cc.update_amps = update_amps # type: ignore[method-assign] ebcc.ext.eccc.BaseExternalCorrection.__exit__(*args) Exit the context manager. Source code in ebcc/ext/eccc.py def __exit__(self, *args: Any) -> None: \"\"\"Exit the context manager.\"\"\" # Restore the original update_amps method assert self._update_amps_old is not None self.cc.update_amps = self._update_amps_old # type: ignore[method-assign] self._update_amps_old = None ebcc.ext.eccc.ExternalCorrectionREBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseExternalCorrection Context manager for externally correcting a REBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\") ebcc.ext.eccc.ExternalCorrectionUEBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseExternalCorrection Context manager for externally correcting a UEBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\") ebcc.ext.eccc.ExternalCorrectionGEBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseExternalCorrection Context manager for externally correcting a GEBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\")","title":"Eccc"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.BaseOptions","text":"Bases: _BaseOptions Options for ecCC calculations. Parameters: mixed_terms_strategy ( Literal ['fixed', 'update', 'ignore'] , default: 'fixed' ) \u2013 Strategy for mixed terms. If \"fixed\", the mixed terms are calculated once and kept fixed. If \"update\", the mixed terms are recalculated at each iteration. If \"ignore\", the mixed terms are not calculated at all.","title":"BaseOptions"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.BaseExternalCorrection","text":"Bases: AbstractContextManager [None] Context manager for externally correcting an EBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\")","title":"BaseExternalCorrection"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.BaseExternalCorrection.__enter__","text":"Enter the context manager. Source code in ebcc/ext/eccc.py def __enter__(self) -> None: \"\"\"Enter the context manager.\"\"\" # Save the original update_amps method self._update_amps_old = self.cc.update_amps # Get the ERIs eris = self.cc.get_eris() # Get the fixed external corrections amplitudes = self._get_external_amplitudes() ext = self._update_external_corrections(eris=eris, amplitudes=amplitudes, which=\"external\") if self.options.mixed_terms_strategy != \"ignore\": mix = self._update_external_corrections(eris=eris, amplitudes=amplitudes, which=\"mixed\") def update_amps( eris: Optional[Any] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes.\"\"\" # Update the mixed terms if necessary nonlocal mix if self.options.mixed_terms_strategy == \"update\" or ( self.options.mixed_terms_strategy == \"fixed\" and mix is None ): if amplitudes is None: raise ValueError( \"Cannot update mixed terms of the external corrections without \" \"providing the cluster amplitudes.\" ) amplitudes_full = amplitudes.copy() for key, val in self.amplitudes.items(): if key not in amplitudes_full: amplitudes_full[key] = val mix = self._update_external_corrections( eris=eris, amplitudes=amplitudes_full, which=\"mixed\" ) # Perform the original update_amps method assert self._update_amps_old is not None amps = self._update_amps_old(eris=eris, amplitudes=amplitudes) # Add the external corrections self._add_to_amps(amps, ext) if self.options.mixed_terms_strategy != \"ignore\": self._add_to_amps(amps, mix) return amps # Replace the original update_amps method update_amps.__doc__ = self._update_amps_old.__doc__ self.cc.update_amps = update_amps # type: ignore[method-assign]","title":"__enter__"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.BaseExternalCorrection.__exit__","text":"Exit the context manager. Source code in ebcc/ext/eccc.py def __exit__(self, *args: Any) -> None: \"\"\"Exit the context manager.\"\"\" # Restore the original update_amps method assert self._update_amps_old is not None self.cc.update_amps = self._update_amps_old # type: ignore[method-assign] self._update_amps_old = None","title":"__exit__"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.ExternalCorrectionREBCC","text":"Bases: BaseExternalCorrection Context manager for externally correcting a REBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\")","title":"ExternalCorrectionREBCC"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.ExternalCorrectionUEBCC","text":"Bases: BaseExternalCorrection Context manager for externally correcting a UEBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\")","title":"ExternalCorrectionUEBCC"},{"location":"reference/ext/eccc/#ebcc.ext.eccc.ExternalCorrectionGEBCC","text":"Bases: BaseExternalCorrection Context manager for externally correcting a GEBCC calculation. This context manager is used to externally correct an EBCC calculation by updating the T1 and T2 amplitudes according to some T3 and T4 amplitudes passed as an argument. The T3 and T4 amplitudes are assumed to span the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the ecCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/eccc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the ecCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}external corrections{ANSI.R}.\") self.cc.log.info( f\" > mixed_terms_strategy: {ANSI.y}{self.options.mixed_terms_strategy}{ANSI.R}\" ) self.cc.log.debug(\"\")","title":"ExternalCorrectionGEBCC"},{"location":"reference/ext/fci/","text":"Tools for FCI solvers to get amplitudes. ebcc.ext.fci.fci_to_amplitudes_restricted(fci, space, max_order=4) Extract amplitudes from an FCI calculation with restricted symmetry. The FCI calculatiion should have been performed in the active space according to the given space , i.e. using mo_coeff[:, space.active] . Parameters: fci ( FCI ) \u2013 PySCF FCI object. space ( Space ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. max_order ( int , default: 4 ) \u2013 Maximum order of the excitation. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes in the active space. Source code in ebcc/ext/fci.py def fci_to_amplitudes_restricted( fci: FCI, space: Space, max_order: int = 4 ) -> Namespace[RSpinArrayType]: \"\"\"Extract amplitudes from an FCI calculation with restricted symmetry. The FCI calculatiion should have been performed in the active space according to the given `space`, i.e. using `mo_coeff[:, space.active]`. Args: fci: PySCF FCI object. space: Space containing the frozen, correlated, and active fermionic spaces. max_order: Maximum order of the excitation. Returns: Cluster amplitudes in the active space. \"\"\" return _ci_vector_to_amplitudes_restricted(fci.ci, space, max_order=max_order) ebcc.ext.fci.fci_to_amplitudes_unrestricted(fci, space, max_order=4) Extract amplitudes from an FCI calculation with unrestricted symmetry. The FCI calculatiion should have been performed in the active space according to the given space , i.e. using mo_coeff[:, space.active] . Parameters: fci ( FCI ) \u2013 PySCF FCI object. space ( tuple [ Space , Space ] ) \u2013 Space containing the frozen, correlated, and active fermionic spaces for each spin channel. max_order ( int , default: 4 ) \u2013 Maximum order of the excitation. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes in the active space. Source code in ebcc/ext/fci.py def fci_to_amplitudes_unrestricted( fci: FCI, space: tuple[Space, Space], max_order: int = 4 ) -> Namespace[USpinArrayType]: \"\"\"Extract amplitudes from an FCI calculation with unrestricted symmetry. The FCI calculatiion should have been performed in the active space according to the given `space`, i.e. using `mo_coeff[:, space.active]`. Args: fci: PySCF FCI object. space: Space containing the frozen, correlated, and active fermionic spaces for each spin channel. max_order: Maximum order of the excitation. Returns: Cluster amplitudes in the active space. \"\"\" return _ci_vector_to_amplitudes_unrestricted(fci.ci, space, max_order=max_order)","title":"Fci"},{"location":"reference/ext/fci/#ebcc.ext.fci.fci_to_amplitudes_restricted","text":"Extract amplitudes from an FCI calculation with restricted symmetry. The FCI calculatiion should have been performed in the active space according to the given space , i.e. using mo_coeff[:, space.active] . Parameters: fci ( FCI ) \u2013 PySCF FCI object. space ( Space ) \u2013 Space containing the frozen, correlated, and active fermionic spaces. max_order ( int , default: 4 ) \u2013 Maximum order of the excitation. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes in the active space. Source code in ebcc/ext/fci.py def fci_to_amplitudes_restricted( fci: FCI, space: Space, max_order: int = 4 ) -> Namespace[RSpinArrayType]: \"\"\"Extract amplitudes from an FCI calculation with restricted symmetry. The FCI calculatiion should have been performed in the active space according to the given `space`, i.e. using `mo_coeff[:, space.active]`. Args: fci: PySCF FCI object. space: Space containing the frozen, correlated, and active fermionic spaces. max_order: Maximum order of the excitation. Returns: Cluster amplitudes in the active space. \"\"\" return _ci_vector_to_amplitudes_restricted(fci.ci, space, max_order=max_order)","title":"fci_to_amplitudes_restricted"},{"location":"reference/ext/fci/#ebcc.ext.fci.fci_to_amplitudes_unrestricted","text":"Extract amplitudes from an FCI calculation with unrestricted symmetry. The FCI calculatiion should have been performed in the active space according to the given space , i.e. using mo_coeff[:, space.active] . Parameters: fci ( FCI ) \u2013 PySCF FCI object. space ( tuple [ Space , Space ] ) \u2013 Space containing the frozen, correlated, and active fermionic spaces for each spin channel. max_order ( int , default: 4 ) \u2013 Maximum order of the excitation. Returns: Namespace [ SpinArrayType ] \u2013 Cluster amplitudes in the active space. Source code in ebcc/ext/fci.py def fci_to_amplitudes_unrestricted( fci: FCI, space: tuple[Space, Space], max_order: int = 4 ) -> Namespace[USpinArrayType]: \"\"\"Extract amplitudes from an FCI calculation with unrestricted symmetry. The FCI calculatiion should have been performed in the active space according to the given `space`, i.e. using `mo_coeff[:, space.active]`. Args: fci: PySCF FCI object. space: Space containing the frozen, correlated, and active fermionic spaces for each spin channel. max_order: Maximum order of the excitation. Returns: Cluster amplitudes in the active space. \"\"\" return _ci_vector_to_amplitudes_unrestricted(fci.ci, space, max_order=max_order)","title":"fci_to_amplitudes_unrestricted"},{"location":"reference/ext/tcc/","text":"Tailored coupled cluster. ebcc.ext.tcc.BaseOptions() dataclass Bases: _BaseOptions Options for tCC calculations. ebcc.ext.tcc.BaseTailor(cc, amplitudes, options=None, **kwargs) Bases: AbstractContextManager [None] Context manager for tailoring an EBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\") ebcc.ext.tcc.BaseTailor.__enter__() Enter the context manager. Source code in ebcc/ext/tcc.py def __enter__(self) -> None: \"\"\"Enter the context manager.\"\"\" # Save the original update_amps method self._update_amps_old = self.cc.update_amps def update_amps( eris: Optional[Any] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes.\"\"\" # Perform the original update_amps method assert self._update_amps_old is not None amps = self._update_amps_old(eris=eris, amplitudes=amplitudes) # Tailor the amplitudes self._set_active_space(amps, self.amplitudes) return amps # Replace the original update_amps method update_amps.__doc__ = self._update_amps_old.__doc__ self.cc.update_amps = update_amps # type: ignore[method-assign] ebcc.ext.tcc.BaseTailor.__exit__(*args) Exit the context manager. Source code in ebcc/ext/tcc.py def __exit__(self, *args: Any) -> None: \"\"\"Exit the context manager.\"\"\" # Restore the original update_amps method assert self._update_amps_old is not None self.cc.update_amps = self._update_amps_old # type: ignore[method-assign] self._update_amps_old = None ebcc.ext.tcc.TailorREBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseTailor Context manager for tailoring an REBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\") ebcc.ext.tcc.TailorUEBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseTailor Context manager for tailoring a UEBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\") ebcc.ext.tcc.TailorGEBCC(cc, amplitudes, options=None, **kwargs) Bases: BaseTailor Context manager for tailoring a GEBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\")","title":"Tcc"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.BaseOptions","text":"Bases: _BaseOptions Options for tCC calculations.","title":"BaseOptions"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.BaseTailor","text":"Bases: AbstractContextManager [None] Context manager for tailoring an EBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\")","title":"BaseTailor"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.BaseTailor.__enter__","text":"Enter the context manager. Source code in ebcc/ext/tcc.py def __enter__(self) -> None: \"\"\"Enter the context manager.\"\"\" # Save the original update_amps method self._update_amps_old = self.cc.update_amps def update_amps( eris: Optional[Any] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Namespace[SpinArrayType]: \"\"\"Update the cluster amplitudes.\"\"\" # Perform the original update_amps method assert self._update_amps_old is not None amps = self._update_amps_old(eris=eris, amplitudes=amplitudes) # Tailor the amplitudes self._set_active_space(amps, self.amplitudes) return amps # Replace the original update_amps method update_amps.__doc__ = self._update_amps_old.__doc__ self.cc.update_amps = update_amps # type: ignore[method-assign]","title":"__enter__"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.BaseTailor.__exit__","text":"Exit the context manager. Source code in ebcc/ext/tcc.py def __exit__(self, *args: Any) -> None: \"\"\"Exit the context manager.\"\"\" # Restore the original update_amps method assert self._update_amps_old is not None self.cc.update_amps = self._update_amps_old # type: ignore[method-assign] self._update_amps_old = None","title":"__exit__"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.TailorREBCC","text":"Bases: BaseTailor Context manager for tailoring an REBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\")","title":"TailorREBCC"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.TailorUEBCC","text":"Bases: BaseTailor Context manager for tailoring a UEBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\")","title":"TailorUEBCC"},{"location":"reference/ext/tcc/#ebcc.ext.tcc.TailorGEBCC","text":"Bases: BaseTailor Context manager for tailoring a GEBCC calculation. This context manager is used to tailor an EBCC calculation by updating the T1 and T2 amplitudes to constrain the active space to known T1 and T2 amplitudes spanning the active space as defined by ebcc.space . Initialise the context manager. Parameters: cc ( BaseEBCC ) \u2013 EBCC object. amplitudes ( Namespace [ SpinArrayType ] ) \u2013 Cluster amplitudes. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the tCC calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/ext/tcc.py def __init__( self, cc: BaseEBCC, amplitudes: Namespace[SpinArrayType], options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: \"\"\"Initialise the context manager. Args: cc: EBCC object. amplitudes: Cluster amplitudes. options: Options for the tCC calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.amplitudes = amplitudes # Attributes: self._update_amps_old = None # Logging: init_logging(self.cc.log) self.cc.log.info(f\"Applying {ANSI.m}tailoring{ANSI.R}.\") self.cc.log.debug(\"\")","title":"TailorGEBCC"},{"location":"reference/ham/","text":"Hamiltonian objects.","title":"Index"},{"location":"reference/ham/base/","text":"Base classes for ebcc.ham . ebcc.ham.base.BaseHamiltonian(mf, space, mo_coeff=None) Bases: Namespace [ Any ] , ABC Base class for Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.base.BaseHamiltonian.__getitem__(key) abstractmethod Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: Any \u2013 Slice of the Hamiltonian. Source code in ebcc/ham/base.py @abstractmethod def __getitem__(self, key: str) -> Any: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Slice of the Hamiltonian. \"\"\" pass ebcc.ham.base.BaseRHamiltonian(mf, space, mo_coeff=None) Bases: BaseHamiltonian Base class for restricted Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.base.BaseUHamiltonian(mf, space, mo_coeff=None) Bases: BaseHamiltonian Base class for unrestricted Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.base.BaseGHamiltonian(mf, space, mo_coeff=None) Bases: BaseHamiltonian Base class for general Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.base.BaseFock(mf, space, mo_coeff=None, g=None, shift=None, xi=None) Bases: BaseHamiltonian Base class for Fock matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi ebcc.ham.base.BaseERIs(mf, space, mo_coeff=None) Bases: BaseHamiltonian Base class for electronic repulsion integrals. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.base.BaseElectronBoson(mf, g, space, mo_coeff=None) Bases: BaseHamiltonian Base class for electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g","title":"Base"},{"location":"reference/ham/base/#ebcc.ham.base.BaseHamiltonian","text":"Bases: Namespace [ Any ] , ABC Base class for Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"BaseHamiltonian"},{"location":"reference/ham/base/#ebcc.ham.base.BaseHamiltonian.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: Any \u2013 Slice of the Hamiltonian. Source code in ebcc/ham/base.py @abstractmethod def __getitem__(self, key: str) -> Any: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Slice of the Hamiltonian. \"\"\" pass","title":"__getitem__"},{"location":"reference/ham/base/#ebcc.ham.base.BaseRHamiltonian","text":"Bases: BaseHamiltonian Base class for restricted Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"BaseRHamiltonian"},{"location":"reference/ham/base/#ebcc.ham.base.BaseUHamiltonian","text":"Bases: BaseHamiltonian Base class for unrestricted Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"BaseUHamiltonian"},{"location":"reference/ham/base/#ebcc.ham.base.BaseGHamiltonian","text":"Bases: BaseHamiltonian Base class for general Hamiltonians. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"BaseGHamiltonian"},{"location":"reference/ham/base/#ebcc.ham.base.BaseFock","text":"Bases: BaseHamiltonian Base class for Fock matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi","title":"BaseFock"},{"location":"reference/ham/base/#ebcc.ham.base.BaseERIs","text":"Bases: BaseHamiltonian Base class for electronic repulsion integrals. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"BaseERIs"},{"location":"reference/ham/base/#ebcc.ham.base.BaseElectronBoson","text":"Bases: BaseHamiltonian Base class for electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g","title":"BaseElectronBoson"},{"location":"reference/ham/cderis/","text":"Cholesky-decomposed electron repulsion integral containers. ebcc.ham.cderis.RCDERIs(mf, space, mo_coeff=None) Bases: BaseERIs , BaseRHamiltonian Restricted Cholesky-decomposed ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.cderis.RCDERIs.__getitem__(key, e2=False) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. e2 ( Optional [ bool ] , default: False ) \u2013 Whether the key is for the second electron. Returns: NDArray [ T ] \u2013 CDERIs for the given spaces. Source code in ebcc/ham/cderis.py def __getitem__(self, key: str, e2: Optional[bool] = False) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. e2: Whether the key is for the second electron. Returns: CDERIs for the given spaces. \"\"\" if len(key) == 4: v1 = self.__getitem__(\"Q\" + key[:2]) v2 = self.__getitem__(\"Q\" + key[2:], e2=True) # type: ignore return util.einsum(\"Qij,Qkl->ijkl\", v1, v2) elif len(key) == 3: key = key[1:] else: raise KeyError(\"Key must be of length 3 or 4.\") key_e2 = f\"{key}_{'e1' if not e2 else 'e2'}\" # Check the DF is built incore if not isinstance(self.mf.with_df._cderi, np.ndarray): with lib.temporary_env(self.mf.with_df, max_memory=1e6): self.mf.with_df.build() if key_e2 not in self._members: s = 0 if not e2 else 2 # Get the coefficients and shape coeffs = self._get_coeffs(key, offset=s) shape = tuple(c.shape[-1] for c in coeffs) ijslice = (0, shape[0], shape[0], shape[0] + shape[1]) coeffs = np.concatenate(coeffs, axis=1) coeffs = self._to_pyscf_backend(coeffs) # Transform the block # TODO: Optimise for (L|pp) block = pyscf.ao2mo._ao2mo.nr_e2( self.mf.with_df._cderi, coeffs, ijslice, aosym=\"s2\", mosym=\"s1\" ) block = self._to_ebcc_backend(block) block = np.reshape(block, (-1, *shape)) # Store the block self._members[key_e2] = block return self._members[key_e2] ebcc.ham.cderis.UCDERIs(mf, space, mo_coeff=None) Bases: BaseERIs , BaseUHamiltonian Unrestricted Cholesky-decomposed ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.cderis.UCDERIs.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RCDERIs \u2013 CDERIs for the given spins. Source code in ebcc/ham/cderis.py def __getitem__(self, key: str) -> RCDERIs: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: CDERIs for the given spins. \"\"\" if len(key) == 3: key = key[1:] if key not in (\"aa\", \"bb\", \"aaaa\", \"aabb\", \"bbaa\", \"bbbb\"): raise KeyError(f\"Invalid key: {key}\") if len(key) == 2: key = key + key i = \"ab\".index(key[0]) j = \"ab\".index(key[2]) if key not in self._members: self._members[key] = RCDERIs( self.mf, space=(self.space[0][i], self.space[1][i], self.space[2][j], self.space[3][j]), mo_coeff=( self.mo_coeff[0][i], self.mo_coeff[1][i], self.mo_coeff[2][j], self.mo_coeff[3][j], ), ) return self._members[key]","title":"CDERIs"},{"location":"reference/ham/cderis/#ebcc.ham.cderis.RCDERIs","text":"Bases: BaseERIs , BaseRHamiltonian Restricted Cholesky-decomposed ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"RCDERIs"},{"location":"reference/ham/cderis/#ebcc.ham.cderis.RCDERIs.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. e2 ( Optional [ bool ] , default: False ) \u2013 Whether the key is for the second electron. Returns: NDArray [ T ] \u2013 CDERIs for the given spaces. Source code in ebcc/ham/cderis.py def __getitem__(self, key: str, e2: Optional[bool] = False) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. e2: Whether the key is for the second electron. Returns: CDERIs for the given spaces. \"\"\" if len(key) == 4: v1 = self.__getitem__(\"Q\" + key[:2]) v2 = self.__getitem__(\"Q\" + key[2:], e2=True) # type: ignore return util.einsum(\"Qij,Qkl->ijkl\", v1, v2) elif len(key) == 3: key = key[1:] else: raise KeyError(\"Key must be of length 3 or 4.\") key_e2 = f\"{key}_{'e1' if not e2 else 'e2'}\" # Check the DF is built incore if not isinstance(self.mf.with_df._cderi, np.ndarray): with lib.temporary_env(self.mf.with_df, max_memory=1e6): self.mf.with_df.build() if key_e2 not in self._members: s = 0 if not e2 else 2 # Get the coefficients and shape coeffs = self._get_coeffs(key, offset=s) shape = tuple(c.shape[-1] for c in coeffs) ijslice = (0, shape[0], shape[0], shape[0] + shape[1]) coeffs = np.concatenate(coeffs, axis=1) coeffs = self._to_pyscf_backend(coeffs) # Transform the block # TODO: Optimise for (L|pp) block = pyscf.ao2mo._ao2mo.nr_e2( self.mf.with_df._cderi, coeffs, ijslice, aosym=\"s2\", mosym=\"s1\" ) block = self._to_ebcc_backend(block) block = np.reshape(block, (-1, *shape)) # Store the block self._members[key_e2] = block return self._members[key_e2]","title":"__getitem__"},{"location":"reference/ham/cderis/#ebcc.ham.cderis.UCDERIs","text":"Bases: BaseERIs , BaseUHamiltonian Unrestricted Cholesky-decomposed ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"UCDERIs"},{"location":"reference/ham/cderis/#ebcc.ham.cderis.UCDERIs.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RCDERIs \u2013 CDERIs for the given spins. Source code in ebcc/ham/cderis.py def __getitem__(self, key: str) -> RCDERIs: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: CDERIs for the given spins. \"\"\" if len(key) == 3: key = key[1:] if key not in (\"aa\", \"bb\", \"aaaa\", \"aabb\", \"bbaa\", \"bbbb\"): raise KeyError(f\"Invalid key: {key}\") if len(key) == 2: key = key + key i = \"ab\".index(key[0]) j = \"ab\".index(key[2]) if key not in self._members: self._members[key] = RCDERIs( self.mf, space=(self.space[0][i], self.space[1][i], self.space[2][j], self.space[3][j]), mo_coeff=( self.mo_coeff[0][i], self.mo_coeff[1][i], self.mo_coeff[2][j], self.mo_coeff[3][j], ), ) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/elbos/","text":"Electron-boson coupling matrix containers. ebcc.ham.elbos.RElectronBoson(mf, g, space, mo_coeff=None) Bases: BaseElectronBoson , BaseRHamiltonian Restricted electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g ebcc.ham.elbos.RElectronBoson.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Electron-boson coupling matrix for the given spaces. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spaces. \"\"\" if key not in self._members: assert key[0] == \"b\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") # Get the slices slices = (slice(None),) + self._get_slices(key[1:]) # Store the block self._members[key] = np.copy(self.g[slices]) return self._members[key] ebcc.ham.elbos.UElectronBoson(mf, g, space, mo_coeff=None) Bases: BaseElectronBoson , BaseUHamiltonian Unrestricted electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g ebcc.ham.elbos.UElectronBoson.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RElectronBoson \u2013 Electron-boson coupling matrix for the given spin. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> RElectronBoson: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spin. \"\"\" if key not in (\"aa\", \"bb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) self._members[key] = RElectronBoson( self.mf, self.g[i] if self.g.ndim == 4 else self.g, space=(self.space[0][i], self.space[1][i]), ) self._members[key]._spin_index = i return self._members[key] ebcc.ham.elbos.GElectronBoson(mf, g, space, mo_coeff=None) Bases: BaseElectronBoson , BaseGHamiltonian Generalised electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g ebcc.ham.elbos.GElectronBoson.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Electron-boson coupling matrix for the given spaces. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spaces. \"\"\" if key not in self._members: assert key[0] == \"b\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") # Get the slices slices = (slice(None),) + self._get_slices(key[1:]) # Store the block self._members[key] = np.copy(self.g[slices]) return self._members[key]","title":"Bosonic"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.RElectronBoson","text":"Bases: BaseElectronBoson , BaseRHamiltonian Restricted electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g","title":"RElectronBoson"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.RElectronBoson.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Electron-boson coupling matrix for the given spaces. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spaces. \"\"\" if key not in self._members: assert key[0] == \"b\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") # Get the slices slices = (slice(None),) + self._get_slices(key[1:]) # Store the block self._members[key] = np.copy(self.g[slices]) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.UElectronBoson","text":"Bases: BaseElectronBoson , BaseUHamiltonian Unrestricted electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g","title":"UElectronBoson"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.UElectronBoson.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RElectronBoson \u2013 Electron-boson coupling matrix for the given spin. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> RElectronBoson: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spin. \"\"\" if key not in (\"aa\", \"bb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) self._members[key] = RElectronBoson( self.mf, self.g[i] if self.g.ndim == 4 else self.g, space=(self.space[0][i], self.space[1][i]), ) self._members[key]._spin_index = i return self._members[key]","title":"__getitem__"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.GElectronBoson","text":"Bases: BaseElectronBoson , BaseGHamiltonian Generalised electron-boson coupling matrices. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. g ( NDArray [ floating ] ) \u2013 The electron-boson coupling matrix array. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, g: NDArray[floating], space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. g: The electron-boson coupling matrix array. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g","title":"GElectronBoson"},{"location":"reference/ham/elbos/#ebcc.ham.elbos.GElectronBoson.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Electron-boson coupling matrix for the given spaces. Source code in ebcc/ham/elbos.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Electron-boson coupling matrix for the given spaces. \"\"\" if key not in self._members: assert key[0] == \"b\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") # Get the slices slices = (slice(None),) + self._get_slices(key[1:]) # Store the block self._members[key] = np.copy(self.g[slices]) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/eris/","text":"Electronic repulsion integral containers. ebcc.ham.eris.RERIs(mf, space, mo_coeff=None) Bases: BaseERIs , BaseRHamiltonian Restricted ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.eris.RERIs.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 ERIs for the given spaces. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spaces. \"\"\" if key not in self._members.keys(): # Get the coefficients and shape coeffs = self._get_coeffs(key) coeffs = tuple(self._to_pyscf_backend(c) for c in coeffs) shape = tuple(c.shape[-1] for c in coeffs) # Transform the block # TODO: Optimise for patially AO if getattr(self.mf, \"_eri\", None) is not None: block = pyscf.ao2mo.incore.general(self.mf._eri, coeffs, compact=False) else: block = pyscf.ao2mo.kernel(self.mf.mol, coeffs, compact=False) block = np.reshape(block, shape) # Store the block self._members[key] = np.asarray(block, dtype=types[float]) return self._members[key] ebcc.ham.eris.UERIs(mf, space, mo_coeff=None) Bases: BaseERIs , BaseUHamiltonian Unrestricted ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4 ebcc.ham.eris.UERIs.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RERIs \u2013 ERIs for the given spins. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> RERIs: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spins. \"\"\" if key not in (\"aaaa\", \"aabb\", \"bbaa\", \"bbbb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) j = \"ab\".index(key[2]) self._members[key] = RERIs( self.mf, space=(self.space[0][i], self.space[1][i], self.space[2][j], self.space[3][j]), mo_coeff=( self.mo_coeff[0][i], self.mo_coeff[1][i], self.mo_coeff[2][j], self.mo_coeff[3][j], ), ) return self._members[key] ebcc.ham.eris.GERIs(*args, **kwargs) Bases: BaseERIs , BaseGHamiltonian Generalised ERIs container class. Initialise the class. Source code in ebcc/ham/eris.py def __init__(self, *args: Any, **kwargs: Any) -> None: \"\"\"Initialise the class.\"\"\" super().__init__(*args, **kwargs) # Get the coefficients and shape mo_a = [self._to_pyscf_backend(mo[: self.mf.mol.nao]) for mo in self.mo_coeff] mo_b = [self._to_pyscf_backend(mo[self.mf.mol.nao :]) for mo in self.mo_coeff] shape = tuple(mo.shape[-1] for mo in self.mo_coeff) if len(set(shape)) != 1: raise ValueError( \"MO coefficients must have the same number of basis functions for \" f\"{self.__class__.__name__}.\" ) nmo = shape[0] if getattr(self.mf, \"_eri\", None) is not None: array = pyscf.ao2mo.incore.general(self.mf._eri, mo_a) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_b) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_a[:2] + mo_b[2:]) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_b[:2] + mo_a[2:]) else: array = pyscf.ao2mo.kernel(self.mf.mol, mo_a) array += pyscf.ao2mo.kernel(self.mf.mol, mo_b) array += pyscf.ao2mo.kernel(self.mf.mol, mo_a[:2] + mo_b[2:]) array += pyscf.ao2mo.kernel(self.mf.mol, mo_b[:2] + mo_a[2:]) array = pyscf.ao2mo.addons.restore(1, array, nmo) array = np.reshape(array, shape) array = self._to_ebcc_backend(array) # Transform to antisymmetric Physicist's notation array = np.transpose(array, (0, 2, 1, 3)) - np.transpose(array, (0, 2, 3, 1)) # Store the array self.__dict__[\"_array\"] = array ebcc.ham.eris.GERIs.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 ERIs for the given spaces. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spaces. \"\"\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") return self._array[self._get_slices(key)]","title":"ERIs"},{"location":"reference/ham/eris/#ebcc.ham.eris.RERIs","text":"Bases: BaseERIs , BaseRHamiltonian Restricted ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"RERIs"},{"location":"reference/ham/eris/#ebcc.ham.eris.RERIs.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 ERIs for the given spaces. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spaces. \"\"\" if key not in self._members.keys(): # Get the coefficients and shape coeffs = self._get_coeffs(key) coeffs = tuple(self._to_pyscf_backend(c) for c in coeffs) shape = tuple(c.shape[-1] for c in coeffs) # Transform the block # TODO: Optimise for patially AO if getattr(self.mf, \"_eri\", None) is not None: block = pyscf.ao2mo.incore.general(self.mf._eri, coeffs, compact=False) else: block = pyscf.ao2mo.kernel(self.mf.mol, coeffs, compact=False) block = np.reshape(block, shape) # Store the block self._members[key] = np.asarray(block, dtype=types[float]) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/eris/#ebcc.ham.eris.UERIs","text":"Bases: BaseERIs , BaseUHamiltonian Unrestricted ERIs container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. \"\"\" Namespace.__init__(self) # Parameters: self.__dict__[\"mf\"] = mf self.__dict__[\"space\"] = space self.__dict__[\"mo_coeff\"] = mo_coeff if mo_coeff is not None else (mf.mo_coeff,) * 4","title":"UERIs"},{"location":"reference/ham/eris/#ebcc.ham.eris.UERIs.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RERIs \u2013 ERIs for the given spins. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> RERIs: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spins. \"\"\" if key not in (\"aaaa\", \"aabb\", \"bbaa\", \"bbbb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) j = \"ab\".index(key[2]) self._members[key] = RERIs( self.mf, space=(self.space[0][i], self.space[1][i], self.space[2][j], self.space[3][j]), mo_coeff=( self.mo_coeff[0][i], self.mo_coeff[1][i], self.mo_coeff[2][j], self.mo_coeff[3][j], ), ) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/eris/#ebcc.ham.eris.GERIs","text":"Bases: BaseERIs , BaseGHamiltonian Generalised ERIs container class. Initialise the class. Source code in ebcc/ham/eris.py def __init__(self, *args: Any, **kwargs: Any) -> None: \"\"\"Initialise the class.\"\"\" super().__init__(*args, **kwargs) # Get the coefficients and shape mo_a = [self._to_pyscf_backend(mo[: self.mf.mol.nao]) for mo in self.mo_coeff] mo_b = [self._to_pyscf_backend(mo[self.mf.mol.nao :]) for mo in self.mo_coeff] shape = tuple(mo.shape[-1] for mo in self.mo_coeff) if len(set(shape)) != 1: raise ValueError( \"MO coefficients must have the same number of basis functions for \" f\"{self.__class__.__name__}.\" ) nmo = shape[0] if getattr(self.mf, \"_eri\", None) is not None: array = pyscf.ao2mo.incore.general(self.mf._eri, mo_a) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_b) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_a[:2] + mo_b[2:]) array += pyscf.ao2mo.incore.general(self.mf._eri, mo_b[:2] + mo_a[2:]) else: array = pyscf.ao2mo.kernel(self.mf.mol, mo_a) array += pyscf.ao2mo.kernel(self.mf.mol, mo_b) array += pyscf.ao2mo.kernel(self.mf.mol, mo_a[:2] + mo_b[2:]) array += pyscf.ao2mo.kernel(self.mf.mol, mo_b[:2] + mo_a[2:]) array = pyscf.ao2mo.addons.restore(1, array, nmo) array = np.reshape(array, shape) array = self._to_ebcc_backend(array) # Transform to antisymmetric Physicist's notation array = np.transpose(array, (0, 2, 1, 3)) - np.transpose(array, (0, 2, 3, 1)) # Store the array self.__dict__[\"_array\"] = array","title":"GERIs"},{"location":"reference/ham/eris/#ebcc.ham.eris.GERIs.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 ERIs for the given spaces. Source code in ebcc/ham/eris.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: ERIs for the given spaces. \"\"\" if \"p\" in key: raise NotImplementedError(f\"AO basis not supported in {self.__class__.__name__}.\") return self._array[self._get_slices(key)]","title":"__getitem__"},{"location":"reference/ham/fock/","text":"Fock matrix containers. ebcc.ham.fock.RFock(mf, space, mo_coeff=None, g=None, shift=None, xi=None) Bases: BaseFock , BaseRHamiltonian Restricted Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi ebcc.ham.fock.RFock.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Fock matrix for the given spaces. Source code in ebcc/ham/fock.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Fock matrix for the given spaces. \"\"\" if key not in self._members: # Get the coefficients coeffs = self._get_coeffs(key) # Transform the block fock_ao: NDArray[T] = np.asarray(self.mf.get_fock(), dtype=types[float]) if self._spin_index is not None: fock_ao = fock_ao[self._spin_index] block = util.einsum(\"pq,pi,qj->ij\", fock_ao, *coeffs) # Store the block self._members[key] = block if self.shift: # Shift for bosons xi = self.xi g = np.copy(self.g.__getattr__(f\"b{key}\")) g += np.transpose(self.g.__getattr__(f\"b{key[::-1]}\"), (0, 2, 1)) self._members[key] -= util.einsum(\"I,Ipq->pq\", xi, g) return self._members[key] ebcc.ham.fock.UFock(mf, space, mo_coeff=None, g=None, shift=None, xi=None) Bases: BaseFock , BaseUHamiltonian Unrestricted Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi ebcc.ham.fock.UFock.__getitem__(key) Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RFock \u2013 Fock matrix for the given spin. Source code in ebcc/ham/fock.py def __getitem__(self, key: str) -> RFock: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Fock matrix for the given spin. \"\"\" if key not in (\"aa\", \"bb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) self._members[key] = RFock( self.mf, space=(self.space[0][i], self.space[1][i]), mo_coeff=(self.mo_coeff[0][i], self.mo_coeff[1][i]), g=self.g[key] if self.g is not None else None, shift=self.shift, xi=self.xi, ) self._members[key].__dict__[\"_spin_index\"] = i return self._members[key] ebcc.ham.fock.GFock(mf, space, mo_coeff=None, g=None, shift=None, xi=None) Bases: RFock Generalised Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi","title":"Fock"},{"location":"reference/ham/fock/#ebcc.ham.fock.RFock","text":"Bases: BaseFock , BaseRHamiltonian Restricted Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi","title":"RFock"},{"location":"reference/ham/fock/#ebcc.ham.fock.RFock.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: NDArray [ T ] \u2013 Fock matrix for the given spaces. Source code in ebcc/ham/fock.py def __getitem__(self, key: str) -> NDArray[T]: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Fock matrix for the given spaces. \"\"\" if key not in self._members: # Get the coefficients coeffs = self._get_coeffs(key) # Transform the block fock_ao: NDArray[T] = np.asarray(self.mf.get_fock(), dtype=types[float]) if self._spin_index is not None: fock_ao = fock_ao[self._spin_index] block = util.einsum(\"pq,pi,qj->ij\", fock_ao, *coeffs) # Store the block self._members[key] = block if self.shift: # Shift for bosons xi = self.xi g = np.copy(self.g.__getattr__(f\"b{key}\")) g += np.transpose(self.g.__getattr__(f\"b{key[::-1]}\"), (0, 2, 1)) self._members[key] -= util.einsum(\"I,Ipq->pq\", xi, g) return self._members[key]","title":"__getitem__"},{"location":"reference/ham/fock/#ebcc.ham.fock.UFock","text":"Bases: BaseFock , BaseUHamiltonian Unrestricted Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi","title":"UFock"},{"location":"reference/ham/fock/#ebcc.ham.fock.UFock.__getitem__","text":"Just-in-time getter. Parameters: key ( str ) \u2013 Key to get. Returns: RFock \u2013 Fock matrix for the given spin. Source code in ebcc/ham/fock.py def __getitem__(self, key: str) -> RFock: \"\"\"Just-in-time getter. Args: key: Key to get. Returns: Fock matrix for the given spin. \"\"\" if key not in (\"aa\", \"bb\"): raise KeyError(f\"Invalid key: {key}\") if key not in self._members: i = \"ab\".index(key[0]) self._members[key] = RFock( self.mf, space=(self.space[0][i], self.space[1][i]), mo_coeff=(self.mo_coeff[0][i], self.mo_coeff[1][i]), g=self.g[key] if self.g is not None else None, shift=self.shift, xi=self.xi, ) self._members[key].__dict__[\"_spin_index\"] = i return self._members[key]","title":"__getitem__"},{"location":"reference/ham/fock/#ebcc.ham.fock.GFock","text":"Bases: RFock Generalised Fock matrix container class. Initialise the Hamiltonian. Parameters: mf ( SCF ) \u2013 Mean-field object. space ( tuple [ SpaceType , ...] ) \u2013 Space object for each index. mo_coeff ( Optional [ tuple [ CoeffType , ...]] , default: None ) \u2013 Molecular orbital coefficients for each index. g ( Optional [ Namespace [ Any ]] , default: None ) \u2013 Namespace containing blocks of the electron-boson coupling matrix. shift ( Optional [ bool ] , default: None ) \u2013 Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi ( Optional [ NDArray [ floating ]] , default: None ) \u2013 Shift in the bosonic operators to diagonalise the photon Hamiltonian. Source code in ebcc/ham/base.py def __init__( self, mf: SCF, space: tuple[SpaceType, ...], mo_coeff: Optional[tuple[CoeffType, ...]] = None, g: Optional[Namespace[Any]] = None, shift: Optional[bool] = None, xi: Optional[NDArray[floating]] = None, ) -> None: \"\"\"Initialise the Hamiltonian. Args: mf: Mean-field object. space: Space object for each index. mo_coeff: Molecular orbital coefficients for each index. g: Namespace containing blocks of the electron-boson coupling matrix. shift: Shift the boson operators such that the Hamiltonian is normal-ordered with respect to a coherent state. This removes the bosonic coupling to the static mean-field density, introducing a constant energy shift. xi: Shift in the bosonic operators to diagonalise the photon Hamiltonian. \"\"\" super().__init__(mf, space, mo_coeff=mo_coeff) # Boson parameters: self.__dict__[\"g\"] = g self.__dict__[\"shift\"] = shift self.__dict__[\"xi\"] = xi","title":"GFock"},{"location":"reference/ham/space/","text":"Space definition. ebcc.ham.space.Space(occupied, frozen, active) Space class. .. code-block:: none \u2500\u252c\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 frozen \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u252c\u2500 virtual \u2502 \u2502 active \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 correlated \u2502 \u2502 inactive \u2502 \u2502 \u2500\u253c\u2500 \u251c\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2524 \u2500\u253c\u2500 \u2502 \u2502 inactive \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 correlated occupied \u2502 \u2502 active \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u2534\u2500 \u2502 \u2502 frozen \u2502 \u2500\u2534\u2500 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Initialise the space. Parameters: occupied ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is occupied. frozen ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is frozen. active ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is active. Source code in ebcc/ham/space.py def __init__( self, occupied: NDArray[B], frozen: NDArray[B], active: NDArray[B], ) -> None: \"\"\"Initialise the space. Args: occupied: Array containing boolean flags indicating whether or not each orbital is occupied. frozen: Array containing boolean flags indicating whether or not each orbital is frozen. active: Array containing boolean flags indicating whether or not each orbital is active. \"\"\" self._occupied = np.asarray(occupied, dtype=np.bool_) self._frozen = np.asarray(frozen, dtype=np.bool_) self._active = np.asarray(active, dtype=np.bool_) # Checks: if not (self._occupied.size == self._frozen.size == self._active.size): raise ValueError(\"The sizes of the space arrays must match.\") if np.any(np.bitwise_and(self._frozen, self._active)): raise ValueError(\"Frozen and active orbitals must be mutually exclusive.\") ebcc.ham.space.Space.occupied: NDArray[B] property Get a boolean mask of occupied orbitals. ebcc.ham.space.Space.virtual: NDArray[B] cached property Get a boolean mask of virtual orbitals. ebcc.ham.space.Space.nmo: int property Get the number of orbitals. ebcc.ham.space.Space.nocc: int cached property Get the number of occupied orbitals. ebcc.ham.space.Space.nvir: int cached property Get the number of virtual orbitals. ebcc.ham.space.Space.correlated: NDArray[B] cached property Get a boolean mask of correlated orbitals. ebcc.ham.space.Space.correlated_occupied: NDArray[B] cached property Get a boolean mask of occupied correlated orbitals. ebcc.ham.space.Space.correlated_virtual: NDArray[B] cached property Get a boolean mask of virtual correlated orbitals. ebcc.ham.space.Space.ncorr: int cached property Get the number of correlated orbitals. ebcc.ham.space.Space.ncocc: int cached property Get the number of occupied correlated orbitals. ebcc.ham.space.Space.ncvir: int cached property Get the number of virtual correlated orbitals. ebcc.ham.space.Space.inactive: NDArray[B] cached property Get a boolean mask of inactive orbitals. ebcc.ham.space.Space.inactive_occupied: NDArray[B] cached property Get a boolean mask of occupied inactive orbitals. ebcc.ham.space.Space.inactive_virtual: NDArray[B] cached property Get a boolean mask of virtual inactive orbitals. ebcc.ham.space.Space.ninact: int cached property Get the number of inactive orbitals. ebcc.ham.space.Space.niocc: int cached property Get the number of occupied inactive orbitals. ebcc.ham.space.Space.nivir: int cached property Get the number of virtual inactive orbitals. ebcc.ham.space.Space.frozen: NDArray[B] property Get a boolean mask of frozen orbitals. ebcc.ham.space.Space.frozen_occupied: NDArray[B] cached property Get a boolean mask of occupied frozen orbitals. ebcc.ham.space.Space.frozen_virtual: NDArray[B] cached property Get a boolean mask of virtual frozen orbitals. ebcc.ham.space.Space.nfroz: int cached property Get the number of frozen orbitals. ebcc.ham.space.Space.nfocc: int cached property Get the number of occupied frozen orbitals. ebcc.ham.space.Space.nfvir: int cached property Get the number of virtual frozen orbitals. ebcc.ham.space.Space.active: NDArray[B] property Get a boolean mask of active orbitals. ebcc.ham.space.Space.active_occupied: NDArray[B] cached property Get a boolean mask of occupied active orbitals. ebcc.ham.space.Space.active_virtual: NDArray[B] cached property Get a boolean mask of virtual active orbitals. ebcc.ham.space.Space.nact: int cached property Get the number of active orbitals. ebcc.ham.space.Space.naocc: int cached property Get the number of occupied active orbitals. ebcc.ham.space.Space.navir: int cached property Get the number of virtual active orbitals. ebcc.ham.space.Space.__repr__() Get a string representation of the space. Source code in ebcc/ham/space.py def __repr__(self) -> str: \"\"\"Get a string representation of the space.\"\"\" out = \"(%do, %dv)\" % (self.nocc, self.nvir) parts = [] if self.nfroz: parts.append(\"(%do, %dv) frozen\" % (self.nfocc, self.nfvir)) if self.nact: parts.append(\"(%do, %dv) active\" % (self.naocc, self.navir)) if len(parts): out += \" [\" + \", \".join(parts) + \"]\" return out ebcc.ham.space.Space.size(char) Convert a character corresponding to a space to the size of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: int \u2013 Size of the space. Source code in ebcc/ham/space.py def size(self, char: str) -> int: \"\"\"Convert a character corresponding to a space to the size of that space. Args: char: Character to convert. Returns: Size of the space. \"\"\" return { \"x\": self.ncorr, \"o\": self.ncocc, \"O\": self.naocc, \"i\": self.niocc, \"v\": self.ncvir, \"V\": self.navir, \"a\": self.nivir, }[char] ebcc.ham.space.Space.mask(char) Convert a character corresponding to a space to a mask of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def mask(self, char: str) -> NDArray[B]: \"\"\"Convert a character corresponding to a space to a mask of that space. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return { \"x\": self.correlated, \"o\": self.correlated_occupied, \"O\": self.active_occupied, \"i\": self.inactive_occupied, \"v\": self.correlated_virtual, \"V\": self.active_virtual, \"a\": self.inactive_virtual, }[char] ebcc.ham.space.Space.slice(char) cached Convert a character corresponding to a space to a slice of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py @functools.lru_cache(maxsize=128) # noqa: B019 def slice(self, char: str) -> _slice: \"\"\"Convert a character corresponding to a space to a slice of that space. Args: char: Character to convert. Returns: Slice of the space. \"\"\" # Check that the respective mask is contiguous mask = self.mask(char) first = np.argmax(mask) size = self.size(char) if not np.all(mask[first : first + size]): raise ValueError( f\"Space '{char}' is not contiguous. In order to slice into this space, \" \"the `mask` method must be used. If you see this error internally, it is \" \"likely that you have constructed a disjoint space. Please reorder the \" \"orbitals in the space.\" ) return slice(first, first + size) ebcc.ham.space.Space.omask(char) Like mask , but returns only a mask into only the occupied sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def omask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the occupied sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.occupied] ebcc.ham.space.Space.vmask(char) Like mask , but returns only a mask into only the virtual sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def vmask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the virtual sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.virtual] ebcc.ham.space.Space.xmask(char) Like mask , but returns only a mask into only the correlated sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def xmask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the correlated sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.correlated] ebcc.ham.space.Space.oslice(char) Like slice , but returns only a slice into only the occupied sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def oslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the occupied sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nocc = self.nocc return slice(s.start, min(s.stop, nocc)) ebcc.ham.space.Space.vslice(char) Like slice , but returns only a slice into only the virtual sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def vslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the virtual sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nocc = self.nocc return slice(max(s.start, nocc) - nocc, s.stop - nocc) ebcc.ham.space.Space.xslice(char) Like slice , but returns only a slice into only the correlated sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def xslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the correlated sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nfocc = self.nfocc return slice(s.start - nfocc, s.stop - nfocc) ebcc.ham.space.construct_default_space(mf) Construct a default space. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. Returns: Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 The molecular orbital coefficients, the molecular orbital occupation numbers, and the Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 default space. Source code in ebcc/ham/space.py def construct_default_space(mf: SCF) -> Union[RConstructSpaceReturnType, UConstructSpaceReturnType]: \"\"\"Construct a default space. Args: mf: PySCF mean-field object. Returns: The molecular orbital coefficients, the molecular orbital occupation numbers, and the default space. \"\"\" def _construct(mo_occ: NDArray[T]) -> Space: \"\"\"Build the default space.\"\"\" frozen = np.zeros(mo_occ.shape, dtype=np.bool_) active = np.zeros(mo_occ.shape, dtype=np.bool_) space = Space( occupied=mo_occ > 0, frozen=frozen, active=active, ) return space # Construct the default space if mf.mo_occ.ndim == 2: space_a = _construct(mf.mo_occ[0]) space_b = _construct(mf.mo_occ[1]) return mf.mo_coeff, mf.mo_occ, (space_a, space_b) else: return mf.mo_coeff, mf.mo_occ, _construct(mf.mo_occ) ebcc.ham.space.construct_fno_space(mf, occ_tol=1e-05, occ_frac=None, amplitudes=None) Construct a frozen natural orbital space. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. occ_tol ( Optional [ float ] , default: 1e-05 ) \u2013 Threshold in the natural orbital occupation numbers. occ_frac ( Optional [ float ] , default: None ) \u2013 Fraction of the natural orbital occupation numbers to be retained. Overrides occ_tol if both are specified. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. If provided, use these amplitudes when calculating the MP2 1RDM. Returns: Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 The natural orbital coefficients, the natural orbital occupation numbers, and the frozen Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 natural orbital space. Source code in ebcc/ham/space.py def construct_fno_space( mf: SCF, occ_tol: Optional[float] = 1e-5, occ_frac: Optional[float] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Union[RConstructSpaceReturnType, UConstructSpaceReturnType]: \"\"\"Construct a frozen natural orbital space. Args: mf: PySCF mean-field object. occ_tol: Threshold in the natural orbital occupation numbers. occ_frac: Fraction of the natural orbital occupation numbers to be retained. Overrides `occ_tol` if both are specified. amplitudes: Cluster amplitudes. If provided, use these amplitudes when calculating the MP2 1RDM. Returns: The natural orbital coefficients, the natural orbital occupation numbers, and the frozen natural orbital space. \"\"\" # Get the MP2 1RDM solver = pyscf.mp.mp2.MP2(mf) dm1: NDArray[T] if not amplitudes: solver.kernel() dm1 = np.asarray(solver.make_rdm1(), dtype=types[float]) else: if isinstance(amplitudes.t2, util.Namespace): t2 = (amplitudes.t2.aaaa, amplitudes.t2.abab, amplitudes.t2.bbbb) dm1 = np.asarray(solver.make_rdm1(t2=t2), dtype=types[float]) else: dm1 = np.asarray(solver.make_rdm1(t2=amplitudes.t2), dtype=types[float]) # def _construct(dm1, mo_energy, mo_coeff, mo_occ): def _construct( dm1: NDArray[T], mo_energy: NDArray[T], mo_coeff: NDArray[T], mo_occ: NDArray[T], ) -> RConstructSpaceReturnType: # Get the number of occupied orbitals nocc = np.count_nonzero(mo_occ > 0) # Calculate the natural orbitals n, c = np.linalg.eigh(dm1[nocc:, nocc:]) n, c = n[::-1], c[:, ::-1] # Truncate the natural orbitals if occ_frac is None: active_vir = n > occ_tol else: active_vir = np.cumsum(n / np.sum(n)) <= occ_frac num_active_vir = np.count_nonzero(active_vir) # Canonicalise the natural orbitals fock_vv = np.diag(mo_energy[nocc:]) fock_vv = util.einsum(\"ab,au,bv->uv\", fock_vv, c, c) _, c_can = np.linalg.eigh(fock_vv[active_vir][:, active_vir]) # Transform the natural orbitals no_coeff_avir = util.einsum( \"pi,iq,qj->pj\", mo_coeff[:, nocc:], c[:, :num_active_vir], c_can ) no_coeff_fvir = mo_coeff[:, nocc:] @ c[:, num_active_vir:] no_coeff_occ = mo_coeff[:, :nocc] no_coeff = np.concatenate((no_coeff_occ, no_coeff_avir, no_coeff_fvir), axis=1) # Build the natural orbital space active = np.zeros(mo_occ.shape, dtype=np.bool_) frozen = np.concatenate( ( np.zeros((nocc + num_active_vir,), dtype=np.bool_), np.ones((mo_occ.size - nocc - num_active_vir,), dtype=np.bool_), ) ) no_space = Space( occupied=mo_occ > 0, frozen=frozen, active=active, ) return no_coeff, mo_occ, no_space # Construct the natural orbitals if mf.mo_occ.ndim == 2: coeff_a, occ_a, space_a = _construct( np.asarray(dm1[0], dtype=types[float]), np.asarray(mf.mo_energy[0], dtype=types[float]), np.asarray(mf.mo_coeff[0], dtype=types[float]), np.asarray(mf.mo_occ[0], dtype=types[float]), ) coeff_b, occ_b, space_b = _construct( np.asarray(dm1[1], dtype=types[float]), np.asarray(mf.mo_energy[1], dtype=types[float]), np.asarray(mf.mo_coeff[1], dtype=types[float]), np.asarray(mf.mo_occ[1], dtype=types[float]), ) return (coeff_a, coeff_b), (occ_a, occ_b), (space_a, space_b) else: return _construct( np.asarray(dm1, dtype=types[float]), np.asarray(mf.mo_energy, dtype=types[float]), np.asarray(mf.mo_coeff, dtype=types[float]), np.asarray(mf.mo_occ, dtype=types[float]), )","title":"Space"},{"location":"reference/ham/space/#ebcc.ham.space.Space","text":"Space class. .. code-block:: none \u2500\u252c\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u2502 frozen \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u252c\u2500 virtual \u2502 \u2502 active \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 correlated \u2502 \u2502 inactive \u2502 \u2502 \u2500\u253c\u2500 \u251c\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2524 \u2500\u253c\u2500 \u2502 \u2502 inactive \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 correlated occupied \u2502 \u2502 active \u2502 \u2502 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2500\u2534\u2500 \u2502 \u2502 frozen \u2502 \u2500\u2534\u2500 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Initialise the space. Parameters: occupied ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is occupied. frozen ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is frozen. active ( NDArray [ B ] ) \u2013 Array containing boolean flags indicating whether or not each orbital is active. Source code in ebcc/ham/space.py def __init__( self, occupied: NDArray[B], frozen: NDArray[B], active: NDArray[B], ) -> None: \"\"\"Initialise the space. Args: occupied: Array containing boolean flags indicating whether or not each orbital is occupied. frozen: Array containing boolean flags indicating whether or not each orbital is frozen. active: Array containing boolean flags indicating whether or not each orbital is active. \"\"\" self._occupied = np.asarray(occupied, dtype=np.bool_) self._frozen = np.asarray(frozen, dtype=np.bool_) self._active = np.asarray(active, dtype=np.bool_) # Checks: if not (self._occupied.size == self._frozen.size == self._active.size): raise ValueError(\"The sizes of the space arrays must match.\") if np.any(np.bitwise_and(self._frozen, self._active)): raise ValueError(\"Frozen and active orbitals must be mutually exclusive.\")","title":"Space"},{"location":"reference/ham/space/#ebcc.ham.space.Space.occupied","text":"Get a boolean mask of occupied orbitals.","title":"occupied"},{"location":"reference/ham/space/#ebcc.ham.space.Space.virtual","text":"Get a boolean mask of virtual orbitals.","title":"virtual"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nmo","text":"Get the number of orbitals.","title":"nmo"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nocc","text":"Get the number of occupied orbitals.","title":"nocc"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nvir","text":"Get the number of virtual orbitals.","title":"nvir"},{"location":"reference/ham/space/#ebcc.ham.space.Space.correlated","text":"Get a boolean mask of correlated orbitals.","title":"correlated"},{"location":"reference/ham/space/#ebcc.ham.space.Space.correlated_occupied","text":"Get a boolean mask of occupied correlated orbitals.","title":"correlated_occupied"},{"location":"reference/ham/space/#ebcc.ham.space.Space.correlated_virtual","text":"Get a boolean mask of virtual correlated orbitals.","title":"correlated_virtual"},{"location":"reference/ham/space/#ebcc.ham.space.Space.ncorr","text":"Get the number of correlated orbitals.","title":"ncorr"},{"location":"reference/ham/space/#ebcc.ham.space.Space.ncocc","text":"Get the number of occupied correlated orbitals.","title":"ncocc"},{"location":"reference/ham/space/#ebcc.ham.space.Space.ncvir","text":"Get the number of virtual correlated orbitals.","title":"ncvir"},{"location":"reference/ham/space/#ebcc.ham.space.Space.inactive","text":"Get a boolean mask of inactive orbitals.","title":"inactive"},{"location":"reference/ham/space/#ebcc.ham.space.Space.inactive_occupied","text":"Get a boolean mask of occupied inactive orbitals.","title":"inactive_occupied"},{"location":"reference/ham/space/#ebcc.ham.space.Space.inactive_virtual","text":"Get a boolean mask of virtual inactive orbitals.","title":"inactive_virtual"},{"location":"reference/ham/space/#ebcc.ham.space.Space.ninact","text":"Get the number of inactive orbitals.","title":"ninact"},{"location":"reference/ham/space/#ebcc.ham.space.Space.niocc","text":"Get the number of occupied inactive orbitals.","title":"niocc"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nivir","text":"Get the number of virtual inactive orbitals.","title":"nivir"},{"location":"reference/ham/space/#ebcc.ham.space.Space.frozen","text":"Get a boolean mask of frozen orbitals.","title":"frozen"},{"location":"reference/ham/space/#ebcc.ham.space.Space.frozen_occupied","text":"Get a boolean mask of occupied frozen orbitals.","title":"frozen_occupied"},{"location":"reference/ham/space/#ebcc.ham.space.Space.frozen_virtual","text":"Get a boolean mask of virtual frozen orbitals.","title":"frozen_virtual"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nfroz","text":"Get the number of frozen orbitals.","title":"nfroz"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nfocc","text":"Get the number of occupied frozen orbitals.","title":"nfocc"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nfvir","text":"Get the number of virtual frozen orbitals.","title":"nfvir"},{"location":"reference/ham/space/#ebcc.ham.space.Space.active","text":"Get a boolean mask of active orbitals.","title":"active"},{"location":"reference/ham/space/#ebcc.ham.space.Space.active_occupied","text":"Get a boolean mask of occupied active orbitals.","title":"active_occupied"},{"location":"reference/ham/space/#ebcc.ham.space.Space.active_virtual","text":"Get a boolean mask of virtual active orbitals.","title":"active_virtual"},{"location":"reference/ham/space/#ebcc.ham.space.Space.nact","text":"Get the number of active orbitals.","title":"nact"},{"location":"reference/ham/space/#ebcc.ham.space.Space.naocc","text":"Get the number of occupied active orbitals.","title":"naocc"},{"location":"reference/ham/space/#ebcc.ham.space.Space.navir","text":"Get the number of virtual active orbitals.","title":"navir"},{"location":"reference/ham/space/#ebcc.ham.space.Space.__repr__","text":"Get a string representation of the space. Source code in ebcc/ham/space.py def __repr__(self) -> str: \"\"\"Get a string representation of the space.\"\"\" out = \"(%do, %dv)\" % (self.nocc, self.nvir) parts = [] if self.nfroz: parts.append(\"(%do, %dv) frozen\" % (self.nfocc, self.nfvir)) if self.nact: parts.append(\"(%do, %dv) active\" % (self.naocc, self.navir)) if len(parts): out += \" [\" + \", \".join(parts) + \"]\" return out","title":"__repr__"},{"location":"reference/ham/space/#ebcc.ham.space.Space.size","text":"Convert a character corresponding to a space to the size of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: int \u2013 Size of the space. Source code in ebcc/ham/space.py def size(self, char: str) -> int: \"\"\"Convert a character corresponding to a space to the size of that space. Args: char: Character to convert. Returns: Size of the space. \"\"\" return { \"x\": self.ncorr, \"o\": self.ncocc, \"O\": self.naocc, \"i\": self.niocc, \"v\": self.ncvir, \"V\": self.navir, \"a\": self.nivir, }[char]","title":"size"},{"location":"reference/ham/space/#ebcc.ham.space.Space.mask","text":"Convert a character corresponding to a space to a mask of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def mask(self, char: str) -> NDArray[B]: \"\"\"Convert a character corresponding to a space to a mask of that space. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return { \"x\": self.correlated, \"o\": self.correlated_occupied, \"O\": self.active_occupied, \"i\": self.inactive_occupied, \"v\": self.correlated_virtual, \"V\": self.active_virtual, \"a\": self.inactive_virtual, }[char]","title":"mask"},{"location":"reference/ham/space/#ebcc.ham.space.Space.slice","text":"Convert a character corresponding to a space to a slice of that space. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py @functools.lru_cache(maxsize=128) # noqa: B019 def slice(self, char: str) -> _slice: \"\"\"Convert a character corresponding to a space to a slice of that space. Args: char: Character to convert. Returns: Slice of the space. \"\"\" # Check that the respective mask is contiguous mask = self.mask(char) first = np.argmax(mask) size = self.size(char) if not np.all(mask[first : first + size]): raise ValueError( f\"Space '{char}' is not contiguous. In order to slice into this space, \" \"the `mask` method must be used. If you see this error internally, it is \" \"likely that you have constructed a disjoint space. Please reorder the \" \"orbitals in the space.\" ) return slice(first, first + size)","title":"slice"},{"location":"reference/ham/space/#ebcc.ham.space.Space.omask","text":"Like mask , but returns only a mask into only the occupied sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def omask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the occupied sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.occupied]","title":"omask"},{"location":"reference/ham/space/#ebcc.ham.space.Space.vmask","text":"Like mask , but returns only a mask into only the virtual sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def vmask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the virtual sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.virtual]","title":"vmask"},{"location":"reference/ham/space/#ebcc.ham.space.Space.xmask","text":"Like mask , but returns only a mask into only the correlated sector. Parameters: char ( str ) \u2013 Character to convert. Returns: NDArray [ B ] \u2013 Mask of the space. Source code in ebcc/ham/space.py def xmask(self, char: str) -> NDArray[B]: \"\"\"Like `mask`, but returns only a mask into only the correlated sector. Args: char: Character to convert. Returns: Mask of the space. \"\"\" return self.mask(char)[self.correlated]","title":"xmask"},{"location":"reference/ham/space/#ebcc.ham.space.Space.oslice","text":"Like slice , but returns only a slice into only the occupied sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def oslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the occupied sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nocc = self.nocc return slice(s.start, min(s.stop, nocc))","title":"oslice"},{"location":"reference/ham/space/#ebcc.ham.space.Space.vslice","text":"Like slice , but returns only a slice into only the virtual sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def vslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the virtual sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nocc = self.nocc return slice(max(s.start, nocc) - nocc, s.stop - nocc)","title":"vslice"},{"location":"reference/ham/space/#ebcc.ham.space.Space.xslice","text":"Like slice , but returns only a slice into only the correlated sector. Parameters: char ( str ) \u2013 Character to convert. Returns: _slice \u2013 Slice of the space. Source code in ebcc/ham/space.py def xslice(self, char: str) -> _slice: \"\"\"Like `slice`, but returns only a slice into only the correlated sector. Args: char: Character to convert. Returns: Slice of the space. \"\"\" s = self.slice(char) nfocc = self.nfocc return slice(s.start - nfocc, s.stop - nfocc)","title":"xslice"},{"location":"reference/ham/space/#ebcc.ham.space.construct_default_space","text":"Construct a default space. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. Returns: Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 The molecular orbital coefficients, the molecular orbital occupation numbers, and the Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 default space. Source code in ebcc/ham/space.py def construct_default_space(mf: SCF) -> Union[RConstructSpaceReturnType, UConstructSpaceReturnType]: \"\"\"Construct a default space. Args: mf: PySCF mean-field object. Returns: The molecular orbital coefficients, the molecular orbital occupation numbers, and the default space. \"\"\" def _construct(mo_occ: NDArray[T]) -> Space: \"\"\"Build the default space.\"\"\" frozen = np.zeros(mo_occ.shape, dtype=np.bool_) active = np.zeros(mo_occ.shape, dtype=np.bool_) space = Space( occupied=mo_occ > 0, frozen=frozen, active=active, ) return space # Construct the default space if mf.mo_occ.ndim == 2: space_a = _construct(mf.mo_occ[0]) space_b = _construct(mf.mo_occ[1]) return mf.mo_coeff, mf.mo_occ, (space_a, space_b) else: return mf.mo_coeff, mf.mo_occ, _construct(mf.mo_occ)","title":"construct_default_space"},{"location":"reference/ham/space/#ebcc.ham.space.construct_fno_space","text":"Construct a frozen natural orbital space. Parameters: mf ( SCF ) \u2013 PySCF mean-field object. occ_tol ( Optional [ float ] , default: 1e-05 ) \u2013 Threshold in the natural orbital occupation numbers. occ_frac ( Optional [ float ] , default: None ) \u2013 Fraction of the natural orbital occupation numbers to be retained. Overrides occ_tol if both are specified. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. If provided, use these amplitudes when calculating the MP2 1RDM. Returns: Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 The natural orbital coefficients, the natural orbital occupation numbers, and the frozen Union [ RConstructSpaceReturnType , UConstructSpaceReturnType ] \u2013 natural orbital space. Source code in ebcc/ham/space.py def construct_fno_space( mf: SCF, occ_tol: Optional[float] = 1e-5, occ_frac: Optional[float] = None, amplitudes: Optional[Namespace[SpinArrayType]] = None, ) -> Union[RConstructSpaceReturnType, UConstructSpaceReturnType]: \"\"\"Construct a frozen natural orbital space. Args: mf: PySCF mean-field object. occ_tol: Threshold in the natural orbital occupation numbers. occ_frac: Fraction of the natural orbital occupation numbers to be retained. Overrides `occ_tol` if both are specified. amplitudes: Cluster amplitudes. If provided, use these amplitudes when calculating the MP2 1RDM. Returns: The natural orbital coefficients, the natural orbital occupation numbers, and the frozen natural orbital space. \"\"\" # Get the MP2 1RDM solver = pyscf.mp.mp2.MP2(mf) dm1: NDArray[T] if not amplitudes: solver.kernel() dm1 = np.asarray(solver.make_rdm1(), dtype=types[float]) else: if isinstance(amplitudes.t2, util.Namespace): t2 = (amplitudes.t2.aaaa, amplitudes.t2.abab, amplitudes.t2.bbbb) dm1 = np.asarray(solver.make_rdm1(t2=t2), dtype=types[float]) else: dm1 = np.asarray(solver.make_rdm1(t2=amplitudes.t2), dtype=types[float]) # def _construct(dm1, mo_energy, mo_coeff, mo_occ): def _construct( dm1: NDArray[T], mo_energy: NDArray[T], mo_coeff: NDArray[T], mo_occ: NDArray[T], ) -> RConstructSpaceReturnType: # Get the number of occupied orbitals nocc = np.count_nonzero(mo_occ > 0) # Calculate the natural orbitals n, c = np.linalg.eigh(dm1[nocc:, nocc:]) n, c = n[::-1], c[:, ::-1] # Truncate the natural orbitals if occ_frac is None: active_vir = n > occ_tol else: active_vir = np.cumsum(n / np.sum(n)) <= occ_frac num_active_vir = np.count_nonzero(active_vir) # Canonicalise the natural orbitals fock_vv = np.diag(mo_energy[nocc:]) fock_vv = util.einsum(\"ab,au,bv->uv\", fock_vv, c, c) _, c_can = np.linalg.eigh(fock_vv[active_vir][:, active_vir]) # Transform the natural orbitals no_coeff_avir = util.einsum( \"pi,iq,qj->pj\", mo_coeff[:, nocc:], c[:, :num_active_vir], c_can ) no_coeff_fvir = mo_coeff[:, nocc:] @ c[:, num_active_vir:] no_coeff_occ = mo_coeff[:, :nocc] no_coeff = np.concatenate((no_coeff_occ, no_coeff_avir, no_coeff_fvir), axis=1) # Build the natural orbital space active = np.zeros(mo_occ.shape, dtype=np.bool_) frozen = np.concatenate( ( np.zeros((nocc + num_active_vir,), dtype=np.bool_), np.ones((mo_occ.size - nocc - num_active_vir,), dtype=np.bool_), ) ) no_space = Space( occupied=mo_occ > 0, frozen=frozen, active=active, ) return no_coeff, mo_occ, no_space # Construct the natural orbitals if mf.mo_occ.ndim == 2: coeff_a, occ_a, space_a = _construct( np.asarray(dm1[0], dtype=types[float]), np.asarray(mf.mo_energy[0], dtype=types[float]), np.asarray(mf.mo_coeff[0], dtype=types[float]), np.asarray(mf.mo_occ[0], dtype=types[float]), ) coeff_b, occ_b, space_b = _construct( np.asarray(dm1[1], dtype=types[float]), np.asarray(mf.mo_energy[1], dtype=types[float]), np.asarray(mf.mo_coeff[1], dtype=types[float]), np.asarray(mf.mo_occ[1], dtype=types[float]), ) return (coeff_a, coeff_b), (occ_a, occ_b), (space_a, space_b) else: return _construct( np.asarray(dm1, dtype=types[float]), np.asarray(mf.mo_energy, dtype=types[float]), np.asarray(mf.mo_coeff, dtype=types[float]), np.asarray(mf.mo_occ, dtype=types[float]), )","title":"construct_fno_space"},{"location":"reference/opt/","text":"Orbital-optimised coupled cluster approaches.","title":"Index"},{"location":"reference/opt/base/","text":"Base classes for ebcc.opt . ebcc.opt.base.BaseOptions(e_tol=1e-08, t_tol=1e-08, max_iter=20, diis_space=9, diis_min_space=1, damping=0.0) dataclass Bases: _BaseOptions Options for Brueckner-orbital calculations. Parameters: e_tol ( float , default: 1e-08 ) \u2013 Threshold for converged in the correlation energy. t_tol ( float , default: 1e-08 ) \u2013 Threshold for converged in the amplitude norm. max_iter ( int , default: 20 ) \u2013 Maximum number of iterations. diis_space ( int , default: 9 ) \u2013 Number of amplitudes to use in DIIS extrapolation. diis_min_space ( int , default: 1 ) \u2013 Minimum number of amplitudes to use in DIIS extrapolation. damping ( float , default: 0.0 ) \u2013 Damping factor for DIIS extrapolation. ebcc.opt.base.BaseBruecknerEBCC(cc, options=None, **kwargs) Bases: ABC Base class for Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\") ebcc.opt.base.BaseBruecknerEBCC.spin_type: str property Get the spin type. ebcc.opt.base.BaseBruecknerEBCC.name: str property Get the name of the method. ebcc.opt.base.BaseBruecknerEBCC.kernel() Run the Bruckner-orbital coupled cluster calculation. Returns: float \u2013 Correlation energy. Source code in ebcc/opt/base.py def kernel(self) -> float: \"\"\"Run the Bruckner-orbital coupled cluster calculation. Returns: Correlation energy. \"\"\" timer = util.Timer() # Make sure the initial CC calculation is converged: if not self.cc.converged: with lib.temporary_env(self.cc, log=NullLogger()): self.cc.kernel() # Set up DIIS: damping = self.Damping(options=self.options) # Initialise coefficients: mo_coeff_new: NDArray[T] = np.copy(np.asarray(self.cc.mo_coeff, dtype=types[float])) mo_coeff_ref: NDArray[T] = np.copy(np.asarray(self.cc.mo_coeff, dtype=types[float])) mo_coeff_ref = self.mo_to_correlated(mo_coeff_ref) u_tot = None self.cc.log.output(\"Solving for Brueckner orbitals.\") self.cc.log.debug(\"\") self.log.info( f\"{ANSI.B}{'Iter':>4s} {'Energy (corr.)':>16s} {'Energy (tot.)':>18s} \" f\"{'Conv.':>8s} {'\u0394(Energy)':>13s} {'|T1|':>13s}{ANSI.R}\" ) self.log.info( f\"%4d %16.10f %18.10f {[ANSI.r, ANSI.g][self.cc.converged]}%8r{ANSI.R}\", 0, self.cc.e_corr, self.cc.e_tot, self.cc.converged, ) converged = False for niter in range(1, self.options.max_iter + 1): # Update rotation matrix: u, u_tot = self.get_rotation_matrix(u_tot=u_tot, damping=damping) # Update MO coefficients: mo_coeff_new = self.update_coefficients(u_tot, mo_coeff_new, mo_coeff_ref) # Transform mean-field and amplitudes: self.mf.mo_coeff = numpy.asarray(mo_coeff_new) self.mf.e_tot = self.mf.energy_tot() amplitudes = self.transform_amplitudes(u) # Run CC calculation: e_prev = self.cc.e_tot with lib.temporary_env(self.cc, log=NullLogger()): self.cc.__class__.__init__( self.cc, self.mf, log=self.cc.log, ansatz=self.cc.ansatz, space=self.cc.space, omega=self.cc.omega, g=self.cc.bare_g, G=self.cc.bare_G, options=self.cc.options, ) self.cc.amplitudes = amplitudes self.cc.kernel() de = abs(e_prev - self.cc.e_tot) dt = self.get_t1_norm() # Log the iteration: converged_e = bool(de < self.options.e_tol) converged_t = bool(dt < self.options.t_tol) self.log.info( f\"%4s %16.10f %18.10f {[ANSI.r, ANSI.g][int(converged)]}%8r{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_e)]}%13.3e{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_t)]}%13.3e{ANSI.R}\", niter, self.cc.e_corr, self.cc.e_tot, self.cc.converged, de, dt, ) # Check for convergence: converged = converged_e and converged_t if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") self.cc.log.debug(\"\") self.cc.log.output(\"E(corr) = %.10f\", self.cc.e_corr) self.cc.log.output(\"E(tot) = %.10f\", self.cc.e_tot) self.cc.log.debug(\"\") self.cc.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.cc.log.debug(\"\") return self.cc.e_corr ebcc.opt.base.BaseBruecknerEBCC.get_rotation_matrix(u_tot=None, damping=None, t1=None) abstractmethod Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/base.py @abstractmethod def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" pass ebcc.opt.base.BaseBruecknerEBCC.transform_amplitudes(u, amplitudes=None) abstractmethod Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/base.py @abstractmethod def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" pass ebcc.opt.base.BaseBruecknerEBCC.get_t1_norm(amplitudes=None) abstractmethod Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/base.py @abstractmethod def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" pass ebcc.opt.base.BaseBruecknerEBCC.mo_to_correlated(mo_coeff) abstractmethod Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( Any ) \u2013 MO coefficients. Returns: Any \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def mo_to_correlated(self, mo_coeff: Any) -> Any: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" pass ebcc.opt.base.BaseBruecknerEBCC.mo_update_correlated(mo_coeff, mo_coeff_corr) abstractmethod Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( Any ) \u2013 MO coefficients. mo_coeff_corr ( Any ) \u2013 Correlated slice of MO coefficients. Returns: Any \u2013 Updated MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def mo_update_correlated(self, mo_coeff: Any, mo_coeff_corr: Any) -> Any: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" pass ebcc.opt.base.BaseBruecknerEBCC.update_coefficients(u_tot, mo_coeff_new, mo_coeff_ref) abstractmethod Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff_new ( Any ) \u2013 New MO coefficients. mo_coeff_ref ( Any ) \u2013 Reference MO coefficients. Returns: Any \u2013 Updated MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def update_coefficients( self, u_tot: SpinArrayType, mo_coeff_new: Any, mo_coeff_ref: Any ) -> Any: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff_new: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" pass","title":"Base"},{"location":"reference/opt/base/#ebcc.opt.base.BaseOptions","text":"Bases: _BaseOptions Options for Brueckner-orbital calculations. Parameters: e_tol ( float , default: 1e-08 ) \u2013 Threshold for converged in the correlation energy. t_tol ( float , default: 1e-08 ) \u2013 Threshold for converged in the amplitude norm. max_iter ( int , default: 20 ) \u2013 Maximum number of iterations. diis_space ( int , default: 9 ) \u2013 Number of amplitudes to use in DIIS extrapolation. diis_min_space ( int , default: 1 ) \u2013 Minimum number of amplitudes to use in DIIS extrapolation. damping ( float , default: 0.0 ) \u2013 Damping factor for DIIS extrapolation.","title":"BaseOptions"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC","text":"Bases: ABC Base class for Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\")","title":"BaseBruecknerEBCC"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.spin_type","text":"Get the spin type.","title":"spin_type"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.name","text":"Get the name of the method.","title":"name"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.kernel","text":"Run the Bruckner-orbital coupled cluster calculation. Returns: float \u2013 Correlation energy. Source code in ebcc/opt/base.py def kernel(self) -> float: \"\"\"Run the Bruckner-orbital coupled cluster calculation. Returns: Correlation energy. \"\"\" timer = util.Timer() # Make sure the initial CC calculation is converged: if not self.cc.converged: with lib.temporary_env(self.cc, log=NullLogger()): self.cc.kernel() # Set up DIIS: damping = self.Damping(options=self.options) # Initialise coefficients: mo_coeff_new: NDArray[T] = np.copy(np.asarray(self.cc.mo_coeff, dtype=types[float])) mo_coeff_ref: NDArray[T] = np.copy(np.asarray(self.cc.mo_coeff, dtype=types[float])) mo_coeff_ref = self.mo_to_correlated(mo_coeff_ref) u_tot = None self.cc.log.output(\"Solving for Brueckner orbitals.\") self.cc.log.debug(\"\") self.log.info( f\"{ANSI.B}{'Iter':>4s} {'Energy (corr.)':>16s} {'Energy (tot.)':>18s} \" f\"{'Conv.':>8s} {'\u0394(Energy)':>13s} {'|T1|':>13s}{ANSI.R}\" ) self.log.info( f\"%4d %16.10f %18.10f {[ANSI.r, ANSI.g][self.cc.converged]}%8r{ANSI.R}\", 0, self.cc.e_corr, self.cc.e_tot, self.cc.converged, ) converged = False for niter in range(1, self.options.max_iter + 1): # Update rotation matrix: u, u_tot = self.get_rotation_matrix(u_tot=u_tot, damping=damping) # Update MO coefficients: mo_coeff_new = self.update_coefficients(u_tot, mo_coeff_new, mo_coeff_ref) # Transform mean-field and amplitudes: self.mf.mo_coeff = numpy.asarray(mo_coeff_new) self.mf.e_tot = self.mf.energy_tot() amplitudes = self.transform_amplitudes(u) # Run CC calculation: e_prev = self.cc.e_tot with lib.temporary_env(self.cc, log=NullLogger()): self.cc.__class__.__init__( self.cc, self.mf, log=self.cc.log, ansatz=self.cc.ansatz, space=self.cc.space, omega=self.cc.omega, g=self.cc.bare_g, G=self.cc.bare_G, options=self.cc.options, ) self.cc.amplitudes = amplitudes self.cc.kernel() de = abs(e_prev - self.cc.e_tot) dt = self.get_t1_norm() # Log the iteration: converged_e = bool(de < self.options.e_tol) converged_t = bool(dt < self.options.t_tol) self.log.info( f\"%4s %16.10f %18.10f {[ANSI.r, ANSI.g][int(converged)]}%8r{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_e)]}%13.3e{ANSI.R}\" f\" {[ANSI.r, ANSI.g][int(converged_t)]}%13.3e{ANSI.R}\", niter, self.cc.e_corr, self.cc.e_tot, self.cc.converged, de, dt, ) # Check for convergence: converged = converged_e and converged_t if converged: self.log.debug(\"\") self.log.output(f\"{ANSI.g}Converged{ANSI.R}.\") break else: self.log.debug(\"\") self.log.warning(f\"{ANSI.r}Failed to converge{ANSI.R}.\") self.cc.log.debug(\"\") self.cc.log.output(\"E(corr) = %.10f\", self.cc.e_corr) self.cc.log.output(\"E(tot) = %.10f\", self.cc.e_tot) self.cc.log.debug(\"\") self.cc.log.debug(\"Time elapsed: %s\", timer.format_time(timer())) self.cc.log.debug(\"\") return self.cc.e_corr","title":"kernel"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.get_rotation_matrix","text":"Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/base.py @abstractmethod def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" pass","title":"get_rotation_matrix"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.transform_amplitudes","text":"Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/base.py @abstractmethod def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" pass","title":"transform_amplitudes"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.get_t1_norm","text":"Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/base.py @abstractmethod def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" pass","title":"get_t1_norm"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.mo_to_correlated","text":"Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( Any ) \u2013 MO coefficients. Returns: Any \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def mo_to_correlated(self, mo_coeff: Any) -> Any: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" pass","title":"mo_to_correlated"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.mo_update_correlated","text":"Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( Any ) \u2013 MO coefficients. mo_coeff_corr ( Any ) \u2013 Correlated slice of MO coefficients. Returns: Any \u2013 Updated MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def mo_update_correlated(self, mo_coeff: Any, mo_coeff_corr: Any) -> Any: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" pass","title":"mo_update_correlated"},{"location":"reference/opt/base/#ebcc.opt.base.BaseBruecknerEBCC.update_coefficients","text":"Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff_new ( Any ) \u2013 New MO coefficients. mo_coeff_ref ( Any ) \u2013 Reference MO coefficients. Returns: Any \u2013 Updated MO coefficients. Source code in ebcc/opt/base.py @abstractmethod def update_coefficients( self, u_tot: SpinArrayType, mo_coeff_new: Any, mo_coeff_ref: Any ) -> Any: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff_new: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" pass","title":"update_coefficients"},{"location":"reference/opt/gbrueckner/","text":"Generalised Brueckner-orbital coupled cluster. ebcc.opt.gbrueckner.BruecknerGEBCC(cc, options=None, **kwargs) Bases: BaseBruecknerEBCC Generalised Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\") ebcc.opt.gbrueckner.BruecknerGEBCC.get_rotation_matrix(u_tot=None, damping=None, t1=None) Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/gbrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = np.eye(self.cc.space.ncorr, dtype=types[float]) zocc = np.zeros((self.cc.space.ncocc, self.cc.space.ncocc)) zvir = np.zeros((self.cc.space.ncvir, self.cc.space.ncvir)) t1_block: NDArray[T] = np.block([[zocc, -t1], [np.transpose(t1), zvir]]) u = scipy.linalg.expm(t1_block) u_tot = u_tot @ u if np.linalg.det(u_tot) < 0: u_tot = _put(u_tot, np.ix_(np.arange(u_tot.shape[0]), np.array([0])), -u_tot[:, 0]) a: NDArray[T] = np.asarray(np.real(scipy.linalg.logm(u_tot)), dtype=types[float]) if damping is not None: a = damping(a, error=t1) u_tot = scipy.linalg.expm(a) return u, u_tot ebcc.opt.gbrueckner.BruecknerGEBCC.transform_amplitudes(u, amplitudes=None) Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/gbrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = self.cc.space.ncocc ci = u[:nocc, :nocc] ca = u[nocc:, nocc:] # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): args: list[Union[tuple[int, ...], NDArray[T]]] = [ self.cc.amplitudes[name], tuple(range(n * 2)), ] for i in range(n): args += [ci, (i, i + n * 2)] for i in range(n): args += [ca, (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] self.cc.amplitudes[name] = util.einsum(*args) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes ebcc.opt.gbrueckner.BruecknerGEBCC.get_t1_norm(amplitudes=None) Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/gbrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight: T = np.linalg.norm(amplitudes[\"t1\"]) return weight ebcc.opt.gbrueckner.BruecknerGEBCC.mo_to_correlated(mo_coeff) Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. Returns: NDArray [ T ] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/gbrueckner.py def mo_to_correlated(self, mo_coeff: NDArray[T]) -> NDArray[T]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return mo_coeff[:, self.cc.space.correlated] ebcc.opt.gbrueckner.BruecknerGEBCC.mo_update_correlated(mo_coeff, mo_coeff_corr) Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. mo_coeff_corr ( NDArray [ T ] ) \u2013 Correlated slice of MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/gbrueckner.py def mo_update_correlated(self, mo_coeff: NDArray[T], mo_coeff_corr: NDArray[T]) -> NDArray[T]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff = _put( mo_coeff, np.ix_(np.arange(mo_coeff.shape[0]), self.cc.space.correlated), # type: ignore mo_coeff_corr, ) return mo_coeff ebcc.opt.gbrueckner.BruecknerGEBCC.update_coefficients(u_tot, mo_coeff, mo_coeff_ref) Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( NDArray [ T ] ) \u2013 New MO coefficients. mo_coeff_ref ( NDArray [ T ] ) \u2013 Reference MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/gbrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: NDArray[T], mo_coeff_ref: NDArray[T] ) -> NDArray[T]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = util.einsum(\"pi,ij->pj\", mo_coeff_ref, u_tot) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"Generalised"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC","text":"Bases: BaseBruecknerEBCC Generalised Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\")","title":"BruecknerGEBCC"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.get_rotation_matrix","text":"Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/gbrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = np.eye(self.cc.space.ncorr, dtype=types[float]) zocc = np.zeros((self.cc.space.ncocc, self.cc.space.ncocc)) zvir = np.zeros((self.cc.space.ncvir, self.cc.space.ncvir)) t1_block: NDArray[T] = np.block([[zocc, -t1], [np.transpose(t1), zvir]]) u = scipy.linalg.expm(t1_block) u_tot = u_tot @ u if np.linalg.det(u_tot) < 0: u_tot = _put(u_tot, np.ix_(np.arange(u_tot.shape[0]), np.array([0])), -u_tot[:, 0]) a: NDArray[T] = np.asarray(np.real(scipy.linalg.logm(u_tot)), dtype=types[float]) if damping is not None: a = damping(a, error=t1) u_tot = scipy.linalg.expm(a) return u, u_tot","title":"get_rotation_matrix"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.transform_amplitudes","text":"Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/gbrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = self.cc.space.ncocc ci = u[:nocc, :nocc] ca = u[nocc:, nocc:] # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): args: list[Union[tuple[int, ...], NDArray[T]]] = [ self.cc.amplitudes[name], tuple(range(n * 2)), ] for i in range(n): args += [ci, (i, i + n * 2)] for i in range(n): args += [ca, (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] self.cc.amplitudes[name] = util.einsum(*args) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes","title":"transform_amplitudes"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.get_t1_norm","text":"Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/gbrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight: T = np.linalg.norm(amplitudes[\"t1\"]) return weight","title":"get_t1_norm"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.mo_to_correlated","text":"Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. Returns: NDArray [ T ] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/gbrueckner.py def mo_to_correlated(self, mo_coeff: NDArray[T]) -> NDArray[T]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return mo_coeff[:, self.cc.space.correlated]","title":"mo_to_correlated"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.mo_update_correlated","text":"Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. mo_coeff_corr ( NDArray [ T ] ) \u2013 Correlated slice of MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/gbrueckner.py def mo_update_correlated(self, mo_coeff: NDArray[T], mo_coeff_corr: NDArray[T]) -> NDArray[T]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff = _put( mo_coeff, np.ix_(np.arange(mo_coeff.shape[0]), self.cc.space.correlated), # type: ignore mo_coeff_corr, ) return mo_coeff","title":"mo_update_correlated"},{"location":"reference/opt/gbrueckner/#ebcc.opt.gbrueckner.BruecknerGEBCC.update_coefficients","text":"Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( NDArray [ T ] ) \u2013 New MO coefficients. mo_coeff_ref ( NDArray [ T ] ) \u2013 Reference MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/gbrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: NDArray[T], mo_coeff_ref: NDArray[T] ) -> NDArray[T]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = util.einsum(\"pi,ij->pj\", mo_coeff_ref, u_tot) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"update_coefficients"},{"location":"reference/opt/rbrueckner/","text":"Restricted Brueckner-orbital coupled cluster. ebcc.opt.rbrueckner.BruecknerREBCC(cc, options=None, **kwargs) Bases: BaseBruecknerEBCC Restricted Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\") ebcc.opt.rbrueckner.BruecknerREBCC.get_rotation_matrix(u_tot=None, damping=None, t1=None) Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/rbrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = np.eye(self.cc.space.ncorr, dtype=types[float]) zocc = np.zeros((self.cc.space.ncocc, self.cc.space.ncocc)) zvir = np.zeros((self.cc.space.ncvir, self.cc.space.ncvir)) t1_block: NDArray[T] = np.block([[zocc, -t1], [np.transpose(t1), zvir]]) u = scipy.linalg.expm(t1_block) u_tot = u_tot @ u if np.linalg.det(u_tot) < 0: u_tot = _put(u_tot, np.ix_(np.arange(u_tot.shape[0]), np.array([0])), -u_tot[:, 0]) a: NDArray[T] = np.asarray(np.real(scipy.linalg.logm(u_tot)), dtype=types[float]) if damping is not None: a = damping(a, error=t1) u_tot = scipy.linalg.expm(a) return u, u_tot ebcc.opt.rbrueckner.BruecknerREBCC.transform_amplitudes(u, amplitudes=None) Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/rbrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = self.cc.space.ncocc ci = u[:nocc, :nocc] ca = u[nocc:, nocc:] # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): args: list[Union[SpinArrayType, tuple[int, ...]]] = [ self.cc.amplitudes[name], tuple(range(n * 2)), ] for i in range(n): args += [ci, (i, i + n * 2)] for i in range(n): args += [ca, (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] self.cc.amplitudes[name] = util.einsum(*args) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes ebcc.opt.rbrueckner.BruecknerREBCC.get_t1_norm(amplitudes=None) Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/rbrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight: T = np.linalg.norm(amplitudes[\"t1\"]) return weight ebcc.opt.rbrueckner.BruecknerREBCC.mo_to_correlated(mo_coeff) Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. Returns: NDArray [ T ] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/rbrueckner.py def mo_to_correlated(self, mo_coeff: NDArray[T]) -> NDArray[T]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return mo_coeff[:, self.cc.space.correlated] ebcc.opt.rbrueckner.BruecknerREBCC.mo_update_correlated(mo_coeff, mo_coeff_corr) Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. mo_coeff_corr ( NDArray [ T ] ) \u2013 Correlated slice of MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/rbrueckner.py def mo_update_correlated(self, mo_coeff: NDArray[T], mo_coeff_corr: NDArray[T]) -> NDArray[T]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff = _put( mo_coeff, np.ix_(np.arange(mo_coeff.shape[0]), self.cc.space.correlated), # type: ignore mo_coeff_corr, ) return mo_coeff ebcc.opt.rbrueckner.BruecknerREBCC.update_coefficients(u_tot, mo_coeff, mo_coeff_ref) Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( NDArray [ T ] ) \u2013 New MO coefficients. mo_coeff_ref ( NDArray [ T ] ) \u2013 Reference MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/rbrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: NDArray[T], mo_coeff_ref: NDArray[T] ) -> NDArray[T]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = util.einsum(\"pi,ij->pj\", mo_coeff_ref, u_tot) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"Restricted"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC","text":"Bases: BaseBruecknerEBCC Restricted Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\")","title":"BruecknerREBCC"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.get_rotation_matrix","text":"Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/rbrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = np.eye(self.cc.space.ncorr, dtype=types[float]) zocc = np.zeros((self.cc.space.ncocc, self.cc.space.ncocc)) zvir = np.zeros((self.cc.space.ncvir, self.cc.space.ncvir)) t1_block: NDArray[T] = np.block([[zocc, -t1], [np.transpose(t1), zvir]]) u = scipy.linalg.expm(t1_block) u_tot = u_tot @ u if np.linalg.det(u_tot) < 0: u_tot = _put(u_tot, np.ix_(np.arange(u_tot.shape[0]), np.array([0])), -u_tot[:, 0]) a: NDArray[T] = np.asarray(np.real(scipy.linalg.logm(u_tot)), dtype=types[float]) if damping is not None: a = damping(a, error=t1) u_tot = scipy.linalg.expm(a) return u, u_tot","title":"get_rotation_matrix"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.transform_amplitudes","text":"Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/rbrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = self.cc.space.ncocc ci = u[:nocc, :nocc] ca = u[nocc:, nocc:] # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): args: list[Union[SpinArrayType, tuple[int, ...]]] = [ self.cc.amplitudes[name], tuple(range(n * 2)), ] for i in range(n): args += [ci, (i, i + n * 2)] for i in range(n): args += [ca, (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] self.cc.amplitudes[name] = util.einsum(*args) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes","title":"transform_amplitudes"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.get_t1_norm","text":"Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/rbrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight: T = np.linalg.norm(amplitudes[\"t1\"]) return weight","title":"get_t1_norm"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.mo_to_correlated","text":"Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. Returns: NDArray [ T ] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/rbrueckner.py def mo_to_correlated(self, mo_coeff: NDArray[T]) -> NDArray[T]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return mo_coeff[:, self.cc.space.correlated]","title":"mo_to_correlated"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.mo_update_correlated","text":"Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( NDArray [ T ] ) \u2013 MO coefficients. mo_coeff_corr ( NDArray [ T ] ) \u2013 Correlated slice of MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/rbrueckner.py def mo_update_correlated(self, mo_coeff: NDArray[T], mo_coeff_corr: NDArray[T]) -> NDArray[T]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff = _put( mo_coeff, np.ix_(np.arange(mo_coeff.shape[0]), self.cc.space.correlated), # type: ignore mo_coeff_corr, ) return mo_coeff","title":"mo_update_correlated"},{"location":"reference/opt/rbrueckner/#ebcc.opt.rbrueckner.BruecknerREBCC.update_coefficients","text":"Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( NDArray [ T ] ) \u2013 New MO coefficients. mo_coeff_ref ( NDArray [ T ] ) \u2013 Reference MO coefficients. Returns: NDArray [ T ] \u2013 Updated MO coefficients. Source code in ebcc/opt/rbrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: NDArray[T], mo_coeff_ref: NDArray[T] ) -> NDArray[T]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = util.einsum(\"pi,ij->pj\", mo_coeff_ref, u_tot) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"update_coefficients"},{"location":"reference/opt/ubrueckner/","text":"Unrestricted Brueckner-orbital coupled cluster. ebcc.opt.ubrueckner.BruecknerUEBCC(cc, options=None, **kwargs) Bases: BaseBruecknerEBCC Unrestricted Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\") ebcc.opt.ubrueckner.BruecknerUEBCC.get_rotation_matrix(u_tot=None, damping=None, t1=None) Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/ubrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = util.Namespace( aa=np.eye(self.cc.space[0].ncorr, dtype=types[float]), bb=np.eye(self.cc.space[1].ncorr, dtype=types[float]), ) t1_block: Namespace[NDArray[T]] = util.Namespace() zocc = np.zeros((self.cc.space[0].ncocc, self.cc.space[0].ncocc)) zvir = np.zeros((self.cc.space[0].ncvir, self.cc.space[0].ncvir)) t1_block.aa = np.block([[zocc, -t1.aa], [np.transpose(t1.aa), zvir]]) zocc = np.zeros((self.cc.space[1].ncocc, self.cc.space[1].ncocc)) zvir = np.zeros((self.cc.space[1].ncvir, self.cc.space[1].ncvir)) t1_block.bb = np.block([[zocc, -t1.bb], [np.transpose(t1.bb), zvir]]) u = util.Namespace(aa=scipy.linalg.expm(t1_block.aa), bb=scipy.linalg.expm(t1_block.bb)) u_tot.aa = u_tot.aa @ u.aa u_tot.bb = u_tot.bb @ u.bb if np.linalg.det(u_tot.aa) < 0: u_tot.aa = _put( u_tot.aa, np.ix_(np.arange(u_tot.aa.shape[0]), np.array([0])), -u_tot.aa[:, 0] ) if np.linalg.det(u_tot.bb) < 0: u_tot.bb = _put( u_tot.bb, np.ix_(np.arange(u_tot.aa.shape[0]), np.array([0])), -u_tot.bb[:, 0] ) a = np.concatenate( [np.ravel(scipy.linalg.logm(u_tot.aa)), np.ravel(scipy.linalg.logm(u_tot.bb))], axis=0 ) a: NDArray[T] = np.asarray(np.real(a), dtype=types[float]) if damping is not None: xerr = np.concatenate([t1.aa.ravel(), t1.bb.ravel()]) a = damping(a, error=xerr) u_tot.aa = scipy.linalg.expm(np.reshape(a[: u_tot.aa.size], u_tot.aa.shape)) u_tot.bb = scipy.linalg.expm(np.reshape(a[u_tot.aa.size :], u_tot.bb.shape)) return u, u_tot ebcc.opt.ubrueckner.BruecknerUEBCC.transform_amplitudes(u, amplitudes=None) Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/ubrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = (self.cc.space[0].ncocc, self.cc.space[1].ncocc) ci = {\"a\": u.aa[: nocc[0], : nocc[0]], \"b\": u.bb[: nocc[1], : nocc[1]]} ca = {\"a\": u.aa[nocc[0] :, nocc[0] :], \"b\": u.bb[nocc[1] :, nocc[1] :]} # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for comb in util.generate_spin_combinations(n, unique=True): args = [getattr(self.cc.amplitudes[name], comb), tuple(range(n * 2))] for i in range(n): args += [ci[comb[i]], (i, i + n * 2)] for i in range(n): args += [ca[comb[i + n]], (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] setattr(self.cc.amplitudes[name], comb, util.einsum(*args)) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes ebcc.opt.ubrueckner.BruecknerUEBCC.get_t1_norm(amplitudes=None) Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/ubrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight_a = np.linalg.norm(amplitudes[\"t1\"].aa) weight_b = np.linalg.norm(amplitudes[\"t1\"].bb) weight: T = (weight_a**2 + weight_b**2) ** 0.5 return weight ebcc.opt.ubrueckner.BruecknerUEBCC.mo_to_correlated(mo_coeff) Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/ubrueckner.py def mo_to_correlated( self, mo_coeff: tuple[NDArray[T], NDArray[T]] ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return ( mo_coeff[0][:, self.cc.space[0].correlated], mo_coeff[1][:, self.cc.space[1].correlated], ) ebcc.opt.ubrueckner.BruecknerUEBCC.mo_update_correlated(mo_coeff, mo_coeff_corr) Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 MO coefficients. mo_coeff_corr ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 Correlated slice of MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Updated MO coefficients. Source code in ebcc/opt/ubrueckner.py def mo_update_correlated( self, mo_coeff: tuple[NDArray[T], NDArray[T]], mo_coeff_corr: tuple[NDArray[T], NDArray[T]], ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" space = self.cc.space mo_coeff = ( _put( mo_coeff[0], np.ix_(np.arange(mo_coeff[0].shape[0]), space[0].correlated), # type: ignore mo_coeff_corr[0], ), _put( mo_coeff[1], np.ix_(np.arange(mo_coeff[1].shape[0]), space[1].correlated), # type: ignore mo_coeff_corr[1], ), ) return mo_coeff ebcc.opt.ubrueckner.BruecknerUEBCC.update_coefficients(u_tot, mo_coeff, mo_coeff_ref) Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 New MO coefficients. mo_coeff_ref ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 Reference MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Updated MO coefficients. Source code in ebcc/opt/ubrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: tuple[NDArray[T], NDArray[T]], mo_coeff_ref: tuple[NDArray[T], NDArray[T]], ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = ( util.einsum(\"pi,ij->pj\", mo_coeff_ref[0], u_tot.aa), util.einsum(\"pi,ij->pj\", mo_coeff_ref[1], u_tot.bb), ) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"Unrestricted"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC","text":"Bases: BaseBruecknerEBCC Unrestricted Brueckner-orbital coupled cluster. Initialise the Brueckner EBCC object. Parameters: cc ( BaseEBCC ) \u2013 Parent EBCC object. options ( Optional [ BaseOptions ] , default: None ) \u2013 Options for the EOM calculation. **kwargs ( Any , default: {} ) \u2013 Additional keyword arguments used to update options . Source code in ebcc/opt/base.py def __init__( self, cc: BaseEBCC, options: Optional[BaseOptions] = None, **kwargs: Any, ) -> None: r\"\"\"Initialise the Brueckner EBCC object. Args: cc: Parent `EBCC` object. options: Options for the EOM calculation. **kwargs: Additional keyword arguments used to update `options`. \"\"\" # Options: if options is None: options = self.Options() self.options = options for key, val in kwargs.items(): setattr(self.options, key, val) # Parameters: self.cc = cc self.mf = cc.mf self.space = cc.space self.log = cc.log # Attributes: self.converged = False # Logging: init_logging(cc.log) cc.log.info(f\"\\n{ANSI.B}{ANSI.U}{self.name}{ANSI.R}\") cc.log.debug(f\"{ANSI.B}{'*' * len(self.name)}{ANSI.R}\") cc.log.debug(\"\") cc.log.info(f\"{ANSI.B}Options{ANSI.R}:\") cc.log.info(f\" > e_tol: {ANSI.y}{self.options.e_tol}{ANSI.R}\") cc.log.info(f\" > t_tol: {ANSI.y}{self.options.t_tol}{ANSI.R}\") cc.log.info(f\" > max_iter: {ANSI.y}{self.options.max_iter}{ANSI.R}\") cc.log.info(f\" > diis_space: {ANSI.y}{self.options.diis_space}{ANSI.R}\") cc.log.info(f\" > diis_min_space: {ANSI.y}{self.options.diis_min_space}{ANSI.R}\") cc.log.info(f\" > damping: {ANSI.y}{self.options.damping}{ANSI.R}\") cc.log.debug(\"\")","title":"BruecknerUEBCC"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.get_rotation_matrix","text":"Update the rotation matrix. Also returns the total rotation matrix. Parameters: u_tot ( Optional [ SpinArrayType ] , default: None ) \u2013 Total rotation matrix. damping ( Optional [ BaseDamping ] , default: None ) \u2013 Damping object. t1 ( Optional [ SpinArrayType ] , default: None ) \u2013 T1 amplitude. Returns: tuple [ SpinArrayType , SpinArrayType ] \u2013 Rotation matrix and total rotation matrix. Source code in ebcc/opt/ubrueckner.py def get_rotation_matrix( self, u_tot: Optional[SpinArrayType] = None, damping: Optional[BaseDamping] = None, t1: Optional[SpinArrayType] = None, ) -> tuple[SpinArrayType, SpinArrayType]: \"\"\"Update the rotation matrix. Also returns the total rotation matrix. Args: u_tot: Total rotation matrix. damping: Damping object. t1: T1 amplitude. Returns: Rotation matrix and total rotation matrix. \"\"\" if t1 is None: t1 = self.cc.t1 if u_tot is None: u_tot = util.Namespace( aa=np.eye(self.cc.space[0].ncorr, dtype=types[float]), bb=np.eye(self.cc.space[1].ncorr, dtype=types[float]), ) t1_block: Namespace[NDArray[T]] = util.Namespace() zocc = np.zeros((self.cc.space[0].ncocc, self.cc.space[0].ncocc)) zvir = np.zeros((self.cc.space[0].ncvir, self.cc.space[0].ncvir)) t1_block.aa = np.block([[zocc, -t1.aa], [np.transpose(t1.aa), zvir]]) zocc = np.zeros((self.cc.space[1].ncocc, self.cc.space[1].ncocc)) zvir = np.zeros((self.cc.space[1].ncvir, self.cc.space[1].ncvir)) t1_block.bb = np.block([[zocc, -t1.bb], [np.transpose(t1.bb), zvir]]) u = util.Namespace(aa=scipy.linalg.expm(t1_block.aa), bb=scipy.linalg.expm(t1_block.bb)) u_tot.aa = u_tot.aa @ u.aa u_tot.bb = u_tot.bb @ u.bb if np.linalg.det(u_tot.aa) < 0: u_tot.aa = _put( u_tot.aa, np.ix_(np.arange(u_tot.aa.shape[0]), np.array([0])), -u_tot.aa[:, 0] ) if np.linalg.det(u_tot.bb) < 0: u_tot.bb = _put( u_tot.bb, np.ix_(np.arange(u_tot.aa.shape[0]), np.array([0])), -u_tot.bb[:, 0] ) a = np.concatenate( [np.ravel(scipy.linalg.logm(u_tot.aa)), np.ravel(scipy.linalg.logm(u_tot.bb))], axis=0 ) a: NDArray[T] = np.asarray(np.real(a), dtype=types[float]) if damping is not None: xerr = np.concatenate([t1.aa.ravel(), t1.bb.ravel()]) a = damping(a, error=xerr) u_tot.aa = scipy.linalg.expm(np.reshape(a[: u_tot.aa.size], u_tot.aa.shape)) u_tot.bb = scipy.linalg.expm(np.reshape(a[u_tot.aa.size :], u_tot.bb.shape)) return u, u_tot","title":"get_rotation_matrix"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.transform_amplitudes","text":"Transform the amplitudes into the Brueckner orbital basis. Parameters: u ( SpinArrayType ) \u2013 Rotation matrix. amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: Namespace [ SpinArrayType ] \u2013 Transformed cluster amplitudes. Source code in ebcc/opt/ubrueckner.py def transform_amplitudes( self, u: SpinArrayType, amplitudes: Optional[Namespace[SpinArrayType]] = None ) -> Namespace[SpinArrayType]: \"\"\"Transform the amplitudes into the Brueckner orbital basis. Args: u: Rotation matrix. amplitudes: Cluster amplitudes. Returns: Transformed cluster amplitudes. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes nocc = (self.cc.space[0].ncocc, self.cc.space[1].ncocc) ci = {\"a\": u.aa[: nocc[0], : nocc[0]], \"b\": u.bb[: nocc[1], : nocc[1]]} ca = {\"a\": u.aa[nocc[0] :, nocc[0] :], \"b\": u.bb[nocc[1] :, nocc[1] :]} # Transform T amplitudes: for name, key, n in self.cc.ansatz.fermionic_cluster_ranks(spin_type=self.spin_type): for comb in util.generate_spin_combinations(n, unique=True): args = [getattr(self.cc.amplitudes[name], comb), tuple(range(n * 2))] for i in range(n): args += [ci[comb[i]], (i, i + n * 2)] for i in range(n): args += [ca[comb[i + n]], (i + n, i + n * 3)] args += [tuple(range(n * 2, n * 4))] setattr(self.cc.amplitudes[name], comb, util.einsum(*args)) # Transform S amplitudes: for name, key, n in self.cc.ansatz.bosonic_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO # Transform U amplitudes: for name, key, nf, nb in self.cc.ansatz.coupling_cluster_ranks(spin_type=self.spin_type): raise util.ModelNotImplemented # TODO return self.cc.amplitudes","title":"transform_amplitudes"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.get_t1_norm","text":"Get the norm of the T1 amplitude. Parameters: amplitudes ( Optional [ Namespace [ SpinArrayType ]] , default: None ) \u2013 Cluster amplitudes. Returns: T \u2013 Norm of the T1 amplitude. Source code in ebcc/opt/ubrueckner.py def get_t1_norm(self, amplitudes: Optional[Namespace[SpinArrayType]] = None) -> T: \"\"\"Get the norm of the T1 amplitude. Args: amplitudes: Cluster amplitudes. Returns: Norm of the T1 amplitude. \"\"\" if not amplitudes: amplitudes = self.cc.amplitudes weight_a = np.linalg.norm(amplitudes[\"t1\"].aa) weight_b = np.linalg.norm(amplitudes[\"t1\"].bb) weight: T = (weight_a**2 + weight_b**2) ** 0.5 return weight","title":"get_t1_norm"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.mo_to_correlated","text":"Transform the MO coefficients into the correlated basis. Parameters: mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Correlated slice of MO coefficients. Source code in ebcc/opt/ubrueckner.py def mo_to_correlated( self, mo_coeff: tuple[NDArray[T], NDArray[T]] ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Transform the MO coefficients into the correlated basis. Args: mo_coeff: MO coefficients. Returns: Correlated slice of MO coefficients. \"\"\" return ( mo_coeff[0][:, self.cc.space[0].correlated], mo_coeff[1][:, self.cc.space[1].correlated], )","title":"mo_to_correlated"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.mo_update_correlated","text":"Update the correlated slice of a set of MO coefficients. Parameters: mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 MO coefficients. mo_coeff_corr ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 Correlated slice of MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Updated MO coefficients. Source code in ebcc/opt/ubrueckner.py def mo_update_correlated( self, mo_coeff: tuple[NDArray[T], NDArray[T]], mo_coeff_corr: tuple[NDArray[T], NDArray[T]], ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Update the correlated slice of a set of MO coefficients. Args: mo_coeff: MO coefficients. mo_coeff_corr: Correlated slice of MO coefficients. Returns: Updated MO coefficients. \"\"\" space = self.cc.space mo_coeff = ( _put( mo_coeff[0], np.ix_(np.arange(mo_coeff[0].shape[0]), space[0].correlated), # type: ignore mo_coeff_corr[0], ), _put( mo_coeff[1], np.ix_(np.arange(mo_coeff[1].shape[0]), space[1].correlated), # type: ignore mo_coeff_corr[1], ), ) return mo_coeff","title":"mo_update_correlated"},{"location":"reference/opt/ubrueckner/#ebcc.opt.ubrueckner.BruecknerUEBCC.update_coefficients","text":"Update the MO coefficients. Parameters: u_tot ( SpinArrayType ) \u2013 Total rotation matrix. mo_coeff ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 New MO coefficients. mo_coeff_ref ( tuple [ NDArray [ T ], NDArray [ T ]] ) \u2013 Reference MO coefficients. Returns: tuple [ NDArray [ T ], NDArray [ T ]] \u2013 Updated MO coefficients. Source code in ebcc/opt/ubrueckner.py def update_coefficients( self, u_tot: SpinArrayType, mo_coeff: tuple[NDArray[T], NDArray[T]], mo_coeff_ref: tuple[NDArray[T], NDArray[T]], ) -> tuple[NDArray[T], NDArray[T]]: \"\"\"Update the MO coefficients. Args: u_tot: Total rotation matrix. mo_coeff: New MO coefficients. mo_coeff_ref: Reference MO coefficients. Returns: Updated MO coefficients. \"\"\" mo_coeff_new_corr = ( util.einsum(\"pi,ij->pj\", mo_coeff_ref[0], u_tot.aa), util.einsum(\"pi,ij->pj\", mo_coeff_ref[1], u_tot.bb), ) mo_coeff_new = self.mo_update_correlated(mo_coeff, mo_coeff_new_corr) return mo_coeff_new","title":"update_coefficients"},{"location":"reference/util/","text":"Utilities.","title":"Index"},{"location":"reference/util/einsumfunc/","text":"Einstein summation convention. ebcc.util.einsumfunc.CONTRACTION_METHOD = 'backend' module-attribute The size of the contraction to fall back on the backend. ebcc.util.einsumfunc.BACKEND_EINSUM_SIZE = 1000 module-attribute The size of the contraction to let the backend optimize. ebcc.util.einsumfunc.BACKEND_OPTIMIZE_SIZE = 100 module-attribute Symbols used in einsum-like functions. ebcc.util.einsumfunc.EinsumOperandError Bases: ValueError Exception for invalid inputs to einsum . ebcc.util.einsumfunc.einsum(*operands, alpha=1.0, beta=0.0, out=None, contract=None, optimize=True) Evaluate an Einstein summation convention on the operands. Using the Einstein summation convention, many common multi-dimensional, linear algebraic array operations can be represented in a simple fashion. In implicit mode einsum computes these values. In explicit mode, einsum provides further flexibility to compute other array operations that might not be considered classical Einstein summation operations, by disabling, or forcing summation over specified subscript labels. See the numpy.einsum documentation for clarification. Parameters: operands ( OperandType [ T ] , default: () ) \u2013 Any valid input to numpy.einsum . alpha ( T , default: 1.0 ) \u2013 Scaling factor for the contraction. beta ( T , default: 0.0 ) \u2013 Scaling factor for the output. out ( Optional [ NDArray [ T ]] , default: None ) \u2013 If provided, the calculation is done into this array. contract ( Optional [ Callable [..., NDArray [ T ]]] , default: None ) \u2013 The function to use for contraction. optimize ( bool , default: True ) \u2013 If True , use the numpy.einsum_path to optimize the contraction. Returns: NDArray [ T ] \u2013 The calculation based on the Einstein summation convention. Source code in ebcc/util/einsumfunc.py def einsum( *operands: OperandType[T], alpha: T = 1.0, # type: ignore[assignment] beta: T = 0.0, # type: ignore[assignment] out: Optional[NDArray[T]] = None, contract: Optional[Callable[..., NDArray[T]]] = None, optimize: bool = True, ) -> NDArray[T]: \"\"\"Evaluate an Einstein summation convention on the operands. Using the Einstein summation convention, many common multi-dimensional, linear algebraic array operations can be represented in a simple fashion. In *implicit* mode `einsum` computes these values. In *explicit* mode, `einsum` provides further flexibility to compute other array operations that might not be considered classical Einstein summation operations, by disabling, or forcing summation over specified subscript labels. See the `numpy.einsum` documentation for clarification. Args: operands: Any valid input to `numpy.einsum`. alpha: Scaling factor for the contraction. beta: Scaling factor for the output. out: If provided, the calculation is done into this array. contract: The function to use for contraction. optimize: If `True`, use the `numpy.einsum_path` to optimize the contraction. Returns: The calculation based on the Einstein summation convention. \"\"\" # Parse the kwargs inp, outs, args = _parse_einsum_input(list(operands)) # type: ignore subscript = \"%s->%s\" % (inp, outs) # Get the contraction function if contract is None: contract = { \"backend\": _contract_backend, \"ttgt\": _contract_ttgt, \"tblis\": _contract_tblis, }[CONTRACTION_METHOD.lower()] # Perform the contraction if not len(args): raise ValueError(\"No input operands\") elif len(args) == 1: # If it's just a transpose, use numpy res = _transpose_backend(subscript, args[0], alpha=alpha, beta=beta, out=out) elif len(args) == 2: # If it's a single contraction, call the backend directly res = contract(subscript, args[0], args[1], alpha=alpha, beta=beta, out=out) else: # If it's a chain of contractions, use the path optimizer args = list(args) path_kwargs = dict(optimize=optimize, einsum_call=True) contractions = np.einsum_path(subscript, *args, **path_kwargs)[1] for contraction in contractions: inds, idx_rm, einsum_str, remain = list(contraction[:4]) contraction_args = [args.pop(x) for x in inds] # type: ignore if alpha != 1.0 or beta != 0.0: raise NotImplementedError(\"Scaling factors not supported for >2 arguments\") if len(contraction_args) == 1: a = contraction_args[0] res = _transpose_backend( einsum_str, a, alpha=types[float](1.0), beta=types[float](0.0), out=None ) elif len(contraction_args) == 2: a, b = contraction_args res = contract( einsum_str, a, b, alpha=types[float](1.0), beta=types[float](0.0), out=None ) else: res = np.einsum(einsum_str, *contraction_args, optimize=True) args.append(res) return res ebcc.util.einsumfunc.dirsum(*operands) Direct sum of arrays. Follows the numpy.einsum input conventions. Parameters: operands ( Union [ str , tuple [ int , ...], NDArray [ T ]] , default: () ) \u2013 Any valid input to numpy.einsum . Returns: NDArray [ T ] \u2013 The direct sum of the arrays. Source code in ebcc/util/einsumfunc.py def dirsum(*operands: Union[str, tuple[int, ...], NDArray[T]]) -> NDArray[T]: \"\"\"Direct sum of arrays. Follows the `numpy.einsum` input conventions. Args: operands: Any valid input to `numpy.einsum`. Returns: The direct sum of the arrays. \"\"\" # Parse the input input_str, output_str, input_arrays = _parse_einsum_input(list(operands)) input_chars = input_str.split(\",\") for i, (chars, array) in enumerate(zip(input_chars, input_arrays)): if len(chars) != array.ndim: raise ValueError(f\"Dimension mismatch for array {i}.\") if len(set(chars)) != len(chars): unique_chars = \"\".join(set(chars)) array = einsum(f\"{chars}->{unique_chars}\", array) input_chars[i] = unique_chars if i == 0: res = array else: shape = res.shape + (1,) * array.ndim res = np.reshape(res, shape) + array # Reshape the output res = einsum(f\"{''.join(input_chars)}->{output_str}\", res) return res","title":"Einstein summations"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.CONTRACTION_METHOD","text":"The size of the contraction to fall back on the backend.","title":"CONTRACTION_METHOD"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.BACKEND_EINSUM_SIZE","text":"The size of the contraction to let the backend optimize.","title":"BACKEND_EINSUM_SIZE"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.BACKEND_OPTIMIZE_SIZE","text":"Symbols used in einsum-like functions.","title":"BACKEND_OPTIMIZE_SIZE"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.EinsumOperandError","text":"Bases: ValueError Exception for invalid inputs to einsum .","title":"EinsumOperandError"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.einsum","text":"Evaluate an Einstein summation convention on the operands. Using the Einstein summation convention, many common multi-dimensional, linear algebraic array operations can be represented in a simple fashion. In implicit mode einsum computes these values. In explicit mode, einsum provides further flexibility to compute other array operations that might not be considered classical Einstein summation operations, by disabling, or forcing summation over specified subscript labels. See the numpy.einsum documentation for clarification. Parameters: operands ( OperandType [ T ] , default: () ) \u2013 Any valid input to numpy.einsum . alpha ( T , default: 1.0 ) \u2013 Scaling factor for the contraction. beta ( T , default: 0.0 ) \u2013 Scaling factor for the output. out ( Optional [ NDArray [ T ]] , default: None ) \u2013 If provided, the calculation is done into this array. contract ( Optional [ Callable [..., NDArray [ T ]]] , default: None ) \u2013 The function to use for contraction. optimize ( bool , default: True ) \u2013 If True , use the numpy.einsum_path to optimize the contraction. Returns: NDArray [ T ] \u2013 The calculation based on the Einstein summation convention. Source code in ebcc/util/einsumfunc.py def einsum( *operands: OperandType[T], alpha: T = 1.0, # type: ignore[assignment] beta: T = 0.0, # type: ignore[assignment] out: Optional[NDArray[T]] = None, contract: Optional[Callable[..., NDArray[T]]] = None, optimize: bool = True, ) -> NDArray[T]: \"\"\"Evaluate an Einstein summation convention on the operands. Using the Einstein summation convention, many common multi-dimensional, linear algebraic array operations can be represented in a simple fashion. In *implicit* mode `einsum` computes these values. In *explicit* mode, `einsum` provides further flexibility to compute other array operations that might not be considered classical Einstein summation operations, by disabling, or forcing summation over specified subscript labels. See the `numpy.einsum` documentation for clarification. Args: operands: Any valid input to `numpy.einsum`. alpha: Scaling factor for the contraction. beta: Scaling factor for the output. out: If provided, the calculation is done into this array. contract: The function to use for contraction. optimize: If `True`, use the `numpy.einsum_path` to optimize the contraction. Returns: The calculation based on the Einstein summation convention. \"\"\" # Parse the kwargs inp, outs, args = _parse_einsum_input(list(operands)) # type: ignore subscript = \"%s->%s\" % (inp, outs) # Get the contraction function if contract is None: contract = { \"backend\": _contract_backend, \"ttgt\": _contract_ttgt, \"tblis\": _contract_tblis, }[CONTRACTION_METHOD.lower()] # Perform the contraction if not len(args): raise ValueError(\"No input operands\") elif len(args) == 1: # If it's just a transpose, use numpy res = _transpose_backend(subscript, args[0], alpha=alpha, beta=beta, out=out) elif len(args) == 2: # If it's a single contraction, call the backend directly res = contract(subscript, args[0], args[1], alpha=alpha, beta=beta, out=out) else: # If it's a chain of contractions, use the path optimizer args = list(args) path_kwargs = dict(optimize=optimize, einsum_call=True) contractions = np.einsum_path(subscript, *args, **path_kwargs)[1] for contraction in contractions: inds, idx_rm, einsum_str, remain = list(contraction[:4]) contraction_args = [args.pop(x) for x in inds] # type: ignore if alpha != 1.0 or beta != 0.0: raise NotImplementedError(\"Scaling factors not supported for >2 arguments\") if len(contraction_args) == 1: a = contraction_args[0] res = _transpose_backend( einsum_str, a, alpha=types[float](1.0), beta=types[float](0.0), out=None ) elif len(contraction_args) == 2: a, b = contraction_args res = contract( einsum_str, a, b, alpha=types[float](1.0), beta=types[float](0.0), out=None ) else: res = np.einsum(einsum_str, *contraction_args, optimize=True) args.append(res) return res","title":"einsum"},{"location":"reference/util/einsumfunc/#ebcc.util.einsumfunc.dirsum","text":"Direct sum of arrays. Follows the numpy.einsum input conventions. Parameters: operands ( Union [ str , tuple [ int , ...], NDArray [ T ]] , default: () ) \u2013 Any valid input to numpy.einsum . Returns: NDArray [ T ] \u2013 The direct sum of the arrays. Source code in ebcc/util/einsumfunc.py def dirsum(*operands: Union[str, tuple[int, ...], NDArray[T]]) -> NDArray[T]: \"\"\"Direct sum of arrays. Follows the `numpy.einsum` input conventions. Args: operands: Any valid input to `numpy.einsum`. Returns: The direct sum of the arrays. \"\"\" # Parse the input input_str, output_str, input_arrays = _parse_einsum_input(list(operands)) input_chars = input_str.split(\",\") for i, (chars, array) in enumerate(zip(input_chars, input_arrays)): if len(chars) != array.ndim: raise ValueError(f\"Dimension mismatch for array {i}.\") if len(set(chars)) != len(chars): unique_chars = \"\".join(set(chars)) array = einsum(f\"{chars}->{unique_chars}\", array) input_chars[i] = unique_chars if i == 0: res = array else: shape = res.shape + (1,) * array.ndim res = np.reshape(res, shape) + array # Reshape the output res = einsum(f\"{''.join(input_chars)}->{output_str}\", res) return res","title":"dirsum"},{"location":"reference/util/misc/","text":"Miscellaneous utilities. ebcc.util.misc.Comparable Bases: Protocol Protocol for comparable objects. ebcc.util.misc.Comparable.__lt__(other) abstractmethod Check if the object is less than another. Source code in ebcc/util/misc.py @abstractmethod def __lt__(self, other: C) -> Any: \"\"\"Check if the object is less than another.\"\"\" pass ebcc.util.misc.InheritedType Type for an inherited variable. ebcc.util.misc.ModelNotImplemented Bases: NotImplementedError Error for unsupported models. ebcc.util.misc.Namespace(**kwargs) Bases: MutableMapping [ str , T ] , Generic [ T ] Namespace class. Replacement for SimpleNamespace, which does not trivially allow conversion to a dict for heterogenously nested objects. Attributes can be added and removed, using either string indexing or accessing the attribute directly. Initialise the namespace. Source code in ebcc/util/misc.py def __init__(self, **kwargs: T): \"\"\"Initialise the namespace.\"\"\" self.__dict__[\"_members\"] = {} for key, val in kwargs.items(): self.__dict__[\"_members\"][key] = val ebcc.util.misc.Namespace.__setitem__(key, val) Set an item. Source code in ebcc/util/misc.py def __setitem__(self, key: str, val: T) -> None: \"\"\"Set an item.\"\"\" self.__dict__[\"_members\"][key] = val ebcc.util.misc.Namespace.__setattr__(key, val) Set an attribute. Source code in ebcc/util/misc.py def __setattr__(self, key: str, val: T) -> None: \"\"\"Set an attribute.\"\"\" return self.__setitem__(key, val) ebcc.util.misc.Namespace.__getitem__(key) Get an item. Source code in ebcc/util/misc.py def __getitem__(self, key: str) -> T: \"\"\"Get an item.\"\"\" value: T = self.__dict__[\"_members\"][key] return value ebcc.util.misc.Namespace.__getattr__(key) Get an attribute. Source code in ebcc/util/misc.py def __getattr__(self, key: str) -> T: \"\"\"Get an attribute.\"\"\" if key in self.__dict__: return self.__dict__[key] # type: ignore[no-any-return] try: return self.__getitem__(key) except KeyError: raise AttributeError(f\"Namespace object has no attribute {key}\") ebcc.util.misc.Namespace.__delitem__(key) Delete an item. Source code in ebcc/util/misc.py def __delitem__(self, key: str) -> None: \"\"\"Delete an item.\"\"\" self._members.pop(key) ebcc.util.misc.Namespace.__delattr__(key) Delete an attribute. Source code in ebcc/util/misc.py def __delattr__(self, key: str) -> None: \"\"\"Delete an attribute.\"\"\" return self.__delitem__(key) ebcc.util.misc.Namespace.__iter__() Iterate over the namespace as a dictionary. Source code in ebcc/util/misc.py def __iter__(self) -> Iterator[str]: \"\"\"Iterate over the namespace as a dictionary.\"\"\" yield from self._members ebcc.util.misc.Namespace.__eq__(other) Check equality. Source code in ebcc/util/misc.py def __eq__(self, other: Any) -> bool: \"\"\"Check equality.\"\"\" if not isinstance(other, Namespace): return False return dict(self) == dict(other) ebcc.util.misc.Namespace.__ne__(other) Check inequality. Source code in ebcc/util/misc.py def __ne__(self, other: Any) -> bool: \"\"\"Check inequality.\"\"\" return not self == other ebcc.util.misc.Namespace.__contains__(key) Check if an attribute exists. Source code in ebcc/util/misc.py def __contains__(self, key: Any) -> bool: \"\"\"Check if an attribute exists.\"\"\" return key in self._members ebcc.util.misc.Namespace.__len__() Get the number of attributes. Source code in ebcc/util/misc.py def __len__(self) -> int: \"\"\"Get the number of attributes.\"\"\" return len(self._members) ebcc.util.misc.Namespace.keys() Get keys of the namespace as a dictionary. Source code in ebcc/util/misc.py def keys(self) -> KeysView[str]: \"\"\"Get keys of the namespace as a dictionary.\"\"\" return self._members.keys() ebcc.util.misc.Namespace.values() Get values of the namespace as a dictionary. Source code in ebcc/util/misc.py def values(self) -> ValuesView[T]: \"\"\"Get values of the namespace as a dictionary.\"\"\" return self._members.values() ebcc.util.misc.Namespace.items() Get items of the namespace as a dictionary. Source code in ebcc/util/misc.py def items(self) -> ItemsView[str, T]: \"\"\"Get items of the namespace as a dictionary.\"\"\" return self._members.items() ebcc.util.misc.Namespace.copy() Return a shallow copy. Source code in ebcc/util/misc.py def copy(self) -> Namespace[T]: \"\"\"Return a shallow copy.\"\"\" return Namespace(**self._members) ebcc.util.misc.Namespace.__repr__() Return a string representation. Source code in ebcc/util/misc.py def __repr__(self) -> str: \"\"\"Return a string representation.\"\"\" return f\"Namespace({self._members})\" ebcc.util.misc.Timer() Timer class. Initialise the timer. Source code in ebcc/util/misc.py def __init__(self) -> None: \"\"\"Initialise the timer.\"\"\" self.t_init = time.perf_counter() self.t_prev = time.perf_counter() self.t_curr = time.perf_counter() ebcc.util.misc.Timer.lap() Return the time since the last call to lap . Source code in ebcc/util/misc.py def lap(self) -> float: \"\"\"Return the time since the last call to `lap`.\"\"\" self.t_prev, self.t_curr = self.t_curr, time.perf_counter() return self.t_curr - self.t_prev ebcc.util.misc.Timer.total() Return the total time since initialization. Source code in ebcc/util/misc.py def total(self) -> float: \"\"\"Return the total time since initialization.\"\"\" return time.perf_counter() - self.t_init ebcc.util.misc.Timer.format_time(seconds, precision=2) staticmethod Return a formatted time. Source code in ebcc/util/misc.py @staticmethod def format_time(seconds: float, precision: int = 2) -> str: \"\"\"Return a formatted time.\"\"\" seconds, milliseconds = divmod(seconds, 1) milliseconds *= 1000 minutes, seconds = divmod(seconds, 60) hours, minutes = divmod(minutes, 60) out = [] if hours: out.append(\"%d h\" % hours) if minutes: out.append(\"%d m\" % minutes) if seconds: out.append(\"%d s\" % seconds) if milliseconds: out.append(\"%d ms\" % milliseconds) return \" \".join(out[-max(precision, len(out)) :]) ebcc.util.misc.prod(values) Return the product of values. Source code in ebcc/util/misc.py def prod(values: Union[list[int], tuple[int, ...]]) -> int: \"\"\"Return the product of values.\"\"\" out = 1 for value in values: out *= value return out ebcc.util.misc.argsort(values) Return the indices that would sort the values. Parameters: values ( Union [ list [ Union [ float , str ]], NDArray [ generic ]] ) \u2013 The values to sort. Returns: list [ int ] \u2013 The indices that would sort the values. Source code in ebcc/util/misc.py def argsort(values: Union[list[Union[float, str]], NDArray[generic]]) -> list[int]: \"\"\"Return the indices that would sort the values. Args: values: The values to sort. Returns: The indices that would sort the values. \"\"\" if isinstance(values, Sized): size = len(values) else: size = values.size return sorted(range(size), key=values.__getitem__) ebcc.util.misc.regularise_tuple(*_items) Regularise the input tuples. Allows input of the forms - func((a, b, c)) - func([a, b, c]) - func(a, b, c) - func(a) Parameters: _items ( Union [ Any , tuple [ Any , ...], list [ Any ]] , default: () ) \u2013 The input tuples. Returns: tuple [ Any , ...] \u2013 The regularised tuple. Source code in ebcc/util/misc.py def regularise_tuple(*_items: Union[Any, tuple[Any, ...], list[Any]]) -> tuple[Any, ...]: \"\"\"Regularise the input tuples. Allows input of the forms - `func((a, b, c))` - `func([a, b, c])` - `func(a, b, c)` - `func(a)` Args: _items: The input tuples. Returns: The regularised tuple. \"\"\" if isinstance(_items[0], (tuple, list)): if len(_items) > 1: raise ValueError(\"Only one tuple can be passed.\") items = _items[0] else: items = _items return tuple(items)","title":"Miscellaneous"},{"location":"reference/util/misc/#ebcc.util.misc.Comparable","text":"Bases: Protocol Protocol for comparable objects.","title":"Comparable"},{"location":"reference/util/misc/#ebcc.util.misc.Comparable.__lt__","text":"Check if the object is less than another. Source code in ebcc/util/misc.py @abstractmethod def __lt__(self, other: C) -> Any: \"\"\"Check if the object is less than another.\"\"\" pass","title":"__lt__"},{"location":"reference/util/misc/#ebcc.util.misc.InheritedType","text":"Type for an inherited variable.","title":"InheritedType"},{"location":"reference/util/misc/#ebcc.util.misc.ModelNotImplemented","text":"Bases: NotImplementedError Error for unsupported models.","title":"ModelNotImplemented"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace","text":"Bases: MutableMapping [ str , T ] , Generic [ T ] Namespace class. Replacement for SimpleNamespace, which does not trivially allow conversion to a dict for heterogenously nested objects. Attributes can be added and removed, using either string indexing or accessing the attribute directly. Initialise the namespace. Source code in ebcc/util/misc.py def __init__(self, **kwargs: T): \"\"\"Initialise the namespace.\"\"\" self.__dict__[\"_members\"] = {} for key, val in kwargs.items(): self.__dict__[\"_members\"][key] = val","title":"Namespace"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__setitem__","text":"Set an item. Source code in ebcc/util/misc.py def __setitem__(self, key: str, val: T) -> None: \"\"\"Set an item.\"\"\" self.__dict__[\"_members\"][key] = val","title":"__setitem__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__setattr__","text":"Set an attribute. Source code in ebcc/util/misc.py def __setattr__(self, key: str, val: T) -> None: \"\"\"Set an attribute.\"\"\" return self.__setitem__(key, val)","title":"__setattr__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__getitem__","text":"Get an item. Source code in ebcc/util/misc.py def __getitem__(self, key: str) -> T: \"\"\"Get an item.\"\"\" value: T = self.__dict__[\"_members\"][key] return value","title":"__getitem__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__getattr__","text":"Get an attribute. Source code in ebcc/util/misc.py def __getattr__(self, key: str) -> T: \"\"\"Get an attribute.\"\"\" if key in self.__dict__: return self.__dict__[key] # type: ignore[no-any-return] try: return self.__getitem__(key) except KeyError: raise AttributeError(f\"Namespace object has no attribute {key}\")","title":"__getattr__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__delitem__","text":"Delete an item. Source code in ebcc/util/misc.py def __delitem__(self, key: str) -> None: \"\"\"Delete an item.\"\"\" self._members.pop(key)","title":"__delitem__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__delattr__","text":"Delete an attribute. Source code in ebcc/util/misc.py def __delattr__(self, key: str) -> None: \"\"\"Delete an attribute.\"\"\" return self.__delitem__(key)","title":"__delattr__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__iter__","text":"Iterate over the namespace as a dictionary. Source code in ebcc/util/misc.py def __iter__(self) -> Iterator[str]: \"\"\"Iterate over the namespace as a dictionary.\"\"\" yield from self._members","title":"__iter__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__eq__","text":"Check equality. Source code in ebcc/util/misc.py def __eq__(self, other: Any) -> bool: \"\"\"Check equality.\"\"\" if not isinstance(other, Namespace): return False return dict(self) == dict(other)","title":"__eq__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__ne__","text":"Check inequality. Source code in ebcc/util/misc.py def __ne__(self, other: Any) -> bool: \"\"\"Check inequality.\"\"\" return not self == other","title":"__ne__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__contains__","text":"Check if an attribute exists. Source code in ebcc/util/misc.py def __contains__(self, key: Any) -> bool: \"\"\"Check if an attribute exists.\"\"\" return key in self._members","title":"__contains__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__len__","text":"Get the number of attributes. Source code in ebcc/util/misc.py def __len__(self) -> int: \"\"\"Get the number of attributes.\"\"\" return len(self._members)","title":"__len__"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.keys","text":"Get keys of the namespace as a dictionary. Source code in ebcc/util/misc.py def keys(self) -> KeysView[str]: \"\"\"Get keys of the namespace as a dictionary.\"\"\" return self._members.keys()","title":"keys"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.values","text":"Get values of the namespace as a dictionary. Source code in ebcc/util/misc.py def values(self) -> ValuesView[T]: \"\"\"Get values of the namespace as a dictionary.\"\"\" return self._members.values()","title":"values"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.items","text":"Get items of the namespace as a dictionary. Source code in ebcc/util/misc.py def items(self) -> ItemsView[str, T]: \"\"\"Get items of the namespace as a dictionary.\"\"\" return self._members.items()","title":"items"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.copy","text":"Return a shallow copy. Source code in ebcc/util/misc.py def copy(self) -> Namespace[T]: \"\"\"Return a shallow copy.\"\"\" return Namespace(**self._members)","title":"copy"},{"location":"reference/util/misc/#ebcc.util.misc.Namespace.__repr__","text":"Return a string representation. Source code in ebcc/util/misc.py def __repr__(self) -> str: \"\"\"Return a string representation.\"\"\" return f\"Namespace({self._members})\"","title":"__repr__"},{"location":"reference/util/misc/#ebcc.util.misc.Timer","text":"Timer class. Initialise the timer. Source code in ebcc/util/misc.py def __init__(self) -> None: \"\"\"Initialise the timer.\"\"\" self.t_init = time.perf_counter() self.t_prev = time.perf_counter() self.t_curr = time.perf_counter()","title":"Timer"},{"location":"reference/util/misc/#ebcc.util.misc.Timer.lap","text":"Return the time since the last call to lap . Source code in ebcc/util/misc.py def lap(self) -> float: \"\"\"Return the time since the last call to `lap`.\"\"\" self.t_prev, self.t_curr = self.t_curr, time.perf_counter() return self.t_curr - self.t_prev","title":"lap"},{"location":"reference/util/misc/#ebcc.util.misc.Timer.total","text":"Return the total time since initialization. Source code in ebcc/util/misc.py def total(self) -> float: \"\"\"Return the total time since initialization.\"\"\" return time.perf_counter() - self.t_init","title":"total"},{"location":"reference/util/misc/#ebcc.util.misc.Timer.format_time","text":"Return a formatted time. Source code in ebcc/util/misc.py @staticmethod def format_time(seconds: float, precision: int = 2) -> str: \"\"\"Return a formatted time.\"\"\" seconds, milliseconds = divmod(seconds, 1) milliseconds *= 1000 minutes, seconds = divmod(seconds, 60) hours, minutes = divmod(minutes, 60) out = [] if hours: out.append(\"%d h\" % hours) if minutes: out.append(\"%d m\" % minutes) if seconds: out.append(\"%d s\" % seconds) if milliseconds: out.append(\"%d ms\" % milliseconds) return \" \".join(out[-max(precision, len(out)) :])","title":"format_time"},{"location":"reference/util/misc/#ebcc.util.misc.prod","text":"Return the product of values. Source code in ebcc/util/misc.py def prod(values: Union[list[int], tuple[int, ...]]) -> int: \"\"\"Return the product of values.\"\"\" out = 1 for value in values: out *= value return out","title":"prod"},{"location":"reference/util/misc/#ebcc.util.misc.argsort","text":"Return the indices that would sort the values. Parameters: values ( Union [ list [ Union [ float , str ]], NDArray [ generic ]] ) \u2013 The values to sort. Returns: list [ int ] \u2013 The indices that would sort the values. Source code in ebcc/util/misc.py def argsort(values: Union[list[Union[float, str]], NDArray[generic]]) -> list[int]: \"\"\"Return the indices that would sort the values. Args: values: The values to sort. Returns: The indices that would sort the values. \"\"\" if isinstance(values, Sized): size = len(values) else: size = values.size return sorted(range(size), key=values.__getitem__)","title":"argsort"},{"location":"reference/util/misc/#ebcc.util.misc.regularise_tuple","text":"Regularise the input tuples. Allows input of the forms - func((a, b, c)) - func([a, b, c]) - func(a, b, c) - func(a) Parameters: _items ( Union [ Any , tuple [ Any , ...], list [ Any ]] , default: () ) \u2013 The input tuples. Returns: tuple [ Any , ...] \u2013 The regularised tuple. Source code in ebcc/util/misc.py def regularise_tuple(*_items: Union[Any, tuple[Any, ...], list[Any]]) -> tuple[Any, ...]: \"\"\"Regularise the input tuples. Allows input of the forms - `func((a, b, c))` - `func([a, b, c])` - `func(a, b, c)` - `func(a)` Args: _items: The input tuples. Returns: The regularised tuple. \"\"\" if isinstance(_items[0], (tuple, list)): if len(_items) > 1: raise ValueError(\"Only one tuple can be passed.\") items = _items[0] else: items = _items return tuple(items)","title":"regularise_tuple"},{"location":"reference/util/permutations/","text":"Symmetry and permutational utilities. ebcc.util.permutations.factorial(n) Return the factorial of n . Source code in ebcc/util/permutations.py def factorial(n: int) -> int: \"\"\"Return the factorial of `n`.\"\"\" if n in (0, 1): return 1 else: return n * factorial(n - 1) ebcc.util.permutations.permute_string(string, permutation) Permute a string. Parameters: string ( str ) \u2013 String to permute. permutation ( tuple [ int , ...] ) \u2013 Permutation to apply. Returns: str \u2013 Permuted string. Examples: >>> permute_string(\"abcd\", (2, 0, 3, 1)) \"cbda\" Source code in ebcc/util/permutations.py def permute_string(string: str, permutation: tuple[int, ...]) -> str: \"\"\"Permute a string. Args: string: String to permute. permutation: Permutation to apply. Returns: Permuted string. Examples: >>> permute_string(\"abcd\", (2, 0, 3, 1)) \"cbda\" \"\"\" return \"\".join([string[i] for i in permutation]) ebcc.util.permutations.get_string_permutation(string, target) Get the permutation to transform one string into another. Parameters: string ( str ) \u2013 Initial string. target ( str ) \u2013 Target string. Returns: tuple [ int , ...] \u2013 Permutation to transform string into target . Examples: >>> get_string_permutation(\"abcd\", \"cbda\") (2, 0, 3, 1) >>> get_string_permutation(\"iijj\", \"jjii\") (2, 3, 0, 1) Source code in ebcc/util/permutations.py def get_string_permutation(string: str, target: str) -> tuple[int, ...]: \"\"\"Get the permutation to transform one string into another. Args: string: Initial string. target: Target string. Returns: Permutation to transform `string` into `target`. Examples: >>> get_string_permutation(\"abcd\", \"cbda\") (2, 0, 3, 1) >>> get_string_permutation(\"iijj\", \"jjii\") (2, 3, 0, 1) \"\"\" # Find the indices of each character in the string indices: dict[str, list[int]] = {char: [] for char in set(string)} for i, char in enumerate(string): indices[char].append(i) # Get the permutation perm: list[int] = [] for char in target: perm.append(indices[char].pop(0)) return tuple(perm) ebcc.util.permutations.tril_indices_ndim(n, dims, include_diagonal=False) Return lower triangular indices for a multidimensional array. Parameters: n ( int ) \u2013 Size of each dimension. dims ( int ) \u2013 Number of dimensions. include_diagonal ( Optional [ bool ] , default: False ) \u2013 If True, include diagonal elements. Returns: tuple [ NDArray [ integer ], ...] \u2013 Lower triangular indices for each dimension. Source code in ebcc/util/permutations.py def tril_indices_ndim( n: int, dims: int, include_diagonal: Optional[bool] = False ) -> tuple[NDArray[integer], ...]: \"\"\"Return lower triangular indices for a multidimensional array. Args: n: Size of each dimension. dims: Number of dimensions. include_diagonal: If True, include diagonal elements. Returns: Lower triangular indices for each dimension. \"\"\" ranges = [np.arange(n)] * dims if dims == 1: return (ranges[0],) # func: Callable[[Any, ...], Any] = np.greater_equal if include_diagonal else np.greater slices = [tuple(slice(None) if i == j else None for i in range(dims)) for j in range(dims)] casted = [rng[ind] for rng, ind in zip(ranges, slices)] if include_diagonal: mask = functools.reduce( lambda x, y: x & y, map(lambda x, y: x >= y, casted[:-1], casted[1:]) ) else: mask = functools.reduce( lambda x, y: x & y, map(lambda x, y: x > y, casted[:-1], casted[1:]) ) tril = tuple( np.broadcast_to(inds, mask.shape)[mask] for inds in np.indices(mask.shape, sparse=True) ) return tril ebcc.util.permutations.ntril_ndim(n, dims, include_diagonal=False) Return len(tril_indices_ndim(n, dims, include_diagonal)) . Source code in ebcc/util/permutations.py def ntril_ndim(n: int, dims: int, include_diagonal: Optional[bool] = False) -> int: \"\"\"Return `len(tril_indices_ndim(n, dims, include_diagonal))`.\"\"\" # FIXME hack until this function is fixed: if include_diagonal: return sum(1 for tup in itertools.combinations_with_replacement(range(n), dims)) else: return sum(1 for tup in itertools.combinations(range(n), dims)) offset = int(include_diagonal) out = 1 for i in range(dims): out *= n + offset offset -= 1 out //= factorial(dims) return out ebcc.util.permutations.generate_spin_combinations(n, excited=False, unique=False) Generate combinations of spin components for a given number of occupied and virtual axes. Parameters: n ( int ) \u2013 Order of cluster amplitude. excited ( Optional [ bool ] , default: False ) \u2013 If True, treat the amplitudes as excited. unique ( Optional [ bool ] , default: False ) \u2013 If True, return only unique combinations. Returns: None \u2013 List of spin combinations. Examples: >>> generate_spin_combinations(1) ['aa', 'bb'] >>> generate_spin_combinations(2) ['aaaa', 'abab', 'baba', 'bbbb'] >>> generate_spin_combinations(2, excited=True) ['aaa', 'aba', 'bab', 'bbb'] >>> generate_spin_combinations(2, unique=True) ['aaaa', 'abab', 'bbbb'] Source code in ebcc/util/permutations.py def generate_spin_combinations( n: int, excited: Optional[bool] = False, unique: Optional[bool] = False ) -> Generator[str, None, None]: \"\"\"Generate combinations of spin components for a given number of occupied and virtual axes. Args: n: Order of cluster amplitude. excited: If True, treat the amplitudes as excited. unique: If True, return only unique combinations. Returns: List of spin combinations. Examples: >>> generate_spin_combinations(1) ['aa', 'bb'] >>> generate_spin_combinations(2) ['aaaa', 'abab', 'baba', 'bbbb'] >>> generate_spin_combinations(2, excited=True) ['aaa', 'aba', 'bab', 'bbb'] >>> generate_spin_combinations(2, unique=True) ['aaaa', 'abab', 'bbbb'] \"\"\" if unique: check = set() for tup in itertools.product((\"a\", \"b\"), repeat=n): comb = \"\".join(list(tup) * 2) if excited: comb = comb[:-1] if unique: sorted_comb = \"\".join(sorted(comb[:n])) + \"\".join(sorted(comb[n:])) if sorted_comb in check: continue check.add(sorted_comb) if not excited: # FIXME nab = (comb[:n].count(\"a\"), comb[:n].count(\"b\")) if nab == (n // 2, n - n // 2): comb = (\"ab\" * n)[:n] * 2 elif nab == (n - n // 2, n // 2): comb = (\"ba\" * n)[:n] * 2 yield comb ebcc.util.permutations.permutations_with_signs(seq) Return permutations of a sequence with a sign indicating the number of swaps. The sign is equal to +1 for an even number of swaps, and -1 for an odd number of swaps. Parameters: seq ( Iterable [ Any ] ) \u2013 Sequence to permute. Returns: list [ tuple [ Any , int ]] \u2013 List of tuples of the form (permuted, sign). Source code in ebcc/util/permutations.py def permutations_with_signs(seq: Iterable[Any]) -> list[tuple[Any, int]]: \"\"\"Return permutations of a sequence with a sign indicating the number of swaps. The sign is equal to +1 for an even number of swaps, and -1 for an odd number of swaps. Args: seq: Sequence to permute. Returns: List of tuples of the form (permuted, sign). \"\"\" def _permutations(seq: list[Any]) -> list[list[Any]]: if not seq: return [[]] items = [] for i, item in enumerate(_permutations(seq[:-1])): if i % 2 == 1: inds = range(len(item) + 1) else: inds = range(len(item), -1, -1) items += [item[:i] + seq[-1:] + item[i:] for i in inds] return items return [(item, -1 if i % 2 else 1) for i, item in enumerate(_permutations(list(seq)))] ebcc.util.permutations.get_symmetry_factor(*numbers) Get a value corresponding to the factor from the neglection of symmetry in repeated indices. Parameters: numbers ( int , default: () ) \u2013 Multiplicity of each distinct degree of freedom. Returns: float \u2013 Symmetry factor. Examples: >>> get_symmetry_factor(1, 1) 1.0 >>> get_symmetry_factor(2, 2) 0.25 >>> get_symmetry_factor(3, 2, 1) 0.125 Source code in ebcc/util/permutations.py def get_symmetry_factor(*numbers: int) -> float: \"\"\"Get a value corresponding to the factor from the neglection of symmetry in repeated indices. Args: numbers: Multiplicity of each distinct degree of freedom. Returns: Symmetry factor. Examples: >>> get_symmetry_factor(1, 1) 1.0 >>> get_symmetry_factor(2, 2) 0.25 >>> get_symmetry_factor(3, 2, 1) 0.125 \"\"\" ntot = 0 for n in numbers: ntot += max(0, n - 1) return 1.0 / (2.0**ntot) ebcc.util.permutations.symmetry_factor(subscript) Get the symmetry factor for a given subscript. Parameters: subscript ( str ) \u2013 Subscript to get the symmetry factor for. Returns: float \u2013 Symmetry factor. Source code in ebcc/util/permutations.py def symmetry_factor(subscript: str) -> float: \"\"\"Get the symmetry factor for a given subscript. Args: subscript: Subscript to get the symmetry factor for. Returns: Symmetry factor. \"\"\" counts = {char: subscript.count(char) for char in set(subscript)} return get_symmetry_factor(*counts.values()) ebcc.util.permutations.antisymmetrise_array(v, axes=None) Antisymmetrise an array. Parameters: v ( NDArray [ T ] ) \u2013 Array to antisymmetrise. axes ( Optional [ tuple [ int , ...]] , default: None ) \u2013 Axes to antisymmetrise over. Returns: NDArray [ T ] \u2013 Antisymmetrised array. Source code in ebcc/util/permutations.py def antisymmetrise_array(v: NDArray[T], axes: Optional[tuple[int, ...]] = None) -> NDArray[T]: \"\"\"Antisymmetrise an array. Args: v: Array to antisymmetrise. axes: Axes to antisymmetrise over. Returns: Antisymmetrised array. \"\"\" if axes is None: axes = tuple(range(v.ndim)) v_as = np.zeros(v.shape, dtype=v.dtype) for perm, sign in permutations_with_signs(axes): transpose = list(range(v.ndim)) for i, ax in enumerate(transpose): if ax in axes: j = axes.index(ax) transpose[i] = perm[j] v_as += np.copy(np.transpose(v, transpose)) * sign return v_as ebcc.util.permutations.is_mixed_spin(spin) Return a boolean indicating if a list of spins is mixed. Source code in ebcc/util/permutations.py def is_mixed_spin(spin: Iterable[Hashable]) -> bool: \"\"\"Return a boolean indicating if a list of spins is mixed.\"\"\" return len(set(spin)) != 1 ebcc.util.permutations.combine_subscripts(*subscripts, sizes=None) Combine subscripts into new unique subscripts for functions such as compress_axes . For example, one may wish to compress an amplitude according to both occupancy and spin signatures. The output string of this function has the same length as the input subscripts, where the i th character is an arbitrary character chosen such that it is unique for a unique value of tuple(s[i] for s in subscripts) among other values of i . This function also returns a dictionary indicating the size of each new character in the subscript according to the size of the corresponding original character in the dictionary sizes . Parameters: subscripts ( str , default: () ) \u2013 Subscripts to combine. sizes ( Optional [ dict [ tuple [ str , ...], int ]] , default: None ) \u2013 Dictionary of sizes for each index. Returns: tuple [ str , dict [ str , int ]] \u2013 New subscript, with a dictionary of sizes of each new index. Source code in ebcc/util/permutations.py def combine_subscripts( *subscripts: str, sizes: Optional[dict[tuple[str, ...], int]] = None, ) -> tuple[str, dict[str, int]]: \"\"\"Combine subscripts into new unique subscripts for functions such as `compress_axes`. For example, one may wish to compress an amplitude according to both occupancy and spin signatures. The output string of this function has the same length as the input subscripts, where the `i`th character is an arbitrary character chosen such that it is unique for a unique value of `tuple(s[i] for s in subscripts)` among other values of `i`. This function also returns a dictionary indicating the size of each new character in the subscript according to the size of the corresponding original character in the dictionary `sizes`. Args: subscripts: Subscripts to combine. sizes: Dictionary of sizes for each index. Returns: New subscript, with a dictionary of sizes of each new index. \"\"\" if len(set(len(s) for s in subscripts)) != 1: raise ValueError(\"Subscripts must be of the same length.\") char_map: dict[tuple[str, ...], str] = {} new_subscript = \"\" new_sizes: dict[str, int] = {} j = 0 for i in range(len(subscripts[0])): key = tuple(s[i] for s in subscripts) if key not in char_map: if j == 91: raise ValueError(\"Too many unique characters.\") char_map[key] = chr(97 + j) j += 1 if j == 123: j = 65 new_subscript += char_map[key] if sizes: new_sizes[char_map[key]] = sizes[key] return new_subscript, new_sizes ebcc.util.permutations.compress_axes(subscript, array, include_diagonal=False) Compress an array into lower-triangular representations using an einsum-like input. Parameters: subscript ( str ) \u2013 Subscript for the input array. array ( NDArray [ T ] ) \u2013 Array to compress. include_diagonal ( Optional [ bool ] , default: False ) \u2013 Whether to include the diagonal elements of the input array in the output array. Returns: NDArray [ T ] \u2013 Compressed array. Examples: >>> t2 = np.zeros((4, 4, 10, 10)) >>> compress_axes(\"iiaa\", t2).shape (6, 45) Source code in ebcc/util/permutations.py def compress_axes( subscript: str, array: NDArray[T], include_diagonal: Optional[bool] = False ) -> NDArray[T]: \"\"\"Compress an array into lower-triangular representations using an einsum-like input. Args: subscript: Subscript for the input array. array: Array to compress. include_diagonal: Whether to include the diagonal elements of the input array in the output array. Returns: Compressed array. Examples: >>> t2 = np.zeros((4, 4, 10, 10)) >>> compress_axes(\"iiaa\", t2).shape (6, 45) \"\"\" # TODO out # TODO can this be OpenMP parallel? assert \"->\" not in subscript # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Reshape array so that all axes of the same character are adjacent: arg = tuple(util.argsort(list(subscript))) array = np.transpose(array, arg) subscript = permute_string(subscript, arg) # Reshape array so that all axes of the same character are flattened: sizes: dict[str, int] = {} for char, n in zip(subscript, array.shape): if char in sizes: assert sizes[char] == n else: sizes[char] = n array = np.reshape( array, [sizes[char] ** subscript.count(char) for char in sorted(set(subscript))] ) # For each axis type, get the necessary lower-triangular indices: indices_ndim = [ tril_indices_ndim(sizes[char], subscript.count(char), include_diagonal=include_diagonal) for char in sorted(set(subscript)) ] indices = [ np.ravel_multi_index(ind, (sizes[char],) * subscript.count(char)) for ind, char in zip(indices_ndim, sorted(set(subscript))) ] # Apply the indices: indices = [ ind[tuple(None if i != j else slice(None) for i in range(len(indices)))] for j, ind in enumerate(indices) ] array_flat: NDArray[T] = array[tuple(indices)] return array_flat ebcc.util.permutations.decompress_axes(subscript, array_flat, shape=None, include_diagonal=False, symmetry=None, out=None) Reverse operation of compress_axes , subscript input is the same. One of shape or out must be passed. Parameters: subscript ( str ) \u2013 Subscript for the output array. array_flat ( NDArray [ T ] ) \u2013 Array to decompress. shape ( Optional [ tuple [ int , ...]] , default: None ) \u2013 Shape of the output array. Must be passed if out is None . include_diagonal ( Optional [ bool ] , default: False ) \u2013 Whether to include the diagonal elements of the output array in the input array. symmetry ( Optional [ str ] , default: None ) \u2013 Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. out ( Optional [ NDArray [ T ]] , default: None ) \u2013 Output array. If None , a new array is created, and shape must be passed. Returns: NDArray [ T ] \u2013 Decompressed array. Source code in ebcc/util/permutations.py def decompress_axes( subscript: str, array_flat: NDArray[T], shape: Optional[tuple[int, ...]] = None, include_diagonal: Optional[bool] = False, symmetry: Optional[str] = None, out: Optional[NDArray[T]] = None, ) -> NDArray[T]: \"\"\"Reverse operation of `compress_axes`, subscript input is the same. One of `shape` or `out` must be passed. Args: subscript: Subscript for the output array. array_flat: Array to decompress. shape: Shape of the output array. Must be passed if `out` is `None`. include_diagonal: Whether to include the diagonal elements of the output array in the input array. symmetry: Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. out: Output array. If `None`, a new array is created, and `shape` must be passed. Returns: Decompressed array. \"\"\" assert \"->\" not in subscript assert shape is not None or out is not None # Get symmetry string if needed: if symmetry is None: symmetry = \"-\" * len(subscript) # Initialise decompressed array if out is None: if shape is None: raise ValueError(\"One of `shape` or `out` must be passed.\") array = np.zeros(shape, dtype=array_flat.dtype) else: array = out out[:] = 0.0 # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Reshape array so that all axes of the same character are adjacent: arg = tuple(util.argsort(list(subscript))) array = np.transpose(array, arg) subscript = permute_string(subscript, arg) # Reshape array so that all axes of the same character are flattened: sizes: dict[str, int] = {} for char, n in zip(subscript, array.shape): if char in sizes: assert sizes[char] == n else: sizes[char] = n array = np.reshape( array, [sizes[char] ** subscript.count(char) for char in sorted(set(subscript))] ) # Check the symmetry string, and compress it: n = 0 symmetry_compressed = \"\" for char in sorted(set(subscript)): assert len(set(symmetry[n : n + subscript.count(char)])) == 1 symmetry_compressed += symmetry[n] n += subscript.count(char) # For each axis type, get the necessary lower-triangular indices: indices = [ tril_indices_ndim(sizes[char], subscript.count(char), include_diagonal=include_diagonal) for char in sorted(set(subscript)) ] # Iterate over permutations with signs: for tup in itertools.product(*[permutations_with_signs(ind) for ind in indices]): indices_perm, signs = zip(*tup) signs = tuple(s if symm == \"-\" else 1 for s, symm in zip(signs, symmetry_compressed)) # Apply the indices: indices_perm = tuple( np.ravel_multi_index(ind, (sizes[char],) * subscript.count(char)) for ind, char in zip(indices_perm, sorted(set(subscript))) ) indices_perm = tuple( ind[tuple(None if i != j else slice(None) for i in range(len(indices_perm)))] for j, ind in enumerate(indices_perm) ) array = _put(array, indices_perm, array_flat * util.prod(signs)) # Reshape array to non-flattened format array = np.reshape( array, (sum([(sizes[char],) * subscript.count(char) for char in sorted(set(subscript))], tuple())), ) # Undo transpose: arg = tuple(util.argsort(list(arg))) array = np.transpose(array, arg) return array ebcc.util.permutations.get_compressed_size(subscript, **sizes) Get the size of a compressed representation of a matrix based on the subscript input. Parameters: subscript ( str ) \u2013 Subscript for the output array. See compressed_axes for details. **sizes ( int , default: {} ) \u2013 Sizes of each character in the subscript. Returns: int \u2013 Size of the compressed representation of the array. Examples: >>> get_compressed_size(\"iiaa\", i=5, a=3) 30 Source code in ebcc/util/permutations.py def get_compressed_size(subscript: str, **sizes: int) -> int: \"\"\"Get the size of a compressed representation of a matrix based on the subscript input. Args: subscript: Subscript for the output array. See `compressed_axes` for details. **sizes: Sizes of each character in the subscript. Returns: Size of the compressed representation of the array. Examples: >>> get_compressed_size(\"iiaa\", i=5, a=3) 30 \"\"\" n = 1 for char in set(subscript): dims = subscript.count(char) n *= ntril_ndim(sizes[char], dims) return n ebcc.util.permutations.symmetrise(subscript, array, symmetry=None, apply_factor=True) Enforce a symmetry in an array. Parameters: subscript ( str ) \u2013 Subscript for the input array. array ( NDArray [ T ] ) \u2013 Array to symmetrise. symmetry ( Optional [ str ] , default: None ) \u2013 Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. apply_factor ( Optional [ bool ] , default: True ) \u2013 Whether to apply a factor to the output array, to account for the symmetry. Returns: NDArray [ T ] \u2013 Symmetrised array. Source code in ebcc/util/permutations.py def symmetrise( subscript: str, array: NDArray[T], symmetry: Optional[str] = None, apply_factor: Optional[bool] = True, ) -> NDArray[T]: \"\"\"Enforce a symmetry in an array. Args: subscript: Subscript for the input array. array: Array to symmetrise. symmetry: Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. apply_factor: Whether to apply a factor to the output array, to account for the symmetry. Returns: Symmetrised array. \"\"\" # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Check the symmetry string, and compress it: if symmetry is None: symmetry = \"-\" * len(subscript) n = 0 symmetry_compressed = \"\" for char in sorted(set(subscript)): assert len(set(symmetry[n : n + subscript.count(char)])) == 1 symmetry_compressed += symmetry[n] n += subscript.count(char) # Iterate over permutations and signs: array_as = np.zeros(array.shape, dtype=array.dtype) groups = tuple(sorted(set(zip(sorted(set(subscript)), symmetry_compressed)))) # don't ask inds = [tuple(i for i, s in enumerate(subscript) if s == char) for char, symm in groups] for tup in itertools.product(*(permutations_with_signs(ind) for ind in inds)): perms, signs = zip(*tup) perm = list(range(len(subscript))) for inds_part, perms_part in zip(inds, perms): for i, p in zip(inds_part, perms_part): perm[i] = p sign = util.prod(signs) if symmetry[perm[0]] == \"-\" else 1 array_as = array_as + np.transpose(array, perm) * sign if apply_factor: # Apply factor sizes = [subscript.count(s) for s in sorted(set(subscript))] array_as = array_as * get_symmetry_factor(*sizes) return array_as ebcc.util.permutations.unique(lst) Get unique elements of a list. Source code in ebcc/util/permutations.py def unique(lst: list[Hashable]) -> list[Hashable]: \"\"\"Get unique elements of a list.\"\"\" done = set() out = [] for el in lst: if el not in done: out.append(el) done.add(el) return out","title":"Permutations"},{"location":"reference/util/permutations/#ebcc.util.permutations.factorial","text":"Return the factorial of n . Source code in ebcc/util/permutations.py def factorial(n: int) -> int: \"\"\"Return the factorial of `n`.\"\"\" if n in (0, 1): return 1 else: return n * factorial(n - 1)","title":"factorial"},{"location":"reference/util/permutations/#ebcc.util.permutations.permute_string","text":"Permute a string. Parameters: string ( str ) \u2013 String to permute. permutation ( tuple [ int , ...] ) \u2013 Permutation to apply. Returns: str \u2013 Permuted string. Examples: >>> permute_string(\"abcd\", (2, 0, 3, 1)) \"cbda\" Source code in ebcc/util/permutations.py def permute_string(string: str, permutation: tuple[int, ...]) -> str: \"\"\"Permute a string. Args: string: String to permute. permutation: Permutation to apply. Returns: Permuted string. Examples: >>> permute_string(\"abcd\", (2, 0, 3, 1)) \"cbda\" \"\"\" return \"\".join([string[i] for i in permutation])","title":"permute_string"},{"location":"reference/util/permutations/#ebcc.util.permutations.get_string_permutation","text":"Get the permutation to transform one string into another. Parameters: string ( str ) \u2013 Initial string. target ( str ) \u2013 Target string. Returns: tuple [ int , ...] \u2013 Permutation to transform string into target . Examples: >>> get_string_permutation(\"abcd\", \"cbda\") (2, 0, 3, 1) >>> get_string_permutation(\"iijj\", \"jjii\") (2, 3, 0, 1) Source code in ebcc/util/permutations.py def get_string_permutation(string: str, target: str) -> tuple[int, ...]: \"\"\"Get the permutation to transform one string into another. Args: string: Initial string. target: Target string. Returns: Permutation to transform `string` into `target`. Examples: >>> get_string_permutation(\"abcd\", \"cbda\") (2, 0, 3, 1) >>> get_string_permutation(\"iijj\", \"jjii\") (2, 3, 0, 1) \"\"\" # Find the indices of each character in the string indices: dict[str, list[int]] = {char: [] for char in set(string)} for i, char in enumerate(string): indices[char].append(i) # Get the permutation perm: list[int] = [] for char in target: perm.append(indices[char].pop(0)) return tuple(perm)","title":"get_string_permutation"},{"location":"reference/util/permutations/#ebcc.util.permutations.tril_indices_ndim","text":"Return lower triangular indices for a multidimensional array. Parameters: n ( int ) \u2013 Size of each dimension. dims ( int ) \u2013 Number of dimensions. include_diagonal ( Optional [ bool ] , default: False ) \u2013 If True, include diagonal elements. Returns: tuple [ NDArray [ integer ], ...] \u2013 Lower triangular indices for each dimension. Source code in ebcc/util/permutations.py def tril_indices_ndim( n: int, dims: int, include_diagonal: Optional[bool] = False ) -> tuple[NDArray[integer], ...]: \"\"\"Return lower triangular indices for a multidimensional array. Args: n: Size of each dimension. dims: Number of dimensions. include_diagonal: If True, include diagonal elements. Returns: Lower triangular indices for each dimension. \"\"\" ranges = [np.arange(n)] * dims if dims == 1: return (ranges[0],) # func: Callable[[Any, ...], Any] = np.greater_equal if include_diagonal else np.greater slices = [tuple(slice(None) if i == j else None for i in range(dims)) for j in range(dims)] casted = [rng[ind] for rng, ind in zip(ranges, slices)] if include_diagonal: mask = functools.reduce( lambda x, y: x & y, map(lambda x, y: x >= y, casted[:-1], casted[1:]) ) else: mask = functools.reduce( lambda x, y: x & y, map(lambda x, y: x > y, casted[:-1], casted[1:]) ) tril = tuple( np.broadcast_to(inds, mask.shape)[mask] for inds in np.indices(mask.shape, sparse=True) ) return tril","title":"tril_indices_ndim"},{"location":"reference/util/permutations/#ebcc.util.permutations.ntril_ndim","text":"Return len(tril_indices_ndim(n, dims, include_diagonal)) . Source code in ebcc/util/permutations.py def ntril_ndim(n: int, dims: int, include_diagonal: Optional[bool] = False) -> int: \"\"\"Return `len(tril_indices_ndim(n, dims, include_diagonal))`.\"\"\" # FIXME hack until this function is fixed: if include_diagonal: return sum(1 for tup in itertools.combinations_with_replacement(range(n), dims)) else: return sum(1 for tup in itertools.combinations(range(n), dims)) offset = int(include_diagonal) out = 1 for i in range(dims): out *= n + offset offset -= 1 out //= factorial(dims) return out","title":"ntril_ndim"},{"location":"reference/util/permutations/#ebcc.util.permutations.generate_spin_combinations","text":"Generate combinations of spin components for a given number of occupied and virtual axes. Parameters: n ( int ) \u2013 Order of cluster amplitude. excited ( Optional [ bool ] , default: False ) \u2013 If True, treat the amplitudes as excited. unique ( Optional [ bool ] , default: False ) \u2013 If True, return only unique combinations. Returns: None \u2013 List of spin combinations. Examples: >>> generate_spin_combinations(1) ['aa', 'bb'] >>> generate_spin_combinations(2) ['aaaa', 'abab', 'baba', 'bbbb'] >>> generate_spin_combinations(2, excited=True) ['aaa', 'aba', 'bab', 'bbb'] >>> generate_spin_combinations(2, unique=True) ['aaaa', 'abab', 'bbbb'] Source code in ebcc/util/permutations.py def generate_spin_combinations( n: int, excited: Optional[bool] = False, unique: Optional[bool] = False ) -> Generator[str, None, None]: \"\"\"Generate combinations of spin components for a given number of occupied and virtual axes. Args: n: Order of cluster amplitude. excited: If True, treat the amplitudes as excited. unique: If True, return only unique combinations. Returns: List of spin combinations. Examples: >>> generate_spin_combinations(1) ['aa', 'bb'] >>> generate_spin_combinations(2) ['aaaa', 'abab', 'baba', 'bbbb'] >>> generate_spin_combinations(2, excited=True) ['aaa', 'aba', 'bab', 'bbb'] >>> generate_spin_combinations(2, unique=True) ['aaaa', 'abab', 'bbbb'] \"\"\" if unique: check = set() for tup in itertools.product((\"a\", \"b\"), repeat=n): comb = \"\".join(list(tup) * 2) if excited: comb = comb[:-1] if unique: sorted_comb = \"\".join(sorted(comb[:n])) + \"\".join(sorted(comb[n:])) if sorted_comb in check: continue check.add(sorted_comb) if not excited: # FIXME nab = (comb[:n].count(\"a\"), comb[:n].count(\"b\")) if nab == (n // 2, n - n // 2): comb = (\"ab\" * n)[:n] * 2 elif nab == (n - n // 2, n // 2): comb = (\"ba\" * n)[:n] * 2 yield comb","title":"generate_spin_combinations"},{"location":"reference/util/permutations/#ebcc.util.permutations.permutations_with_signs","text":"Return permutations of a sequence with a sign indicating the number of swaps. The sign is equal to +1 for an even number of swaps, and -1 for an odd number of swaps. Parameters: seq ( Iterable [ Any ] ) \u2013 Sequence to permute. Returns: list [ tuple [ Any , int ]] \u2013 List of tuples of the form (permuted, sign). Source code in ebcc/util/permutations.py def permutations_with_signs(seq: Iterable[Any]) -> list[tuple[Any, int]]: \"\"\"Return permutations of a sequence with a sign indicating the number of swaps. The sign is equal to +1 for an even number of swaps, and -1 for an odd number of swaps. Args: seq: Sequence to permute. Returns: List of tuples of the form (permuted, sign). \"\"\" def _permutations(seq: list[Any]) -> list[list[Any]]: if not seq: return [[]] items = [] for i, item in enumerate(_permutations(seq[:-1])): if i % 2 == 1: inds = range(len(item) + 1) else: inds = range(len(item), -1, -1) items += [item[:i] + seq[-1:] + item[i:] for i in inds] return items return [(item, -1 if i % 2 else 1) for i, item in enumerate(_permutations(list(seq)))]","title":"permutations_with_signs"},{"location":"reference/util/permutations/#ebcc.util.permutations.get_symmetry_factor","text":"Get a value corresponding to the factor from the neglection of symmetry in repeated indices. Parameters: numbers ( int , default: () ) \u2013 Multiplicity of each distinct degree of freedom. Returns: float \u2013 Symmetry factor. Examples: >>> get_symmetry_factor(1, 1) 1.0 >>> get_symmetry_factor(2, 2) 0.25 >>> get_symmetry_factor(3, 2, 1) 0.125 Source code in ebcc/util/permutations.py def get_symmetry_factor(*numbers: int) -> float: \"\"\"Get a value corresponding to the factor from the neglection of symmetry in repeated indices. Args: numbers: Multiplicity of each distinct degree of freedom. Returns: Symmetry factor. Examples: >>> get_symmetry_factor(1, 1) 1.0 >>> get_symmetry_factor(2, 2) 0.25 >>> get_symmetry_factor(3, 2, 1) 0.125 \"\"\" ntot = 0 for n in numbers: ntot += max(0, n - 1) return 1.0 / (2.0**ntot)","title":"get_symmetry_factor"},{"location":"reference/util/permutations/#ebcc.util.permutations.symmetry_factor","text":"Get the symmetry factor for a given subscript. Parameters: subscript ( str ) \u2013 Subscript to get the symmetry factor for. Returns: float \u2013 Symmetry factor. Source code in ebcc/util/permutations.py def symmetry_factor(subscript: str) -> float: \"\"\"Get the symmetry factor for a given subscript. Args: subscript: Subscript to get the symmetry factor for. Returns: Symmetry factor. \"\"\" counts = {char: subscript.count(char) for char in set(subscript)} return get_symmetry_factor(*counts.values())","title":"symmetry_factor"},{"location":"reference/util/permutations/#ebcc.util.permutations.antisymmetrise_array","text":"Antisymmetrise an array. Parameters: v ( NDArray [ T ] ) \u2013 Array to antisymmetrise. axes ( Optional [ tuple [ int , ...]] , default: None ) \u2013 Axes to antisymmetrise over. Returns: NDArray [ T ] \u2013 Antisymmetrised array. Source code in ebcc/util/permutations.py def antisymmetrise_array(v: NDArray[T], axes: Optional[tuple[int, ...]] = None) -> NDArray[T]: \"\"\"Antisymmetrise an array. Args: v: Array to antisymmetrise. axes: Axes to antisymmetrise over. Returns: Antisymmetrised array. \"\"\" if axes is None: axes = tuple(range(v.ndim)) v_as = np.zeros(v.shape, dtype=v.dtype) for perm, sign in permutations_with_signs(axes): transpose = list(range(v.ndim)) for i, ax in enumerate(transpose): if ax in axes: j = axes.index(ax) transpose[i] = perm[j] v_as += np.copy(np.transpose(v, transpose)) * sign return v_as","title":"antisymmetrise_array"},{"location":"reference/util/permutations/#ebcc.util.permutations.is_mixed_spin","text":"Return a boolean indicating if a list of spins is mixed. Source code in ebcc/util/permutations.py def is_mixed_spin(spin: Iterable[Hashable]) -> bool: \"\"\"Return a boolean indicating if a list of spins is mixed.\"\"\" return len(set(spin)) != 1","title":"is_mixed_spin"},{"location":"reference/util/permutations/#ebcc.util.permutations.combine_subscripts","text":"Combine subscripts into new unique subscripts for functions such as compress_axes . For example, one may wish to compress an amplitude according to both occupancy and spin signatures. The output string of this function has the same length as the input subscripts, where the i th character is an arbitrary character chosen such that it is unique for a unique value of tuple(s[i] for s in subscripts) among other values of i . This function also returns a dictionary indicating the size of each new character in the subscript according to the size of the corresponding original character in the dictionary sizes . Parameters: subscripts ( str , default: () ) \u2013 Subscripts to combine. sizes ( Optional [ dict [ tuple [ str , ...], int ]] , default: None ) \u2013 Dictionary of sizes for each index. Returns: tuple [ str , dict [ str , int ]] \u2013 New subscript, with a dictionary of sizes of each new index. Source code in ebcc/util/permutations.py def combine_subscripts( *subscripts: str, sizes: Optional[dict[tuple[str, ...], int]] = None, ) -> tuple[str, dict[str, int]]: \"\"\"Combine subscripts into new unique subscripts for functions such as `compress_axes`. For example, one may wish to compress an amplitude according to both occupancy and spin signatures. The output string of this function has the same length as the input subscripts, where the `i`th character is an arbitrary character chosen such that it is unique for a unique value of `tuple(s[i] for s in subscripts)` among other values of `i`. This function also returns a dictionary indicating the size of each new character in the subscript according to the size of the corresponding original character in the dictionary `sizes`. Args: subscripts: Subscripts to combine. sizes: Dictionary of sizes for each index. Returns: New subscript, with a dictionary of sizes of each new index. \"\"\" if len(set(len(s) for s in subscripts)) != 1: raise ValueError(\"Subscripts must be of the same length.\") char_map: dict[tuple[str, ...], str] = {} new_subscript = \"\" new_sizes: dict[str, int] = {} j = 0 for i in range(len(subscripts[0])): key = tuple(s[i] for s in subscripts) if key not in char_map: if j == 91: raise ValueError(\"Too many unique characters.\") char_map[key] = chr(97 + j) j += 1 if j == 123: j = 65 new_subscript += char_map[key] if sizes: new_sizes[char_map[key]] = sizes[key] return new_subscript, new_sizes","title":"combine_subscripts"},{"location":"reference/util/permutations/#ebcc.util.permutations.compress_axes","text":"Compress an array into lower-triangular representations using an einsum-like input. Parameters: subscript ( str ) \u2013 Subscript for the input array. array ( NDArray [ T ] ) \u2013 Array to compress. include_diagonal ( Optional [ bool ] , default: False ) \u2013 Whether to include the diagonal elements of the input array in the output array. Returns: NDArray [ T ] \u2013 Compressed array. Examples: >>> t2 = np.zeros((4, 4, 10, 10)) >>> compress_axes(\"iiaa\", t2).shape (6, 45) Source code in ebcc/util/permutations.py def compress_axes( subscript: str, array: NDArray[T], include_diagonal: Optional[bool] = False ) -> NDArray[T]: \"\"\"Compress an array into lower-triangular representations using an einsum-like input. Args: subscript: Subscript for the input array. array: Array to compress. include_diagonal: Whether to include the diagonal elements of the input array in the output array. Returns: Compressed array. Examples: >>> t2 = np.zeros((4, 4, 10, 10)) >>> compress_axes(\"iiaa\", t2).shape (6, 45) \"\"\" # TODO out # TODO can this be OpenMP parallel? assert \"->\" not in subscript # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Reshape array so that all axes of the same character are adjacent: arg = tuple(util.argsort(list(subscript))) array = np.transpose(array, arg) subscript = permute_string(subscript, arg) # Reshape array so that all axes of the same character are flattened: sizes: dict[str, int] = {} for char, n in zip(subscript, array.shape): if char in sizes: assert sizes[char] == n else: sizes[char] = n array = np.reshape( array, [sizes[char] ** subscript.count(char) for char in sorted(set(subscript))] ) # For each axis type, get the necessary lower-triangular indices: indices_ndim = [ tril_indices_ndim(sizes[char], subscript.count(char), include_diagonal=include_diagonal) for char in sorted(set(subscript)) ] indices = [ np.ravel_multi_index(ind, (sizes[char],) * subscript.count(char)) for ind, char in zip(indices_ndim, sorted(set(subscript))) ] # Apply the indices: indices = [ ind[tuple(None if i != j else slice(None) for i in range(len(indices)))] for j, ind in enumerate(indices) ] array_flat: NDArray[T] = array[tuple(indices)] return array_flat","title":"compress_axes"},{"location":"reference/util/permutations/#ebcc.util.permutations.decompress_axes","text":"Reverse operation of compress_axes , subscript input is the same. One of shape or out must be passed. Parameters: subscript ( str ) \u2013 Subscript for the output array. array_flat ( NDArray [ T ] ) \u2013 Array to decompress. shape ( Optional [ tuple [ int , ...]] , default: None ) \u2013 Shape of the output array. Must be passed if out is None . include_diagonal ( Optional [ bool ] , default: False ) \u2013 Whether to include the diagonal elements of the output array in the input array. symmetry ( Optional [ str ] , default: None ) \u2013 Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. out ( Optional [ NDArray [ T ]] , default: None ) \u2013 Output array. If None , a new array is created, and shape must be passed. Returns: NDArray [ T ] \u2013 Decompressed array. Source code in ebcc/util/permutations.py def decompress_axes( subscript: str, array_flat: NDArray[T], shape: Optional[tuple[int, ...]] = None, include_diagonal: Optional[bool] = False, symmetry: Optional[str] = None, out: Optional[NDArray[T]] = None, ) -> NDArray[T]: \"\"\"Reverse operation of `compress_axes`, subscript input is the same. One of `shape` or `out` must be passed. Args: subscript: Subscript for the output array. array_flat: Array to decompress. shape: Shape of the output array. Must be passed if `out` is `None`. include_diagonal: Whether to include the diagonal elements of the output array in the input array. symmetry: Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. out: Output array. If `None`, a new array is created, and `shape` must be passed. Returns: Decompressed array. \"\"\" assert \"->\" not in subscript assert shape is not None or out is not None # Get symmetry string if needed: if symmetry is None: symmetry = \"-\" * len(subscript) # Initialise decompressed array if out is None: if shape is None: raise ValueError(\"One of `shape` or `out` must be passed.\") array = np.zeros(shape, dtype=array_flat.dtype) else: array = out out[:] = 0.0 # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Reshape array so that all axes of the same character are adjacent: arg = tuple(util.argsort(list(subscript))) array = np.transpose(array, arg) subscript = permute_string(subscript, arg) # Reshape array so that all axes of the same character are flattened: sizes: dict[str, int] = {} for char, n in zip(subscript, array.shape): if char in sizes: assert sizes[char] == n else: sizes[char] = n array = np.reshape( array, [sizes[char] ** subscript.count(char) for char in sorted(set(subscript))] ) # Check the symmetry string, and compress it: n = 0 symmetry_compressed = \"\" for char in sorted(set(subscript)): assert len(set(symmetry[n : n + subscript.count(char)])) == 1 symmetry_compressed += symmetry[n] n += subscript.count(char) # For each axis type, get the necessary lower-triangular indices: indices = [ tril_indices_ndim(sizes[char], subscript.count(char), include_diagonal=include_diagonal) for char in sorted(set(subscript)) ] # Iterate over permutations with signs: for tup in itertools.product(*[permutations_with_signs(ind) for ind in indices]): indices_perm, signs = zip(*tup) signs = tuple(s if symm == \"-\" else 1 for s, symm in zip(signs, symmetry_compressed)) # Apply the indices: indices_perm = tuple( np.ravel_multi_index(ind, (sizes[char],) * subscript.count(char)) for ind, char in zip(indices_perm, sorted(set(subscript))) ) indices_perm = tuple( ind[tuple(None if i != j else slice(None) for i in range(len(indices_perm)))] for j, ind in enumerate(indices_perm) ) array = _put(array, indices_perm, array_flat * util.prod(signs)) # Reshape array to non-flattened format array = np.reshape( array, (sum([(sizes[char],) * subscript.count(char) for char in sorted(set(subscript))], tuple())), ) # Undo transpose: arg = tuple(util.argsort(list(arg))) array = np.transpose(array, arg) return array","title":"decompress_axes"},{"location":"reference/util/permutations/#ebcc.util.permutations.get_compressed_size","text":"Get the size of a compressed representation of a matrix based on the subscript input. Parameters: subscript ( str ) \u2013 Subscript for the output array. See compressed_axes for details. **sizes ( int , default: {} ) \u2013 Sizes of each character in the subscript. Returns: int \u2013 Size of the compressed representation of the array. Examples: >>> get_compressed_size(\"iiaa\", i=5, a=3) 30 Source code in ebcc/util/permutations.py def get_compressed_size(subscript: str, **sizes: int) -> int: \"\"\"Get the size of a compressed representation of a matrix based on the subscript input. Args: subscript: Subscript for the output array. See `compressed_axes` for details. **sizes: Sizes of each character in the subscript. Returns: Size of the compressed representation of the array. Examples: >>> get_compressed_size(\"iiaa\", i=5, a=3) 30 \"\"\" n = 1 for char in set(subscript): dims = subscript.count(char) n *= ntril_ndim(sizes[char], dims) return n","title":"get_compressed_size"},{"location":"reference/util/permutations/#ebcc.util.permutations.symmetrise","text":"Enforce a symmetry in an array. Parameters: subscript ( str ) \u2013 Subscript for the input array. array ( NDArray [ T ] ) \u2013 Array to symmetrise. symmetry ( Optional [ str ] , default: None ) \u2013 Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. apply_factor ( Optional [ bool ] , default: True ) \u2013 Whether to apply a factor to the output array, to account for the symmetry. Returns: NDArray [ T ] \u2013 Symmetrised array. Source code in ebcc/util/permutations.py def symmetrise( subscript: str, array: NDArray[T], symmetry: Optional[str] = None, apply_factor: Optional[bool] = True, ) -> NDArray[T]: \"\"\"Enforce a symmetry in an array. Args: subscript: Subscript for the input array. array: Array to symmetrise. symmetry: Symmetry of the output array, with a \"+\" indicating symmetry and \"-\" indicating antisymmetry for each dimension in the decompressed array. apply_factor: Whether to apply a factor to the output array, to account for the symmetry. Returns: Symmetrised array. \"\"\" # Substitute the input characters so that they are ordered: subs = {} i = 0 for char in subscript: if char not in subs: subs[char] = chr(97 + i) i += 1 subscript = \"\".join([subs[s] for s in subscript]) # Check the symmetry string, and compress it: if symmetry is None: symmetry = \"-\" * len(subscript) n = 0 symmetry_compressed = \"\" for char in sorted(set(subscript)): assert len(set(symmetry[n : n + subscript.count(char)])) == 1 symmetry_compressed += symmetry[n] n += subscript.count(char) # Iterate over permutations and signs: array_as = np.zeros(array.shape, dtype=array.dtype) groups = tuple(sorted(set(zip(sorted(set(subscript)), symmetry_compressed)))) # don't ask inds = [tuple(i for i, s in enumerate(subscript) if s == char) for char, symm in groups] for tup in itertools.product(*(permutations_with_signs(ind) for ind in inds)): perms, signs = zip(*tup) perm = list(range(len(subscript))) for inds_part, perms_part in zip(inds, perms): for i, p in zip(inds_part, perms_part): perm[i] = p sign = util.prod(signs) if symmetry[perm[0]] == \"-\" else 1 array_as = array_as + np.transpose(array, perm) * sign if apply_factor: # Apply factor sizes = [subscript.count(s) for s in sorted(set(subscript))] array_as = array_as * get_symmetry_factor(*sizes) return array_as","title":"symmetrise"},{"location":"reference/util/permutations/#ebcc.util.permutations.unique","text":"Get unique elements of a list. Source code in ebcc/util/permutations.py def unique(lst: list[Hashable]) -> list[Hashable]: \"\"\"Get unique elements of a list.\"\"\" done = set() out = [] for el in lst: if el not in done: out.append(el) done.add(el) return out","title":"unique"}]}